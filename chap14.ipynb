{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9d60a1b-2392-4174-8d64-16b97d4d31e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m sklearn\u001b[38;5;241m.\u001b[39m__version__ \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.20\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m tf\u001b[38;5;241m.\u001b[39m__version__ \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2.0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "assert tf.__version__ >=\"2.0\"\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943bc2de-3580-446c-8228-6b3135274a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(image):\n",
    "    plt.imshow(image, cmap=\"gray\", interpolation='nearest')\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "def plot_color_image(image):\n",
    "    plt.imshow(image, interpolation='nearest')\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba23bf7-81e0-4569-a6a7-bbc83034cac6",
   "metadata": {},
   "source": [
    "# What is a Convolution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffef755-da13-48e8-a9a6-93f01dd5291a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_sample_image\n",
    "\n",
    "china=load_sample_image(\"china.jpg\")/255\n",
    "flower=load_sample_image(\"flower.jpg\")/255\n",
    "images=np.array([china, flower])\n",
    "batch_size, height, width, channels = images.shape\n",
    "\n",
    "filters=np.zeros(shape=(7,7,channels, 2),dtype=np.float32)\n",
    "filters[:,3,:,0] =1 # vertical line\n",
    "filters[3,:,:,1] =1 # horizontal line\n",
    "\n",
    "outputs = tf.nn.conv2d(images, filters, strides=1, padding=\"SAME\")\n",
    "\n",
    "plt.imshow(outputs[0,:,:,1], cmap='gray')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1e2d1f-cfb2-425e-9471-813d5cffa885",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_index in (0,1):\n",
    "    for feature_map_index in (0,1):\n",
    "        plt.subplot(2,2, image_index*2 + feature_map_index+1)\n",
    "        plot_image(outputs[image_index,:,:,feature_map_index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f45d06-1f06-402b-bd5b-9f4c9b855605",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop(image):\n",
    "    return images[150:220, 130:250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a101f04d-3c3c-47b2-b019-8ca0a8c2a713",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_image(crop(images[0,:,:,0]))\n",
    "\n",
    "for feature_map_index, filename in enumerate([\"china_vertical\", \"china_horizontal\"]):\n",
    "    plot_image(crop(outputs[0,:,:,feature_map_index]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebce159-9c17-4bd6-b06c-b85e6e0fc23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_image(filters[:,:,0,0])\n",
    "plot_image(filters[:,:,0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3643c86d-896e-49da-b9b3-8040c621216c",
   "metadata": {},
   "source": [
    "## Convolutional Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f57df0-4880-44b5-93a4-0ad33c014975",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = keras.layers.Conv2D(filters =2, kernel_size=7, strides=1,\n",
    "                          padding=\"SAME\", activation='relu', input_shape=outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9b5ff2-e27a-4480-9f2b-62c00a40ede1",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_outputs=conv(images)\n",
    "conv_outputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47dfb9d6-b380-402a-8bdc-c29cda88f91a",
   "metadata": {},
   "source": [
    "次元はバッチサイズ、高さ、幅、チャンネル。  \n",
    "この畳込み層は2つのフィルターを持つのでチャンネルの次元数は2になる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73317e43-31b7-41b6-a9f7-54328b57e649",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize =(10,6))\n",
    "for image_index in (0,1):\n",
    "    for feature_map_index in (0,1):\n",
    "        plt.subplot(2,2, image_index*2+feature_map_index+1 )\n",
    "        plot_image(crop(conv_outputs[image_index, :,:,feature_map_index]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e05698-c8db-401c-9d74-ca212f93425f",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv.set_weights([filters, np.zeros(2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c62a9d-1c96-40ba-8055-f976a7150324",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_outputs=conv(images)\n",
    "conv_outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88946736-7f3d-4e32-9483-ceb8f2dfe175",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize =(10,6))\n",
    "for image_index in (0,1):\n",
    "    for feature_map_index in (0,1):\n",
    "        plt.subplot(2,2, image_index*2+feature_map_index+1 )\n",
    "        plot_image(crop(conv_outputs[image_index, :,:,feature_map_index]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb27d56a-b544-4e6c-8012-c57395ece317",
   "metadata": {},
   "source": [
    "## VALID vs SAME padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b919165d-66bc-415e-8371-16335fc0bf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_map_size(input_size, kernel_size, strides=1, padding=\"SAME\"):\n",
    "    if padding=='SAME':\n",
    "        return (input_size-1)//strides +1\n",
    "    else:\n",
    "        return (input_size -kernel_size)//strides+1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece27e9e-1682-4474-9e6c-8b08ff2694f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_before_and_padded_size(input_size, kernel_size, strides=1):\n",
    "    fmap_size=feature_map_size(input_size, kernel_size, strides)\n",
    "    padded_size=max((fmap_size -1)*strides + kernel_size, input_size)\n",
    "    pad_before=(padded_size-input_size)//2\n",
    "    return pad_before, padded_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacd10b7-bb10-4780-a726-2553faf9815e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_same_padding(images, kernel_size, strides=1):\n",
    "    if kernel_size==1:\n",
    "        return images.astype(np.float32)\n",
    "    batch_size, height, width, channels=images.shape\n",
    "    top_pad, padded_height=pad_before_and_padded_size(height, kernel_size, strides)\n",
    "    left_pad, padded_widtht=pad_before_and_padded_size(width, kernel_size, strides)\n",
    "    padded_shape  = [batch_size, padded_height, padded_width, channels]\n",
    "    padded_images=np.zeros(padded_shape, dtype=np.float32)\n",
    "    padded_images[:, top_pad:hieght+top_pad, left_pad:width+left_pad, :]=images\n",
    "    return padded_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed16761e-168a-4627-b10b-f6607526562d",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_size =7\n",
    "strides =2\n",
    "\n",
    "conv_valid = keras.layers.Conv2D(filters=1, kernel_size=kernel_size, strides=strides, padding=\"VALID\")\n",
    "conv_same = keras.layers.Conv2D(filters=1, kernel_size=kernel_size, strides=strides, padding=\"SAME\")\n",
    "\n",
    "valid_output = conv_valid(manual_same_padding(images, kernel_size, strides))\n",
    "\n",
    "conv_same.build(tf.TensorShape(images.shape))\n",
    "\n",
    "conv_same.set_weights(conv_valid.get_weights())\n",
    "\n",
    "same_output = conv_same(images.astype(np.float32))\n",
    "\n",
    "assert np.allclose(valid_output.numpy(), same_output.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b8c944-0a60-4934-9bdb-ff0e108a7b02",
   "metadata": {},
   "source": [
    "# Pooling layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f00d1b-826f-4bf2-9d95-31e22401ed89",
   "metadata": {},
   "source": [
    "## Max pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3756ed2-60ad-43e6-9079-9067db0ac4da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
