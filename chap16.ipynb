{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75a525b2-54d5-4965-ad3f-7cbfd2e43a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import sklearn\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7072b8dd-3b74-42fa-8d6f-8e715c0c6318",
   "metadata": {},
   "source": [
    "# Char-RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2e960d-e8fc-4b22-965f-b603e64da8da",
   "metadata": {},
   "source": [
    "## Splitting a sequence into batches of shuffled windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fa38c5e-bd1a-49d8-88ac-7a0dd923951d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________ Batch 0 \n",
      "X_batch\n",
      "[[6 7 8 9]\n",
      " [2 3 4 5]\n",
      " [4 5 6 7]]\n",
      "===== \n",
      "Y_batch\n",
      "[[ 7  8  9 10]\n",
      " [ 3  4  5  6]\n",
      " [ 5  6  7  8]]\n",
      "____________________ Batch 1 \n",
      "X_batch\n",
      "[[ 0  1  2  3]\n",
      " [ 8  9 10 11]\n",
      " [10 11 12 13]]\n",
      "===== \n",
      "Y_batch\n",
      "[[ 1  2  3  4]\n",
      " [ 9 10 11 12]\n",
      " [11 12 13 14]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "n_steps=5\n",
    "dataset =tf.data.Dataset.from_tensor_slices(tf.range(15))\n",
    "dataset = dataset.window(n_steps, shift=2, drop_remainder=True)\n",
    "dataset = dataset.flat_map(lambda window: window.batch(n_steps))\n",
    "dataset = dataset.shuffle(10).map(lambda window: (window[:-1], window[1:]))\n",
    "dataset = dataset.batch(3).prefetch(1)\n",
    "for index, (X_batch, Y_batch) in enumerate(dataset):\n",
    "    print(\"_\" * 20, \"Batch\", index, \"\\nX_batch\")\n",
    "    print(X_batch.numpy())\n",
    "    print(\"=\" *5, \"\\nY_batch\")\n",
    "    print(Y_batch.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d2d97e-257d-4fc6-8d57-215e72574d8c",
   "metadata": {},
   "source": [
    "## Loading the Data and Preparing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e243762-5e94-4e6f-a199-2571ee158fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespeare_url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
    "filepath = keras.utils.get_file(\"shakespeare.txt\", shakespeare_url)\n",
    "with open(filepath) as f:\n",
    "    shakespeare_text =f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80e35f56-e024-4ff0-b899-62e820f7bb58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(shakespeare_text[:148])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5cc2797d-2ba8-4123-aa12-9215aa08c699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n !$&',-.3:;?abcdefghijklmnopqrstuvwxyz\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\".join(sorted(set(shakespeare_text.lower())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df5114a0-52be-48f6-99c6-562e7acb88d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer= keras.preprocessing.text.Tokenizer(char_level =True)\n",
    "tokenizer.fit_on_texts(shapespeare_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1602d1e-213b-4290-84ad-a2cc3e32521e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[20, 6, 9, 8, 3]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.texts_to_sequences([\"First\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73838d53-a96a-4b2b-9507-1559aed0f5c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['f i r s t']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.sequences_to_texts([[20,6,9,8,3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0bc69b57-9fff-412e-8116-fba89f3334c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_id = len(tokenizer.word_index)\n",
    "dataset_size = tokenizer.document_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c1e8e07-c76e-4755-a70b-4245c3a65dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "[encoded] = np.array(tokenizer.texts_to_sequences([shapespeare_text])) -1\n",
    "train_size = dataset_size *90 //100\n",
    "dataset= tf.data.Dataset.from_tensor_slices(encoded[:train_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc0b6f99-702e-41f4-806a-3683596d13ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 100\n",
    "window_length = n_steps +1\n",
    "dataset = dataset.window(window_length, shift=1, drop_remainder =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "661df4d3-a5f9-44aa-a2b7-e7009f054b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.flat_map(lambda window: window.batch(window_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d9bfbb6-85da-40eb-bb9a-758048ec2f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "84381ae2-c7d3-4e47-a652-5e11b69ebbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size =32\n",
    "dataset = dataset.shuffle(10000).batch(batch_size)\n",
    "dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c213647-bb79-454e-a99c-25c209c756de",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e75ddc66-852e-48f5-a6bc-d49e592316d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "98776554-f938-433d-8160-f4967525bfdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 100, 39) (32, 100)\n"
     ]
    }
   ],
   "source": [
    "for X_batch, Y_batch in dataset.take(1):\n",
    "    print(X_batch.shape, Y_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe277bfc-82d8-4219-97b7-decd34ece41f",
   "metadata": {},
   "source": [
    "## Creating and Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623aba0f-969f-42c4-aa8c-75966100216c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([keras.layers.GRU(128, return_sequences=True, input_shape = [None, max_id], \n",
    "                                                  # dropout=0.2, recurrent_dropout=0.2,\n",
    "                                                  dropout =0.2),\n",
    "                                 keras.layers.GRU(128, return_sequences=True,\n",
    "                                                  # dropout=0.2, recurrent_dropout=0.2,\n",
    "                                                  dropout =0.2),\n",
    "                                 keras.layers.TimeDistributed(keras.layers.Dense(max_id, activation=\"softmax\"))\n",
    "                                ])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer =\"adam\")\n",
    "history= model.fit(dataset, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39036b6a-2e1d-4be2-815f-11d23fe34dad",
   "metadata": {},
   "source": [
    "## Using the Model to Generate Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ca643e-5471-474c-9799-8bf360a6d3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(texts):\n",
    "    X=np.array(tokenizer.texts_to_sequences(texts))-1\n",
    "    return tf.one_hot(X, max_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9289b90f-29d2-4960-8984-640a933b0053",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new=preprocess([\"How are yo\"])\n",
    "Y_pred = np.argmax(model(X_new), axis=-1)\n",
    "tokenizer.sequences_to_texts(Y_pred+1)[0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3555d07-3459-4a45-986b-dc1bb2987c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "tf.random.categorical([[np.log(0.5), np.log(0.4), np.log(0.1)]], num_samples=40).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5716e4-37c0-417a-be48-f14d2f6f3534",
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_char(text, temperature=1):\n",
    "    X_new=preprocess([text])\n",
    "    y_proba=model(X_new)[0, -1:, :]\n",
    "    rescaled_logits = tf.math.log(y_proba)/ temperature\n",
    "    char_id = tf.random.categorical(rescaled_logits, num_samples=1)+1\n",
    "    return tokenizer.sequences_to_texts(char_id.numpy())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4236409-4967-41cd-abba-0b8ca58a0c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "next_char(\"How are yo\", temperature=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21458dc-be09-4260-848e-6ef52f232246",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_text(text, n_chars=50, temperature=1):\n",
    "    for _ in range(n_chars):\n",
    "        text += next_char(text, temperature)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680be356-dfee-450a-8512-064b7ca84b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "print(complete_text(\"t\", temperature=0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525efc10-47ae-4f43-883c-b7695f36ce37",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(complete_text(\"t\", temperature=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9be030-50a0-41a3-9f5e-d41361a94cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(complete_text(\"t\", temperature=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23a927c-9cbf-429c-a9cf-4c5e952c13d2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Stateful RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c980000-0563-4e30-9816-77195a489029",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e872c8bd-53ee-4784-a9ea-010b1e4e119a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset= tf.data.Dataset.from_tensor_slices(encoded[:train_size])\n",
    "dataset = dataset.window(window_length, shift=n_steps, drop_remainder=True)\n",
    "dataset=dataset.flat_map(lambda window: window.batch(window_length))\n",
    "dataset=dataset.batch(1)\n",
    "dataset=dataset.map(lambda windows:(windows[:,:-1], windows[:, 1:]))\n",
    "dataset =dataset.map(lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch))\n",
    "dataset =dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4572848-6f3f-4124-a089-fe8002bea813",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "encoded_parts=np.array_split(encoded[:train_size], batch_size)\n",
    "datasets=[]\n",
    "for encoded_part in encoded_parts:\n",
    "    dataset =tf.data.Dataset.from_tensor_slices(encoded_part)\n",
    "    dataset=dataset.window(window_length, shift=n_steps, drop_remainder=True)\n",
    "    dataset = dataset.flat_map(lambda window: window.batch(window_length))\n",
    "    datasets.append(dataset)\n",
    "dataset = tf.data.Dataset.zip(tuple(datasets)).map(lambda *windows: tf.stack(windows))\n",
    "dataset= dataset.map(lambda windows: (windows[:,:-1], windows[:,1:]))\n",
    "dataset = dataset.map(lambda X_batch, Y_batch:(tf.one_hot(X_batch, depth=max_id), Y_batch))\n",
    "dataset = dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94fc318-3cd5-470f-b9eb-589dfbd45f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([keras.layers.GRU(128, return_sequences=True, stateful=True, \n",
    "                                                  # dropout=0.2, recurrent_dropout=0.2,\n",
    "                                                  dropout =0.2, \n",
    "                                                  batch_input_shape=[batch_size, None, max_id]),\n",
    "                                 keras.layers.GRU(128, return_sequences=True,stateful =True,\n",
    "                                                  # dropout=0.2, recurrent_dropout=0.2,\n",
    "                                                  dropout =0.2),\n",
    "                                 keras.layers.TimeDistributed(keras.layers.Dense(max_id, activation=\"softmax\"))\n",
    "                                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6530b2-72ac-4572-a527-720dafb6dbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResetStatesCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_begin(self, epoch, logs):\n",
    "        self.model.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013f5351-a315-44b2-b1b5-c9156f7f8104",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer =\"adam\")\n",
    "history= model.fit(dataset, epochs=50, \n",
    "                  callbacks=[ResetStatesCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9371c19e-54d7-4c99-a45c-66c77c3592a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "stateless_model = keras.models.Sequential([\n",
    "    keras.layers.GRU(128, return_sequences=True, input_shape = [None, max_id] ),\n",
    "    keras.layers.GRU(128, return_sequences=True),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(max_id, activation=\"softmax\"))\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e665df-fbc3-470b-bba4-ad589248140e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stateless_model.build(tf.TensorShape([None, None, max_id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3732b963-f9ef-4a3e-a9e6-481af1f2da48",
   "metadata": {},
   "outputs": [],
   "source": [
    "stateless_model.set_weights(model.get_weights())\n",
    "model = stateless_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fe524f-f5f4-4275-a1cd-67c1a9661dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "print(complete_text(\"t\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880c66b1-ef86-44e7-b5f3-81872fdab61c",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd88d2c0-3ae3-45ea-b5ca-d66426b76edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
