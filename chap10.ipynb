{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6eb44e5e-128b-4164-b0e1-19387431ae16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe241a5-1ede-4685-91e1-52f633b781bc",
   "metadata": {
    "tags": []
   },
   "source": [
    "# From Biological to Artificial Neural Networks with Keras\n",
    "## The Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93136240-6d59-4e4e-bbc9-348205e1f126",
   "metadata": {},
   "source": [
    "[Perceptron](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Perceptron.html):1層のTLUからなるネットワーク。\n",
    "\n",
    "TLU:threshold logic unit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3dc933e2-47f5-4c9e-8914-98a97ad49343",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "iris=load_iris()\n",
    "X=iris.data[:,(2,3)]\n",
    "y=(iris.target==0).astype(np.int32)\n",
    "\n",
    "per_clf=Perceptron()\n",
    "per_clf.fit(X,y)\n",
    "\n",
    "y_pred=per_clf.predict([[2,0.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab2ba832-418e-41fc-856b-c3f33822b605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f57c6ec0-0756-4068-a2e0-cedae3e719b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 5.0, 0.0, 2.0)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAm4AAAEOCAYAAAAwtJvUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAABLWklEQVR4nO3deZzN5fvH8dc1izU7o7Kv2YpsKVlKiUopqZRv6y8paUVajD3ZlQwppCilFG2Wkohkj4xCkUgkys4s9++PcxxjzIwZ5sw5Z+b9fDzOw5zr/izXmbFcPp/7c1/mnENEREREgl9YoBMQERERkfRR4SYiIiISIlS4iYiIiIQIFW4iIiIiIUKFm4iIiEiIUOEmIiIiEiKyrHAzszJm9o2ZxZrZejN7IoVtzMxeNbPNZrbWzOomGbvXzDZ5X/dmVd4iIiIiwcKyah03M7sAuMA5t8rMCgArgbbOudgk21wPdAWuBy4DXnHOXWZmRYEVQH3Aefet55zblyXJi4iIiASBLLvi5pzb6Zxb5f36ALABKJVss5uBt53HUqCwt+C7DpjnnNvrLdbmAa2yKncRERGRYBARiJOaWXngUuCHZEOlgD+SvN/ujaUWT+nYnYBOALlz569XsmS1zElaRERE5Ay2bUt9rGzZM22/Fef2WFrHz/LCzczOAz4CnnTO7c/s4zvnxgPjAcqVq++ef35FZp9CREREJEWdO6c+9vzzZ9q+/hmPn6VPlZpZJJ6ibapzbkYKm+wAyiR5X9obSy0uIiIikmNk5VOlBkwANjjnRqSy2SzgHu/TpY2A/5xzO4E5QEszK2JmRYCW3piIiIhI0ChYMHPiqcnKW6WNgf8B68xsjTf2PFAWwDk3DvgCzxOlm4HDwP3esb1m1h9Y7t2vn3Nub9alLiIiInJmQ4ac/fadO69ceabts6xwc859B6Q54c551ibpksrYRGCiH1ITERERCQnqnCAiIiISIlS4iYiIiISIgKzjJiIiIiLQowfs9y2OVq/embbXFTcRERGRANmfwRVtVbiJiIiIhAgVbiIiIiIhQoWbiIiISIhQ4SYiIiISIlS4iYiIiARIMLe8EhEREZEkMtrySlfcREREREKECjcRERGREKHCTURERCREaI6biIiISBo6d059bNy4U98/8gg4d/p2ZjB27LnnoituIiIiIpkkpaItrXhGqXATERERCREq3ERERERChAo3ERERkRCRZQ8nmNlE4EZgt3OuVgrj3YG7k+RVHSjhnNtrZluBA0ACEO+cq581WYuIiIgEj6y84vYW0Cq1QefcUOdcHedcHeA54Fvn3N4km1zlHVfRJiIiIkHJLGPxjMqyK27OuYVmVj6dm3cA3vNjOiIiIiLpknzJj7RkxpIfaQm6OW5mlg/PlbmPkoQdMNfMVppZp8BkJiIiIhJYwbgAbxtgcbLbpFc653aYWRQwz8x+ds4tTGlnb2HXCaBo0bL+z1ZEREQkiwTdFTfgTpLdJnXO7fD+uhv4GGiY2s7OufHOufrOufrnnVfCr4mKiIiIZKWguuJmZoWAZkDHJLH8QJhz7oD365ZAvwClKCIiIlmoRw/Yv//0eMGCMGRI1ueT2U79fPXqnWn7rFwO5D2gOVDczLYDvYFIAOfciWl/twBznXOHkuxaEvjYPI9jRADvOudmZ1XeIiIiEjgpFW1pxUNNRj9HVj5V2iEd27yFZ9mQpLHfgNr+yUpEREQkdATjHDcRERERSYEKNxEREZEQka0Lt717f2f//l2BTkNEREQkU2Trwu3gwT1ER1dhzpzBxMUdDXQ6IiIikkEFC2YsHmoy+jnMOeefTIKAmfk+XPHiFbjlliHUrdsOy6yGYSIiIiKZpHNnW3mmnuzZ+opbnjyRvq/37NnCG2+0Z/jwZvz++8oAZiUiIiJydrJ14Va9ehleeaUTRYsW8MU2b17Eyy83YPLk+/n33z8DmJ2IiIhIxmTrws3MeOSR69mwYSxPPHETERHhADjn+P77t+jduyqff96f48cPBzhTERERkTPL1nPc6tWr7JYuHe57v3HjDnr2nMxnny07ZbsiRcpw662DqV//Ts1/ExERCSL+ankVjK20cvwct+SqVi3FjBnPM3t2X2rVKueL79v3BxMm3MWQIVfw229LA5ihiIiIJOWvlleh2korRxVuJ1x9dW2WLx9BTMwjlChRyBffsmUpQ4ZczoQJd7N37x8BzFBERETkdDmycAMIDw/n//7vOmJjY3jmmVvIletk29bly9+ld++qzJoVzdGjBwOYpYiIiMhJObZwO6FQofwMGnQva9e+xq23XuGLx8Ud5Ysv+tO7d1W+/34yiYmJAcxSRERERIWbT8WK5zNtWg++/nogl15a0Rf/77+dTJ58Hy+/3JBNmxYFMEMRERHJ6VS4JdOkSU2+/34Yb77ZlQsuKOKLb9u2kuHDmzJ+fHv27NkSwAxFRERyDn+1vArVVlo5ajmQjDp48AhDh85g5MiZHD163BePiMhFixZP0arV8+TNG+Q/YREREQkJWg7kHJ13Xl769r2bn34awx13NPHF4+OPM2fOYKKjq7Bo0RskJiYEMEsRERHJKVS4pUPZsiV4551nWLjwZRo2rOqLHziwm6lTOzFwYF1+/nl+ADMUERGRnECFWwY0alSNhQtfZvLkpyhdupgvvmPHWkaNasHYsW3ZtWtTADMUERGR7CzL5riZ2UTgRmC3c65WCuPNgZnAiZn/M5xz/bxjrYBXgHDgTefcy+k557nOcUvL4cPHGDnyE4YOncHhw8d88fDwSK66qivXX9+LfPkK++XcIiIi/hYsLaE6d059bNy4U99nJGd/fb5HHoGUSiszGDv29PipedTHuRVp9t7MyitubwGtzrDNIudcHe/rRNEWDowBWgM1gA5mVsOvmaZDvny5eeGFO1i/Pob//e8qXzwhIY6vvhpBr16VWbAghoSE+ABmKSIicnZCsSVURnL21+dL7XpYavGMni/LCjfn3EJg71ns2hDY7Jz7zTl3HJgG3JypyZ2DUqWKMWHCE3z//TAaN67uix869A/TpnVhwIDarF8/J4AZioiISHYRbHPcLjezH83sSzOr6Y2VApI2Dt3ujaXIzDqZ2QozW7FnT9b9t6BevcrMn/8S773Xg/Llo3zxnTtjGT26FaNHX8/OnRuyLB8RERHJfoKpcFsFlHPO1QZGA5+czUGcc+Odc/Wdc/WLF8/aNdbMjHbtrmDt2tcYMOB/FCiQ1ze2fv2X9O9/MdOmdeXgwX+yNC8RERHJHoKmcHPO7XfOHfR+/QUQaWbFgR1AmSSblvbGglaePLno0aMdsbFjefDBazHzzDNMTExgwYLXiI6uzNdfjyI+/vgZjiQiIiJyUtAUbmZ2vnkrHDNriCe3f4DlQBUzq2BmuYA7gVmByzT9SpYszNixXVi2bATNm1/six8+/C/Tpz9Fv361WLv2U7Jz9woREQlNodgSKiM5++vzWSrPhKYWz+j5snI5kPeA5kBxYBfQG4gEcM6NM7PHgEeAeOAI8LRzbol33+uBUXiWA5nonBuYnnP6czmQjHLO8emny+jZ8y02b955yli1ai247bYRlC59SYCyExERkUBLT8sr9SrNYsePxxET8wUDB77Pf/8d9sXDwsJo3Pj/aNOmPwULRqVxBBEREcmO1Ks0COXKFcmTT95MbOxYOnduTXi450eQmJjIokXjiY6uwpw5Q4iLO3aGI4mIiEhOo8ItQEqUKMSrrz7MihWjuPbaOr740aP7+fjjZ+nbtwarVn2k+W8iIiLio1ulQcA5x+zZK+nR4y1++WX7KWNVqjSlffuRlC1bN0DZiYhIVguWdlP+ktG2UOmVke9bRnLIqp+HbpWGCDOjdev6rFo1ilGjHqJo0QK+sU2bFjJoUH3efvsB/vtvZxpHERGR7CIU201lREbbQqVXRr5vGckhmH4eKtyCSGRkBI8+egOxsTE8/ngbIiLCAc8VuSVLJhEdXYUvvhjI8eNHApypiIiIBIIKtyBUtGgBhg17kNWrX+WGGxr44seOHWLWrBfp06cay5dP0/w3ERGRHEaFWxC76KJSfPzxC3z5ZV9q1izri+/du40JEzowdGhjtmz5IYAZioiISFZS4RYCWrSozfLlIxkz5hFKlCjki//22/cMHtyIiRM7snfvHwHMUERERLKCCrcQERERzkMPXUdsbAxPP92WXLkifGPLlk2lf//KfPppb44dOxTALEVEJDOEYrupjMhoW6j0ysj3LSM5BNPPQ8uBhKhff93Jc89N5pNPlp4SL1ToQm65ZRANG3YkLEx1uYiISKjQciDZWKVKF/DBBz356qsB1KlT0Rf/778/eeutexk8+DI2b/4ugBmKiIhIZlPhFuKaNq3F998P5Y03unL++UV88d9/X8GwYU0YP/529uzZEsAMRUREJLOk61apmeUBngBaAFEkK/icc5f4JbtzlJ1vlabkwIEjDB06g1GjZnL06HFfPCIiNy1aPEWrVs+RN282mSAhIuIHodixoHPn1MfGjTv1fUa6BfhrW8jY99lf2wajzLxVGgP0BLYCnwAfJXtJEChQIC/9+t3NunWvcfvtTXzx+PhjzJnzMr17V+W7794kMTEhgFmKiASvYFoh3x8y0i3AX9tCxr7P/to2VEWceRMA2gLtnXNf+TEXySTlykUxZcozdOlyA926TWD58k0A7N+/iylTHmLBgtdo334kF110VYAzFRERkYxI7xW3w4AWCgsxl19ejUWLBvPWW09RqlQxX3z79h8ZOfJqxo69hd27NwcwQxEREcmI9BZuQ4Cnzc51hRXJamFhYdx1VzPWr48hOroD+fLl9o39+OMn9O1bgw8/7Mbhw/8GLkkRERFJl1QLNzObdeIFXAPcAWw1sy+TjnnHJcjly5ebF1+8g/XrY+jY8eQt0oSEOL76ajjR0VX49tuxJCTEBzBLERERSUtaV9z+Sfb6GJgP/JXC2BmZ2UQz221mP6UyfreZrTWzdWa2xMxqJxnb6o2vMbMV6fpkkqJSpYoxceITLFkylCuuqO6LHzy4h/fee5SBA+uwfv2cAGYoIhI4wbRCvj9kpFuAv7aFjH2f/bVtqMqyzglm1hQ4CLztnKuVwvgVwAbn3D4zaw30cc5d5h3bCtR3zu3JyDlz2nIgGeWc48MPF/P885P5/fe/TxmrVet6brttOOefXy1A2YmIiOQsmbYciJnNN7PCKcQLmtn89BzDObcQ2JvG+BLn3D7v26VA6fQcV86emdG+/ZWsWzeG/v07ct55eXxjP/30Bf361eL99x/n4MF0XVQVERERP0vvwwnNgVwpxPMATVKIn6sHgS+TvHfAXDNbaWad0trRzDqZ2QozW7FnTzZauMWP8uTJxbPP3kZs7Fjuv/8aTjyDkpiYwDffjCY6ugpff/0KCQlxAc5UREQkZ0uzcDOzumZW1/v2khPvva8GQCdgR2YmZGZX4Sncnk0SvtI5VxdoDXTx3nZNkXNuvHOuvnOufvHi2eimdhY4//wivP76Y/zww3CaNTt5N/vw4X1Mn/4k/fpdzNq1n5FVt9dFRETkVGdagHcFnqtdDpibwvgRoGtmJWNmlwBvAq2dc777c865Hd5fd5vZx0BDYGFmnVdOVadORebO7c+sWT/Qs+db/PrrXwDs2vULMTFtqF79Wm67bQSlSp02VVFERDJBMLR58mf7qGBoTRUMOZyNM90qrQBUAgxPsVQhyasUUNA5NzEzEjGzssAM4H/OuY1J4vnNrMCJr4GWQIpPpkrmMTNuvrkRa9aMZvDg+yhUKJ9vbMOGeQwYUJt3332EAwf+TuMoIiJyNoKhzZM/20cFQ2uqYMjhbKRZuDnnfnfObXXOhTnnVnjfn3jtdM6lu+mlmb0HfA9cZGbbzexBM+tsZifa40YDxYCYZMt+lAS+M7MfgWXA58652Rn+pHJWcueO5Kmn2hIbO5aHH25FWJjnt4xziSxcOI5evSozd+5Q4uKOBThTERGR7C/VW6Vmdk96D+Kcezsd23Q4w/j/Af+XQvw3oPbpe0hWKlGiEKNHd+bhh1vz7LOTmDdvDQBHj+5nxoweLFw4jnbthlGnTlvfww0iIiKSudKa4zYm2ftcQCSQ6H0fBsQBx4AzFm6SPdSqVY7PPuvN7Nkr6d59Ehs3ep5N2bPnN15//VaqVGlG+/YjKVv20gBnKiIikv2keqvUOVfgxAu4E1iLZ+mPPJxcBmQNcFcW5ClBxMxo3bo+q1e/wsiR/0eRIuf5xjZt+pZBg+rx9tsP8t9/OwOYpYiISPaT3nXchgGPO+cWO+fiva/FwJOAWhPkUJGREXTpciMbNoyla9cbiYgIBzwdGZYsmUh0dBW+/PIljh8/EuBMRURCSzC0efJn+6hgaE0VDDmcjXS1vDKzI8Blzrm1yeK1gaXOubx+yu+cqOVV1vrllx08++wkvvji1HayRYuW5dZbh1Cv3u2a/yYiIpKKTGt5BfwAvGpmpU4EvF+PxNOeSoSLLirFJ5+8yBdf9KFmzbK++N6923jzzTsZOvRKtmxZFsAMRUREQlt6C7cH8SzVsdXMtnqbvm8FooCH/JOahKprrqnD8uUjee21ziTtXvHbb0sYPPgyJk36H/v2bQ9ghiIiIqEpXYWbc+5X4BLgBmCE93U9cLFzbrP/0pNQFRERTqdOrYiNjeHpp9sSGXnyAeYffphCdHRVPv20D8eOHQpgliIiIqElXXPcQpXmuAWPzZt38txzk5k589Q764ULl6Jt20E0bHi3b3FfEclaodr6J9QEQxsrCW7pmeOW1gK8TwMxzrmj3q9T5ZwbcZY5Sg5RufIFTJ/ek2+/XUe3bhP58cctAPz77w7eeusevvlmNO3bj6Ry5cYBzlQk5wnV1j+hJhjaWEnoS2sB3q7AZOAoaTeSd3hunYqcUbNmF7N06TDeeecbevWawq5d/wLw++/LGTbsSurVu51bbhlM8eLlA5qniIhIMEprAd4Kzrl/knyd2qti1qUr2UF4eDj33XcNsbFjefbZ28idO9I3tnLlB/TpU41PPnmeo0cPBDBLERGR4JOuSUVmltaVOZGzUqBAXvr378i6da/Rvv2Vvnh8/DFmzx5EdHQVFi+eQGJiQgCzFBERCR7pnQ3+r5nNNbPnzewKFXKSmcqXL8nUqd1YsGAQ9etX8cX379/FO+/8H4MG1eeXXxYELkEREZEgkd7CrS2eRXhbA/OBfUkLOX8lJznLFVdU57vvBjNp0pOUKlXMF//jjzWMHHkV48bdyt9//xrADEWyp1Bt/RNqgqGNlYS+DC8HYmZ5gSuAu4GOQLhzLtwPuZ0zLQcSug4dOsrw4R8zfPjHHDly3BcPD4/k6quf4PrrXyRv3kIBzFBERCRzZWbLK8wsyszuwPMEaQxwJ7AY6HdOWYqkIH/+PERHd2D9+hjuvru5L56QEMe8ecPo1asyCxeOIyEhPnBJioiIZLH0PpwQC2wBHgZ2Ap2AIs65q5xzff2Yn+RwpUsXZ9KkJ1m8eAiXX17NFz94cA/vvvsIAwfWITZ2bgAzFBERyTrpveJWAEgAjgCHgYPA8TT3EMlEDRpUZcGCQUyZ0o1y5Ur44n/+uZ5XX72OMWNu5K+/fg5ghiIiIv6X7jluZlYJaO59NcNTzC0CvnHOjUznMSYCNwK7nXO1Uhg34BU8fVAPA/c551Z5x+4FXvRuOsA5N/lM59Mct+zpyJFjvPLKLIYM+YiDB4/64mFhETRr9ig33tib/PmLBjBDETkbjzwCKf2TZAZjxwbfcYOlLZVaaWUfmTrHzTn3q3NuAnAfcAfwMdAKGJaBnN7y7pOa1kAV76sTMBbAzIoCvYHLgIZAbzMrkoHzSjaSN29uevZsz/r1Mdx3Xws89T4kJsbzzTev0qtXZebPf5WEhLgAZyoiGZHadYRzbantr+MGS1sqtdLKWdI7x62hmfUwsy+BfcACoDowHM/VsXRxzi0E9qaxyc3A285jKVDYzC4ArgPmOef2Ouf2AfNIuwCUHOCCC4oyfnxXli4dTtOmNX3xw4f38cEHT9Cv38WsW/c5GX1yWkREJFil94rbd3jWclsDtAeKOucud84955ybk4n5lAL+SPJ+uzeWWvw0ZtbJzFaY2Yo9e/RfiJzg0ksrMm/eAD74oCcVK5b0xXft+oUxY27k1VevY8eOnwKYoYiISOZIb+FWxDl3xYlCzTl3yK9ZnQPn3HjnXH3nXP3ixbVSYU5hZrRt24gff3yNl1++j4IF8/nGNmyYx4ABtXn33Uc4cODvAGYpIiJybtJVuGVhobYDKJPkfWlvLLW4yCly547k6afbEhsbQ6dOrQgL8/wWdy6RhQvH0atXZebOHUZc3LEAZyoiIpJx6X44IYvMAu4xj0bAf865ncAcoKWZFfE+lNDSGxNJUVRUYV57rTPLl4/gmmtq++JHj+5nxozu9OtXk9WrP9b8N5Eg4n3OKN3xQB83WNpSqZVWzpLhllfndDKz9/AsJ1Ic2IXnSdFIAOfcOO9yIK/hefDgMHC/c26Fd98HgOe9hxronJt0pvNpORABcM7x5Zcr6d59Ips2/XnKWNWqzWnffiRlytQJTHIiIiJe6VkOJEsLt6ymwk2SiouLZ9y4Lxkw4H327Tvoi5sZV1zxADfdNIBChc4PYIYiIpKTZeo6biKhLjIygq5d27Bhw1gee+xGwsNPzH9zLF48gejoKsyePYi4uKNnOJKIiEhgpHrFzcyeTu9BnHMjMi2jTKQrbpKWn3/eTs+eb/HFFytOiRctWo5bbx1CvXrtfYv7ioiI+Ns53So1sy3pPI9zzlXMaHJZQYWbpMe8eavp3n0SsbHbTolXqtSY9u1HUr58gwBlJiIiOYnmuKlwk3SKj09gwoS59O37HskXbr7ssv/Rtu0gihRJcc1nERGRTKE5biLpFBERzsMPtyY2NoannrqZyMgI39gPP7xD//6V+Oyzvhw/fjiAWYqISE6X7itu3vXTWgNlgVxJx5xz/TI/tXOnK25ytjZv3knPnm8xa9YPp8SLFClN27aDaNDgLt/iviIiIpkh026VehfD/Rw4BpTA07XgAu/7rc65S8493cynwk3O1YIF6+jWbQJr1249JV6+fEPatx9JpUpXBCYxERHJdjLzVulQYCqexu5HgavxXHlbAQw+lyRFglnz5hfzww/Def31LpQsWdgX37p1GUOHNubNNzvwzz+/By5BERHJUdJbuF0CvOY8l+cSgNzOuV3As0AfP+UmEhTCw8O5//5riY0dS48e7cidO9I3tmLFNPr0qcYnn7zA0aMHApiliIjkBOkt3I4n+XoXUM779UHgwkzNSCRIFSiQlwED/se6da9x222NffG4uKPMnv0S0dFVWbJkEomJiQHMUkREsrP0Fm6rgBOLWS0ABpjZvcCrwFo/5CUStMqXL8m773bnm29eol69yr74/v1/8fbbDzBoUH02bvw2gBmKiEh2ld7C7QXgRHfuF4G/gdFAEeBhP+QlEvQaN67B4sVDmDDhCS68sKgv/scfqxkxojmvv96Ov//+NYAZiohIdqMFeEUywaFDRxk27GNGjPiYI0dOziyIiMjFVVc9wfXXv0DevIUCmKGIiAS7THuq1Mzmm1nhFOIFzWz+WeYnkm3kz5+H3r078NNPY+jQoZkvHh9/nHnzhhIdXYWFC18nISE+gFmKiEioS++t0uYkW3TXKw/QJNOyEQlxZcqUYPLkp/juuyE0anSRL37gwN+8+25nBg68lNjYeQHMUEREQlmahZuZ1TWzut63l5x47301ADrhWYxXRJJo2LAq3377Mu+88wxly5bwxf/88ydefbUlY8a04a+/fglghiIiEorSnONmZonAiQ0shU2OAF2dcxP9kNs50xw3CQZHjhxj1KhZDBnyEYcOHfXFIyLCadr0MW64IZr8+YumcQQREckJMmOOWwWgEp6iraH3/YlXKaBgsBZtIsEib97cPPdce2JjY7j33haYef4PFB+fwPz5rxAdXYVvvhlNQkJcgDMVEZFgl2bh5pz73Tm31TkX5pxb4X1/4rXTOZeQkZOZWSsz+8XMNptZzxTGR5rZGu9ro5n9m2QsIcnYrIycVyQYXHBBUd54oytLlw6jSZOavvihQ3t5//3H6d//Etat+4Ls/KS3iIicm/Q+nICZtTazz8ws1szKeGP/Z2Yt0rl/ODAGaA3UADqYWY2k2zjnnnLO1XHO1cGzTtyMJMNHTow5525Kb94iwebSSyvx1VcDeP/9Z6lQoaQv/tdfPzNmzA2MHt2aP/9cH8AMRUQkWKV3OZC7gQ+ATXhuk55o1hgO9EjnuRoCm51zvznnjgPTgJvT2L4D8F46jy0SUsyMW265nLVrX2PQoHspUCCvbyw2dg4DBtTm3Xcf5cCBvwOYpYiIBJv0XnHrATzknHsKSLoQ1VKgTjqPUQr4I8n77d7YacysHJ4CMekacXnMbIWZLTWztqmdxMw6ebdbsWfP/nSmJhIYuXNH8swzt7Bhw1geeug6wsI8fyQTExNYuHAs0dFV+OqrEcTHHz/DkUREJCdIb+FWBfg+hfhBoGDmpeNzJ/Bhsjl05bxPWtwFjDKzSint6Jwb75yr75yrX7y4P1ITyXxRUYUZM+YRli8fQYsWtX3xI0f+48MPn6Fv35qsWfOJ5r+JiORw6S3c/gSqphBvCqS3GeMOoEyS96VJfQ24O0l2m9Q5t8P76294Gt1fms7zioSMiy8uzxdf9OHjj1+gSpULffG//97MuHG3MGpUC7Zv/zGAGYqISCClt3AbD7xqZo2978uY2b3AEGBsOo+xHKhiZhXMLBee4uy0p0PNrBqe5vXfJ4kVMbPc3q+LA42B2HSeVySkmBk33NCA1atfYdiwByhcOL9v7JdfvmHgwEt5552H+O+/vwKYpYiIBEK6Cjfn3BA8T3jOA/ID3wDjgHHOuTHpPEY88BgwB9gAfOCcW29m/cws6VOidwLT3Kn3hKoDK8zsR++5X3bOqXCTbC1Xrkgef/wmNmwYS5cuNxAe7vnj6pxj8eI3iY6uwuzZLxMXd/QMRxIRkewizc4Jp21slg/PUh5hQKxz7qC/EssM6pwg2cmGDX/Qs+dbfPnlylPixYqV59Zbh1C37m2+xX1FRCT0nHPnBDPLZ2ZjzGyHme0G3gS2OueWBXvRJpLdVK9ehpkze/HZZ72pXv3kdNF//tnKG2/czvDhTfn99xUBzFBERPztTLdK+wL3AZ/jWXftWtI/p01E/KBly0tZuXIUr77aiWLFCvjimzd/x6BBDXjrrXvZty+1535ERCSUnalwuxV40DnXyTn3OHAD0NbbBUFEAiQiIpzOna9nw4axPPnkTURGRvjGli59m969q/L55/04fvxwALMUEZHMdqbCrQyw6MQb59wyPAvwXpjqHiKSZQoXPo8hQx5gzZpXadOmoS9+/PhhPv20N717X8QPP0wlMTExgFmKiEhmOVPhFg4kX7I9HohIYVsRCZAqVS7ko4+eZ86cflx8cXlffN++7Uya1JGhQ6/gt99SWkNbRERCSZpPlZpZIp4lQI4lCbcGvgV892CCtem7niqVnCghIYHJk+cTHT2F3bv/O2Wsfv07ueWWlylWrFyAshMRkdSc81OlwGQ8XRP+SfKagqfnaNKYiASJ8PBwHnjgWmJjx9K9ezty5Tp5gXzFimn06VONmTNf5OhRPRguIhJqMrSOW6jRFTcR2LJlF88/P5mPPlpySrxQoQu4+eaBNGp0r6+5vYiIBE5mXHETkQDZvftbVqx4iMWLb2HFiofYvfvbszpOhQolee+9HsyfP5C6dSv54v/9t5O3336Al19uwKZNCzMrbRER8SMVbiJBaPfub/n11xiOHfsbcBw79je//hpz1sUbwJVX1mTJkqG8+ebjXHhhUV9827ZVDB/ejNdfv42///4tE7IXERF/UeEmEoS2bZtCYuKxU2KJicfYtm3KOR03LCyMe+65mvXrY3jhhTvIkyeXb2z16o/o27c6M2Y8y5Ej+8/pPCIi4h8q3ESC0LFjezIUz6j8+fPQu3cH1q8fQ4cOzXzx+PjjzJ07hOjoyixaNJ7ExIRMOZ+IiGQOFW4iQSh37uIZip+tMmVKMHnyU3z33RAuu+wiX/zAgb+ZOvVhBg68lJ9//jpTzykiImdPhZtIECpbtiNhYblPiYWF5aZs2Y5+OV/DhlVZuPBl3n77acqUOVkc7tixjlGjriEm5iZ27drol3OLiEj6qXATCUJRUc2oVOlRcucuARi5c5egUqVHiYpqdsZ9z5aZceedTVm3bgx9+txF/vx5fGNr135K3741+eCDpzh0aJ/fchARkbRpHTcRSdGff+4lOnoKb789/5R4/vxFufHGvjRt+jDh4ZEByk5EJPvROm4ictYuvLAob775OEuXDuPKK2v44ocO7eX997vSv39tfvrpywBmKCKS86hwE5E01a1bma+/Hsi0aT2oUKGkL/7XXxt47bXrGT26NX/+GRvADEVEco4sLdzMrJWZ/WJmm82sZwrj95nZ32a2xvv6vyRj95rZJu/r3qzMWyTYZVaXhdSYGbfeegU//jial166hwIF8vrG1q+fzYABl/Dee49x8GDmLFciIiIpy7LCzczCgTFAa6AG0MHMaqSw6fvOuTre15vefYsCvYHLgIZAbzMrkkWpiwQ1f3RZSE2ePLno1u1WYmPH8n//19LX4zQxMYFvvx1Dr16V+eqrkcTHH8/0c4uISNZecWsIbHbO/eacOw5MA25O577XAfOcc3udc/uAeUArP+UpElL81WUhLSVLFiYm5lGWLRvB1Vdf4osfOfIfH374NP361WLNmplk54efREQCISsLt1LAH0neb/fGkmtnZmvN7EMzK5PBfTGzTma2wsxW7Nmjtj2S/fm7y0JaLrmkPF9+2ZePPnqeypUv9MV3797EuHFtGTXqGrZvX+v3PEREcopgezjhU6C8c+4SPFfVJmf0AM658c65+s65+sWLF8z0BEWCTVZ1WUiNmdGmTUPWrHmFoUMfoHDh/L6xX36Zz8CBlzJlSif279+VJfmIiGRnEVl4rh1AmSTvS3tjPs65f5K8fRMYkmTf5sn2XZDpGYqEoLJlO/LrrzGn3C71Z5eF1OTKFckTT9zE3Xc3p3//aYwfP5uEhEScS+S7795gxYpptG79Aldf/QSRkXnOfECRAIiIiKNSpe3ky3c00KlINpOQEM6uXYXZvbs4zp39dbMsW4DXzCKAjUALPIXYcuAu59z6JNtc4Jzb6f36FuBZ51wj78MJK4G63k1XAfWcc3vTOqcW4JWcYvfub9m2bQrHju0hd+7ilC3b0a9dFtIjNvYPnn12EnPmrDolXrx4BW65ZQh167bDzAKUnUjKLrpoC2XKFKBAgWL6/SmZxjlHQkIce/fuYudOx6+/lk1xu/QswJtlV9ycc/Fm9hgwBwgHJjrn1ptZP2CFc24W8LiZ3QTEA3uB+7z77jWz/niKPYB+ZyraRHKSqKhmAS/UkqtRowyffhrN7Nkr6dFjEj//vB2APXu28MYb7alcuQnt24+kXLl6Ac5U5KR8+Y5SoEB5FW2SqcyMiIhclChRikOHfjm3Y2Xnp750xU0kOMTFxfPmm3Pp1+89/vnngC9uZlx22T20bfsShQtfmMYRRLLGpZduoEKF6oFOQ7KxLVs2sHp1yr/H1PJKRIJCZGQEjzxyPbGxY3niiZuIiAgHPLcPli6dTHR0FT7/vD/Hjx8OcKYiIsFNhZuIZJkiRc5j6NAHWLPmVW68saEvfvz4YT79NJrevauxbNm7Wv9NRCQVWflUqUjI8Ndk/3Xrotm//+S6ZgULXsLFF/c75xz8+XCCP45dtWopZsx4nvnzf6Rbt4n89NPvAOzb9wcTJ97NN9+Mpn37kVSs2CgzPoKIBEjbts2pVq0WL7/8WqBTyTZ0xU0kGX+1kEpetAHs37+WdeuizykHf7a88nc7rauvrs3y5SMYO/ZRoqIK+eJbtixlyJDLmTDhbvbu3ZYp5xLJrrp2vY+oKGP48P6nxBcvXkBUlPHPP+lfjLtt2+b07PlYus559903nnG7SZNm8OKLg9J9/uQOHz7MwIHP07BhZcqUyUO1asW54YbGzJjxXrqPsW3bVqKijDVrVpx1HsFEhZtIMv5qIZW8aEsrnpEc/NnyKivaaYWHh/Pggy2JjR1Lt263kivXyRsBy5e/S+/eFzFrVjRHjx7MtHOK+EvNmhAVdfqrZk3/njdPnjyMGTOUPXv+9u+J0un4cU+/4iJFinLeeQXO+jjdu3fmk0/eZ8CAUSxe/DPTp8/jtts6sm9fzl1YQoWbSDKBbCF1Njn4M9+s/F4ULJiPl166h7VrX+PWW6/wxePijvLFF/3p3bsqS5a8RWJiYqafWySz/J1K3ZRaPLM0bnwVZcqUZ8SI/mlu9/33C2nV6jLKlMlDjRol6dXrKV+R1bXrfSxZ8i0TJ44hKsqIijK2bduarvOfuAL36quDqV27NHXqlAZOv4L32WczaNbsEsqWzUvVqkW5+eZm7N6deleVOXNm8cQTz9Gy5Y2ULVueiy++lPvvf4QHH+zi28Y5x+jRQ2jQoBJly+alWbOLmT795H8u69evAEDLlg2IijLatm0OQGJiIsOH96dOnTKULp2bZs0u5ssvZ55y/mHD+lG3bjlKl85NzZrn06XLPb6x+fNn06ZNE6pUKULVqkW5/fbr2LhxQ7q+X+dChZtIMoFuIZXRHPyZbyC+FxUrns+0aT34+uuBXHppRV/8v/928vbb9/Pyyw3ZtGmR384vEorCwsLo1etlJk8ex5Ytv6a4zc6dO+jQoTW1al3K11+vZtSoCcyY8R4DBjwHwMCBr1C//uV06HA/69btZN26nZQqVSbFY6VkyZJviY1dy7Rps/nww69PG9+16y8efvhO7rjjXr77bgMzZy6kffv/pXnMqKjzmT9/Nvv3/5fqNoMGvci7705g8OAxLFoUy+OPP0f37g8zb97nAMyZswyAadNms27dTiZNmgHA+PGvMGbMUHr1Gsy3366jdetbuP/+W1m3bg0An376ETExwxg8OIalSzcxdepn1K178qGqQ4cO0anTk8yZs4yPP15AwYKF6Nixja8Q9hcVbiLJlC3bkbCw3KfEMqOFVMGCl6Q7npEc/JWvv499Jk2a1OT774fx5ptdueCCIr74tm0rGT68KePHt2fPni1+z0MkVFxzzfU0bNiYQYNeSHF80qQYSpa8kCFDYqhatTotW95Ir14vM3Hiaxw+fJiCBQuRK1cu8ubNR8mS51Oy5PmEh4en+/x58uThlVcmUr16LWrUuPi08V27/iQuLo42bW6jbNnyVK9ei44d/4+oqJKpHnP48PGsWvUD1aoVp0WLuvTs+RgLFszzjR86dIhx40YwcuSbXH11K8qVq0C7dnfRseNDTJw4BoBixUoAULRoMUqWPJ8iRYoCEBMzjEcf7Ua7dndRqVJVevbsR6NGTYiJGQbA9u2/U7LkBTRv3pLSpctSp059Hnzw5NXDNm3a0aZNOypWrELNmpfwyiuT2LZtC6tWLUv39+xsqHATSSYqqhmVKj1K7twlACN37hJUqvToOT9JefHF/U4r0lJ7qjQjOfgrX38fOz3CwsK4554WrF8fw3PPtSdPnly+sVWrPqRPn2p8/HFPjhzZnyX5iAS7Xr0GM2vWdH78ceVpYxs3bqBevUaEhZ38p79hwys5fvw4W7ZsPudzV6tWi9y5c6c6XrNmbZo2vYamTWtx//3tmDRprG9O3vbt2yhf/jzfa9SolwC4/PKmLF/+GzNmzOfmm2/n1183cvvtLXnmmYe9nymWo0ePcuedrU7Z/623xrJ1a8pXHgEOHNjPX3/9ScOGjU+JX3bZlWzcGAvATTe159ixo9SvX4Enn3yQWbOmc+zYyTm/W7b8SufOd9GgQSUqVixIzZolSUxMZMcO/z5QpeVARFLgrxZSqS39ca45+LPlVTC00zrvvLz07Xs3Dz7YkhdeeJv33/fcKo2PP86cOYNZsmQSN900gMaNHyAsLP1XCESym7p1G3Ljje3o168HTz/dK937ZUaLr3z58qc5Hh4ezvTpc1mxYikLFszl3XcnMHDgc3zyybdUq1aT+fPX+LY9cVUMIDIykkaNmtCoURMef7wnI0YM4OWXe/HEE8/55ry+886nlCp1av/PyMjIs/ocJ74XpUqVYcmSX1i06GsWLvyK3r2fYdiwvnz55Q/kz5+fjh1v5IILSjNs2OtccEEpIiIiuPLKGsTF6VapiAgAZcuW4J13nmHhwpdp2LCqL37gwG6mTu3EwIF1+fnn+QHMUHK6EiUyFveH559/iaVLFzF//uxT4lWrVmflyqWnPOCzbNl35MqVi/LlKwEQGZmLhIQEv+VmZjRocDndu/dm7tzlnH/+hcyc+T4RERFUrFjZ90pauCVXtWoNAA4dOshFF9Ugd+7cbN/++yn7V6xYmTJlygGQK5fnSn3Sz1WgQEHOP/9Cli1bfMqxf/jhO9/xwXP799prb6B//5HMmbOcn39ez7Jli9m79x82bfqZJ598nmbNrqFq1eocPHiA+Pj4TPtepUZX3EQk5DRqVI2FC1/m/fcX8eKL7/DHH56nXHfsWMuoUS245JKbaNduGCVLVglwppLTrF8f6AygYsXK/O9/nXjjjVdOid9//6OMHz+KHj0epVOnJ/j999/o378nDzzwGPny5QOgbNnyrF69jG3btpI//3kUKVL0lFur52LFiqUsXPgVV111HSVKlGTdutXs2PHHKYVScm3bNueWWzpQp059ihQpxsaNsbz00vNUqVKNqlWrEx4ezqOPdqNPn24452jUqCmHDh1k5cql3qkWnShePIq8efPyzTdzKFOmPHny5KFgwUJ06dKdwYOjqVixCrVr12P69CksXbqIr75aBcC0aW8RHx9P3bqXkT//ecyc+T6RkZFUrFiFwoWLUKxYcaZMeYMLLyzDX3/toG/f7kRE+L+s0hU3EQlJYWFhdOjQjHXrxtC7dwfy5Ts5t2bt2ln061eT6dOf5tChfQHMUiQwnnkmmvDwU4uICy4oxXvvfclPP63m6qvr8MQTD3DrrR144YWXfNs8+mg3IiNz0aRJDapXL8H27Zk3X6tgwUIsW7aYu+++kUaNqtC79zM8/XQv2rdP/WGnq666junT3+GOO66jceNqPPvsozRq1IQPPpjre3CiZ8/+dO/eh5iYYTRtWpPbb7+Wzz77iLJlPcuAREREMHDgq0yd+iaXXHIh99xzMwAPPfQ4Xbp0p1+/HjRtWosvv/yYiRM/olat2t58CzN16gRuuqkJzZrV4rPPPmLSpBmUK1eBsLAwxo9/n9jYtTRrVouePbvw7LP9yZUr9Tl+mcWyc0/AevUqu6VLhwc6DQlBmzePY9euuUAiEEbJki2pXLlzitv6q41VRviz5VWo2LHjH6Kjp/DOO9+cEs+fvxht2vSlSZOHT/uHTCS5Sy/dQIUK1QOdhmRjW7ZsYPXqlH+Pde5sK51z9dPaX1fcRJLxFG2z8RRtAIns2jWbzZvHnbatv9pYZYS/21KFilKlijFhwhN8//0wGjc++ZfioUP/MG3aYwwYUJv162encQQRkeCnwk0kGc+VtvTF/dXGKiOyoi1VKKlXrzLz57/Ee+/1oHz5KF98585YRo9uzejR17Nzp/9XNxcR8QcVbiKnSa2l0rm1WvJX+6hgaNEVbMyMdu2uYO3a1xg48B4KFMjrG1u//kv697+YadO6cvDgPwHMUkQk41S4iZwmtT8W5/bHxV/to4KhRVewypMnF92730ps7FgefPBa3/pMiYkJLFjwGtHRlfn661HEx/t33SURkcySpYWbmbUys1/MbLOZ9Uxh/GkzizWztWb2tZmVSzKWYGZrvK9ZWZm35CwlS7ZMd9xfbawyIpBtqUJFyZKFGTu2C8uWjaB585OteA4f/pfp05+iX79arF37Kdn5YS0RyR6yrHAzs3BgDNAaqAF0MLPki7esBuo75y4BPgSGJBk74pyr433dlCVJS45UuXJnSpZsxck/HmGULNkqxadK/dXGKiMC3ZYqlNSuXYE5c/rx4YfPUbnyBb747t2biIm5iVdeuZbt21OetygiEgyybDkQM7sc6OOcu877/jkA59ygVLa/FHjNOdfY+/6gc+68jJxTy4GISGqOH48jJuYLBg58n//+O+yLh4WF0bjx/9GmTX8KFoxK4wiSHWk5EPG3UFoOpBTwR5L3272x1DwIfJnkfR4zW2FmS82srR/yE5EcJFeuSJ588mY2bBhH586tCQ/3/HWYmJjIokXjiY6uzJw5Q4iLO3aGI4mIZJ2gfDjBzDoC9YGhScLlvFXoXcAoM6uUyr6dvAXeij179mdBtiISyooXL8irrz7MihWjaNnyUl/86NEDfPzxs/TtW4NVqz7S/DcRCQpZWbjtAMokeV/aGzuFmV0DvADc5Jzz/VfXObfD++tvwALg0uT7esfHO+fqO+fqFy9eMPOyF5FsrWbNsnz2WW9mzerFRReV9sX37PmN8eNvY8SI5mzbtiqAGYqcm7Ztm9Oz52OBTkPOUVb2f1kOVDGzCngKtjvxXD3z8c5rex1o5ZzbnSReBDjsnDtmZsWBxpz64IJkE/5q3ZSRFlYAK1d25ejRk3f28+QpQ716o1PcdvHidkBCkkg4jRt/lMq2twNJl57IRePGH6S47Q8/PEB8/F7f+4iIolx22cQUt/Vny6uc1k6rVat6tGhRmzfemEO/ftPYu/cAAJs2LWTQoPo0anQvN988kMKFLwxwpiInde16H3v37mHq1M9S3WbSpBlERkae9TkOHz7MyJEDmDnzA3bu3E7+/OdRqdJFPPjgY9x6a4d0HWPbtq3Ur1+BuXOXU6dOmlO5JBVZdsXNORcPPAbMATYAHzjn1ptZPzM78ZToUOA8YHqyZT+qAyvM7EfgG+Bl51xsVuUuWcNfrZsy0sIKTi/aAI4e/YOVK7uetu3pRRtAgjeefNvkRRvAcW/8VMmLNoD4+L388MMDp23rz5ZXObWdVmRkBI8+egMbNozl8cfbEBHhaWbtnOP779+id++qfPHFAI4fPxLgTCUY/fvvVDZuLM/69WFs3Fief/+dGtB8jh/3/L1TpEhRzjuvwFkfp3v3znzyyfsMGDCKxYt/Zvr0edx2W0f27dt75p0l02TpHDfn3BfOuarOuUrOuYHeWLRzbpb362uccyWTL/vhnFvinLvYOVfb++uErMxbsoa/WjdlpIUVcFrRlnY8edGWVjy1RV5Pjycv2tKK+7PlVU5vp1WkyHkMG/Ygq1e/yg03NPDFjx07xKxZvejTpxrLl7+n+W/i8++/U/nzz07Exf0OOOLifufPPztlafHWtet93H33jbz66mBq1y5NnTqeW//Jb5V+9tkMmjW7hLJl81K1alFuvrkZu3fvSvW4c+bM4oknnqNlyxspW7Y8F198Kfff/wgPPtjFt41zjtGjh9CgQSXKls1Ls2YXM336yb8v6tevAEDLlg2IijLatm0OeB4KGj68P3XqlKF06dw0a3YxX34585TzDxvWj7p1y1G6dG5q1jyfLl3u8Y3Nnz+bNm2aUKVKEapWLcrtt1/Hxo3Zs7VdUD6cIDmT/1o3+aeFVbDwZ8srtdPyuOiiUnz88Qt8+WVfatYs64vv3buNCRPuYujQxmzZ8kMAM5RgsXv3Czh3+JSYc4fZvfuFLM1jyZJviY1dy7Rps/nww69PG9+16y8efvhO7rjjXr77bgMzZy6kffv/pXnMqKjzmT9/Nvv3/5fqNoMGvci7705g8OAxLFoUy+OPP0f37g8zb97nAMyZswyAadNms27dTiZNmgHA+PGvMGbMUHr1Gsy3366jdetbuP/+W1m3bg0An376ETExwxg8OIalSzcxdepn1K3b0HfeQ4cO0anTk8yZs4yPP15AwYKF6Nixje9qY3aSlXPcRNKUO3dx7y250+PnJoyUi7Ts8f8W/33f/HvsUNSiRW2WLx/JpElf0afPu/z9t+cfsN9++57BgxvRsOHdtG07iKJFy5zhSJJdxcVty1DcX/LkycMrr0wkd+7cKY7v2vUncXFxtGlzG2XKeJoUVa9eK81jDh8+nkceuZtq1YpTvfrFNGhwBa1a3Uzz5tcCnuJp3LgRfPDBXBo1agJAuXIVWL16GRMnjuHaa2+gWLESABQtWoySJc/3HTsmZhiPPtqNdu08U9979uzH0qULiYkZxtixU9i+/XdKlryA5s1bEhkZSenSZU+ZI9emzanTU155ZRKVKhVk1aplNGp0ZUa+dUEve/zLJdmCv1o3ZaSFFXgeREh/PDyVs6YUz5XKtqfHIyKKprhlSnF/trxSO63TRUSE89BD1xEbG8Mzz9xCrlwn//+7bNlUeve+iE8/7c2xY4cCmKUESmRk2QzF/aVatVqpFm0ANWvWpmnTa2jatBb339+OSZPGsmeP5z9p27dvo3z583yvUaNeAuDyy5uyfPlvzJgxn5tvvp1ff93I7be35JlnHgZg48ZYjh49yp13tjpl/7feGsvWrb+mmsuBA/v5668/adiw8Snxyy67ko0bPdPZb7qpPceOHaV+/Qo8+eSDzJo1nWPHTk7j2LLlVzp3vosGDSpRsWJBatYsSWJiIjt2ZG3BnBVUuEnQ8Ffrpoy0sAKoV2/0aUVaak+Vep4eTV6kpfxUqefp0eRFWspPlV522cTTirTUnir1Z8srtdNKXaFC+Rk06F5+/HE0t9xyuS8eF3eEzz/vR3R0Vb7/fjKJidnjlrykT1TUQMzynRIzy0dU1MAszSNfvvxpjoeHhzN9+lw++GAuNWpcwrvvTqBRoyr89NOPnH/+hcyfv8b3uvfek39XRkZG0qhREx5/vCfTp8+lZ8/+vPPOeLZt2+r7vf7OO5+esv/Chev54IOU5xSfiZkBUKpUGZYs+YVhw16nQIGC9O79DNdeW49Dhzz/QerY8Ub27PmbYcNeZ/bsH5g/fzURERHExelWqYhfRUU180tRULly5zSX/0gutaU/UpLa0h8pb5vy0h8pSW3pj5T46/vm72NnB5UqXcD77z/LwoU/0a3bRNas+Q2A//77k8mT72PBgtdo334klStnr9s1krLChe8GPHPd4uK2ERlZlqiogb54MDEzGjS4nAYNLqdbt2iaNKnJzJnvU6vWS1SsWDldx6ha1dNy/NChg1x0UQ1y587N9u2/06TJ1SlunyuX5z+vCQknH+AqUKAg559/IcuWLaZp0xa++A8/fOc7Pnhu/1577Q1ce+0NdO3ak1q1zmfZssXUrl2PTZt+ZvDgGK688ioA1q5dRXx8fMa+ISFChZuISCZo2rQW338/lClTFtCr1xT++msfAL//voJhw5pQt257br11MMWLVwhwpuJvhQvfHZSFWlIrVixl4cKvuOqq6yhRoiTr1q1mx44/TimUkmvbtjm33NKBOnXqU6RIMTZujOWll56nSpVqVK1anfDwcB59tBt9+nTDOUejRk05dOggK1cuJSwsjHvu6UTx4lHkzZuXb76ZQ5ky5cmTJw8FCxaiS5fuDB4cTcWKVahdux7Tp09h6dJFfPWVZ9HradPeIj4+nrp1LyN//vOYOfN9IiMjqVixCoULF6FYseJMmfIGF15Yhr/+2kHfvt2JiMieJU72/FQiIgEQHh7Ovfe2oF27KxgyZAajRs3k6FHPrZpVq6azdu0sWrR4ilatniNvXnV2kcApWLAQy5Yt5s03R7N//79ceGEZnn66F+3bpz5/9aqrrmP69HcYNOgFDh06SFTU+TRrdi3PPBNNeLhnykjPnv0pUaIkMTHD6NHjEQoUKEjNmnV47LEeAERERDBw4KsMH96PYcP60qhREz75ZAEPPfQ4Bw8eoF+/Hvz99y4qV76IiRM/olat2t58CzN69GD69OlGfHwcVavWYNKkGZQr5/mP0Pjx7/PCC4/TrFktKlSoTJ8+w3nggdPX08wOLDuvP1SvXmW3dOnwQKchIjnU77/v5oUX3uGDDxadEi9YsCQ33TSAK664n7Cw1B5wkUC49NINVKhQPdBpSDa2ZcsGVq9O+fdY58620tuXPVW64iYhK1haMWWknVZGW29JaCtXLoopU56hS5cb6NZtAsuXbwJg//5dTJnykG/+20UXXRXgTEUkVOipUglJwdKKKSPttDLaekuyj8svr8aiRYN5662nKF26mC++ffuPjBx5NWPHtmXXrk0BzFBEQoUKNwlJwdKKKSPttDLaekuyl7CwMO66qxk//RRDdHQH8uU7ucbWjz/OpF+/mnz44TMcPvxv4JIUkaCnwk1CUvC0YspIO63s3XpL0idfvty8+OIdrF8fQ8eOJ2+RJiTE8dVXI4iOrsKCBTEkJGTPpQxE5NyocJOQlFrLpaxvxZTaH6GU4hnZVrK7UqWKMXHiEyxZMpQrrjg5UfngwT1Mm9aFAQNqs379nABmmHNl54f2JLAy4/eW/sWQkBQsrZgy0k4ro623JGeoX78K33zzElOndqNcuRK++M6dsYwe3YrXXruBnTs3BDDDnCUhIZyEhLhApyHZVFzcEeLiIs/pGCrcJCQFSyumjLTTymjrLck5zIz27a9k3boxDBjwP847L49v7KefvqB//4t5//3HOXjwnwBmmTPs2lWYvXt34ZymMEjmcc5x/Phhdu7cwbZtUed0LK3jJiISZP76ax99+rzLpElfnXJrJV++ItxwQzTNmj1KRETyvreSGcwSqVhxOwULHgp0KpLNxMVFsm1bFPv3p774dnrWcVPhJiISpNas+Y3u3Sfy7bc/nRIvWbIq7doN5+KLb/A14RaR0Jeewk23SkVEglSdOhWZO7c/06f3pFKl833xXbs2EhPThldeacmOHesCmKGIZDUVbiIiQczMuPnmRqxZM5rBg++jUKF8vrGff/6KAQPqMHVqZ/bv3x3ALEUkq2Rp4WZmrczsFzPbbGY9UxjPbWbve8d/MLPyScae88Z/MbPrsjJvEZFAy507kqeeakts7FgefrgVYWGev76dS2TRoteJjq7C3LlDiYs7doYjiUgoy7LCzczCgTFAa6AG0MHMaiTb7EFgn3OuMjASGOzdtwZwJ1ATaAXEeI8nIpKjlChRiNGjO7NixUiuvbaOL3706H5mzOhB3741WL16htYiE8mmsvKKW0Ngs3PuN+fccWAacHOybW4GJnu//hBoYZ6ZtzcD05xzx5xzW4DN3uOJiORItWqV47PPejNz5otUrVrKF9+z5zdef70dI0ZcxbZtqwKYoYj4Q0QWnqsU8EeS99uBy1LbxjkXb2b/AcW88aXJ9i1FCsysE9DJ+/ZYrlxtf0ppOwl6xYGs7l8lmUc/vwDbtOlbXnqp3tnsqp9daNPPL7RddKYNsrJwyxLOufHAeAAzW3Gmx2olOOlnF9r08wtd+tmFNv38QpuZrTjTNll5q3QHUCbJ+9LeWIrbmFkEUAj4J537ioiIiGRrWVm4LQeqmFkFM8uF52GDWcm2mQXc6/36NmC+88ywnQXc6X3qtAJQBViWRXmLiIiIBIUsu1XqnbP2GDAHCAcmOufWm1k/YIVzbhYwAXjHzDYDe/EUd3i3+wCIBeKBLs65hHScdrw/PotkCf3sQpt+fqFLP7vQpp9faDvjzy9bt7wSERERyU7UOUFEREQkRKhwExEREQkR2bJwO1NrLQleZjbRzHabmdbfCzFmVsbMvjGzWDNbb2ZPBDonST8zy2Nmy8zsR+/Pr2+gc5KMMbNwM1ttZp8FOhfJGDPbambrzGzNmZYEyXZz3LytsDYC1+JZqHc50ME5FxvQxCRdzKwpcBB42zlXK9D5SPqZ2QXABc65VWZWAFgJtNWfvdDg7VKT3zl30Mwige+AJ5xzS8+wqwQJM3saqA8UdM7dGOh8JP3MbCtQ3zl3xsWTs+MVt/S01pIg5ZxbiOeJYgkxzrmdzrlV3q8PABtIpcOJBB/ncdD7NtL7yl7/s8/GzKw0cAPwZqBzEf/KjoVbSq219I+HSBYys/LApcAPAU5FMsB7q20NsBuY55zTzy90jAJ6AIkBzkPOjgPmmtlKb+vOVGXHwk1EAsjMzgM+Ap50zu0PdD6Sfs65BOdcHTzdaRqamaYrhAAzuxHY7ZxbGehc5Kxd6ZyrC7QGuninDaUoOxZuao8lEiDeuVEfAVOdczMCnY+cHefcv8A3QKsApyLp0xi4yTtPahpwtZlNCWxKkhHOuR3eX3cDH+OZ9pWi7Fi4pae1lohkMu/k9gnABufciEDnIxljZiXMrLD367x4HvD6OaBJSbo4555zzpV2zpXH82/efOdcxwCnJelkZvm9D3RhZvmBlkCqKytku8LNORcPnGittQH4wDm3PrBZSXqZ2XvA98BFZrbdzB4MdE6Sbo2B/+H53/4a7+v6QCcl6XYB8I2ZrcXzH+B5zjktKyHifyWB78zsRzx92D93zs1ObeNstxyIiIiISHaV7a64iYiIiGRXKtxEREREQoQKNxEREZEQocJNREREJESocBMREREJESrcRES8zGyrmXVLY/w+MzuY2nhWM7O3zExLdojkICrcRCSoeIsR533FmdlvZjbMuzBlevYv7923vr9zzSrZ8TOJyNmJCHQCIiIp+ArPYr6RQBPgTSA/8EggkxIRCTRdcRORYHTMOfeXc+4P59y7wFSgLXhaa5lZDzP71cyOmNk6M0va3meL99fl3qtUC7z7NTCzuWa2x8z2m9l3Znb5uSZqZm3MbKWZHTWzLWY20Ntu78T4VjN70cxe9553u5l1T3aMqmb2rfcYv5jZ9WZ20MzuS+szJdn/CTPbYWb7zGySmeU7188lIsFJhZuIhIIjeK6+AQwAHgS6ADWAQcDrZnaDd/xEc+ZWeNo43ep9XwB4B88VvIbAGuALMyt2tkmZ2XV4isrXgJrAA8BtwEvJNn0KWAfUBQYDQ04UjWYWhqepdDzQCLgP6A3kTrJ/ap8J7+epBVwD3AHcAjxxtp9JRIKbbpWKSFAzs4bAXcDX3nluTwMtnXOLvJts8W7TBfgc+Nsb/8c599eJ4zjn5ic7blegHdAamHKW6b0ADHXOTfK+/9XMngWmmFl3d7Kn4Fzn3Gver0eb2eNACzx9ea8FLvJ+ph3e3J4CFic5T4qfyWs/0Nk5lwBsMLPp3mMPOsvPJCJBTIWbiASjVt6nNyPwXGmbCXTFc4UtDzDbzJI2Wo4EtqZ1QDOLAvoDV+Fp6hwO5AXKnkOe9YCG3mLthDDvcc8Hdnpja5Pt9ycQ5f26GvDniaLNazmQmM4cYr1FW9JjX5bOfUUkxKhwE5FgtBDoBMThKWriAMysgne8DbAt2T5xZzjmZDwF21N4irxjwNdArjT2OZMwoC8wPYWxv5N8nTw3R+ZNVfHnsUUkyKhwE5FgdNg5tzmFeCyegqtc8lufSRz3/hqeLH4l8Lhz7nMAMyuJZ77YuVgFVEsl1/T6GbjQzC50zv3pjdXn1OIrtc8kIjmMCjcRCRnOuQNmNgwYZmaG58rceXgm9Sc658YDu/E8zHCdmW0Fjjrn/gM2Ah3N7Ac8S4sM4WRBdLb6AZ+Z2e/AB3geMKgFNHTO9UjnMeYBvwCTvYv/5gVGeI914nZwap9JRHIYXU4XkVDTC+gDdAPW4yl82uFdMsM5Fw88DvwfnvleM737PYCnyFsJTAMmcoZ5cWfinJsD3IBn3twy76snp9/GTesYiXieBM3t3X8yMBBP0Xb0DJ9JRHIYO/nQk4iIBAMzq41nuZL6zrmVAU5HRIKICjcRkQAzs1uAQ8AmoDyeW6UGXOr0l7SIJKE5biIigVcAz8K8ZYB9wALgKRVtIpKcrriJiIiIhAg9nCAiIiISIlS4iYiIiIQIFW4iIiIiIUKFm4iIiEiIUOEmIiIiEiL+H7PTtzbZ51/KAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a= -per_clf.coef_[0][0] / per_clf.coef_[0][1]\n",
    "b= -per_clf.intercept_ / per_clf.coef_[0][1]\n",
    "\n",
    "axes=[0,5, 0,2]\n",
    "\n",
    "x0, x1= np.meshgrid(\n",
    "    np.linspace(axes[0], axes[1], 500).reshape(-1,1),\n",
    "    np.linspace(axes[2], axes[3], 200).reshape(-1,1),\n",
    ")\n",
    "X_new=np.c_[x0.ravel(), x1.ravel()]\n",
    "y_predict=per_clf.predict(X_new)\n",
    "zz= y_predict.reshape(x0.shape)\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(X[y==0,0], X[y==0,1], 'bs', label=\"Not Iris-Setosa\")\n",
    "plt.plot(X[y==1,0], X[y==1,1], 'yo', label=\"Iris-Setosa\")\n",
    "\n",
    "plt.plot([axes[0], axes[1]],[a *axes[0] +b, a*axes[1]+b], 'k-', linewidth=3)\n",
    "from matplotlib.colors import ListedColormap\n",
    "custom_cmap=ListedColormap(['#9898ff', '#fafab0'])\n",
    "\n",
    "plt.contourf(x0,x1,zz, cmap=custom_cmap)\n",
    "plt.xlabel('Petal length', fontsize=14)\n",
    "plt.ylabel('Petal width', fontsize=14)\n",
    "plt.legend(loc='lower right', fontsize=14)\n",
    "plt.axis(axes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb72592-af31-4784-a056-7d2f847d3d7c",
   "metadata": {},
   "source": [
    "## Activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c63bac9-2862-46c6-b43a-c4680d8eac6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2275b3e2-61d4-4ab2-ba07-5d9c3a04b03c",
   "metadata": {},
   "source": [
    "# Implementing MLPs with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2437b9-b465-48e2-98b0-4fb7a49492f4",
   "metadata": {},
   "source": [
    "## Installing TensorFlow 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d57bcc0-ea24-425b-9b1c-172a6fe8171f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.0\n",
      "2.9.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1611948-1d08-4a21-b9ae-53a1783bc727",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Building an Image Classifier Using the Sequential API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c374eb49-5e16-46ac-a628-e68532d1da31",
   "metadata": {},
   "source": [
    "[fashion_mnist](https://keras.io/ja/datasets/#fashion-mnist): 10種類のファッションカテゴリの白黒画像。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c90fdd56-2c91-414f-865f-6df0d24e75fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist=keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test)=fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb2962bc-8c47-4407-9233-415d367c298e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "uint8\n"
     ]
    }
   ],
   "source": [
    "print(X_train_full.shape)\n",
    "print(X_train_full.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c200185c-5e47-4526-b4ee-690fc20d3b8b",
   "metadata": {},
   "source": [
    "訓練データと検証データに分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bb9ec3a-382c-4a3c-a69b-3a52dfc62ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, X_train=X_train_full[:5000] /255.0, X_train_full[5000:]/255.0\n",
    "y_valid, y_train=y_train_full[:5000], y_train_full[5000:]\n",
    "class_names=[\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "             \"Sandal\", \"Shirt\",\"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00616946-f092-4cbc-b808-43a163cf0fee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Coat'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names[y_train[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2baf5318-a295-4767-a6b0-101f756325a3",
   "metadata": {},
   "source": [
    "[Sequential](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential): レイヤーをスタックしたモデル。\n",
    "\n",
    "[Flatten](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Flatten): インプットの平坦化。\n",
    "\n",
    "[Dense](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense): densely-connected layer(全結合層）。引数にノード数、活性化層の指定、重みの初期化・正規化などがある。\n",
    "\n",
    "一層目に`input_shape`引数を書く。もしくは`model.add(keras.Input(shape=(28,28)))`のような書き方もできる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98d56469-3d5f-4f96-bea6-142ff4e60c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28,28]))\n",
    "model.add(keras.layers.Dense(300,activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(100,activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(10,activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651e4177-e236-4305-8647-2d5de74e530a",
   "metadata": {},
   "source": [
    "こういう書き方もできる\n",
    "```\n",
    "model=keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28,28]),\n",
    "    keras.layers.Dense(300,activation=\"relu\"),\n",
    "    keras.layers.Dense(100,activation=\"relu\"),\n",
    "    keras.layers.Dense(10,activation=\"softmax\")\n",
    "])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96f4de8d-83bf-46e0-b007-2c2a1acbdf72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 300)               235500    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               30100     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "378103d2-73d0-4619-bcbc-57f0c965a976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.reshaping.flatten.Flatten at 0x7f0bb5db14b0>,\n",
       " <keras.layers.core.dense.Dense at 0x7f0b750d69b0>,\n",
       " <keras.layers.core.dense.Dense at 0x7f0b750d6e00>,\n",
       " <keras.layers.core.dense.Dense at 0x7f0b750d5db0>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d040ebb-8c79-479f-842a-cea865d3aad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dense'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden1=model.layers[1]\n",
    "hidden1.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9cd8df9f-c377-4457-9085-352d4735bf47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer('dense') is hidden1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be60ca7f-1ea4-48fb-9a8a-c7514828faba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.03800577, -0.06072519,  0.04525503, ..., -0.04033432,\n",
       "         0.05997644, -0.02142646],\n",
       "       [ 0.03907026,  0.03999666, -0.07150029, ...,  0.05328341,\n",
       "        -0.04518685,  0.04850858],\n",
       "       [ 0.04501025,  0.02594817, -0.05556693, ..., -0.04995359,\n",
       "         0.05097643, -0.01770821],\n",
       "       ...,\n",
       "       [-0.07217607, -0.00272013,  0.01440709, ..., -0.06088309,\n",
       "        -0.05158113,  0.00285212],\n",
       "       [-0.03817282, -0.03467896, -0.05260331, ..., -0.07254871,\n",
       "        -0.0632885 ,  0.05916578],\n",
       "       [ 0.02746485, -0.05840463,  0.03913011, ...,  0.02073743,\n",
       "         0.02145883, -0.03724727]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights, biases=hidden1.get_weights()\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "662b6ffa-24af-4d66-ad5a-de5aaa4121ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d311aeb2-7739-426d-be2c-edad66827ced",
   "metadata": {},
   "source": [
    "weightsはランダムに初期化された状態。biasesは0。Dense()の引数で`kernel_initializer`を指定すると異なる初期化法を使える。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5569da17-269c-4021-b607-620b6ccce1d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 300)\n",
      "(300,)\n"
     ]
    }
   ],
   "source": [
    "print(weights.shape)\n",
    "print(biases.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4537140e-7c79-4e0f-bcf4-a1b12b37b0c8",
   "metadata": {},
   "source": [
    "### Compiling the model\n",
    "損失関数やオプティマイザを指定するために`compile`が必要。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9fdcb91-893f-43e5-8bd1-b0a7c4f5ed89",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "             optimizer='sgd',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a42ede9-4a95-4d80-9547-50ca11dd8965",
   "metadata": {},
   "source": [
    "`sparse_categorical_crossentropy`は排他的な0-9のインデックスを求める今回の問題のような時に使用。  \n",
    "one-hotベクトルの場合は`categorical_crossentropy`を使う。  \n",
    "2値分類なら`binary_crossentropy`。その場合最終層の活性化は`sigmoid`にする。\n",
    "\n",
    "`optimizer='sgd'`は学習率が0.01固定なので、文字列指定よりも`optimizer=keras.optimizers.SGD(lr=???)`とするのが一般的。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db3d0ed-c9c1-4a83-8666-9c2a1c467121",
   "metadata": {},
   "source": [
    "### Training and evaluating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c940ae-06b5-410f-9d64-d048ae887851",
   "metadata": {},
   "source": [
    "訓練データだけでなく検証データも一緒に渡している（これはオプション）。エポックごとにlossとmetrics(ここではaccuracy)を測れる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32b8bdf1-a645-4b58-800a-fa559df06458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.7308 - accuracy: 0.7598 - val_loss: 0.4981 - val_accuracy: 0.8332\n",
      "Epoch 2/30\n",
      "1719/1719 [==============================] - 2s 961us/step - loss: 0.4856 - accuracy: 0.8311 - val_loss: 0.4491 - val_accuracy: 0.8492\n",
      "Epoch 3/30\n",
      "1719/1719 [==============================] - 2s 957us/step - loss: 0.4396 - accuracy: 0.8452 - val_loss: 0.4269 - val_accuracy: 0.8526\n",
      "Epoch 4/30\n",
      "1719/1719 [==============================] - 2s 931us/step - loss: 0.4141 - accuracy: 0.8544 - val_loss: 0.4054 - val_accuracy: 0.8612\n",
      "Epoch 5/30\n",
      "1719/1719 [==============================] - 2s 955us/step - loss: 0.3939 - accuracy: 0.8620 - val_loss: 0.3937 - val_accuracy: 0.8668\n",
      "Epoch 6/30\n",
      "1719/1719 [==============================] - 2s 954us/step - loss: 0.3791 - accuracy: 0.8662 - val_loss: 0.3706 - val_accuracy: 0.8710\n",
      "Epoch 7/30\n",
      "1719/1719 [==============================] - 2s 961us/step - loss: 0.3648 - accuracy: 0.8705 - val_loss: 0.3713 - val_accuracy: 0.8706\n",
      "Epoch 8/30\n",
      "1719/1719 [==============================] - 2s 963us/step - loss: 0.3535 - accuracy: 0.8747 - val_loss: 0.3455 - val_accuracy: 0.8798\n",
      "Epoch 9/30\n",
      "1719/1719 [==============================] - 2s 950us/step - loss: 0.3434 - accuracy: 0.8770 - val_loss: 0.3527 - val_accuracy: 0.8748\n",
      "Epoch 10/30\n",
      "1719/1719 [==============================] - 2s 966us/step - loss: 0.3335 - accuracy: 0.8818 - val_loss: 0.3516 - val_accuracy: 0.8750\n",
      "Epoch 11/30\n",
      "1719/1719 [==============================] - 2s 953us/step - loss: 0.3249 - accuracy: 0.8832 - val_loss: 0.3570 - val_accuracy: 0.8692\n",
      "Epoch 12/30\n",
      "1719/1719 [==============================] - 2s 951us/step - loss: 0.3161 - accuracy: 0.8865 - val_loss: 0.3481 - val_accuracy: 0.8746\n",
      "Epoch 13/30\n",
      "1719/1719 [==============================] - 2s 939us/step - loss: 0.3089 - accuracy: 0.8891 - val_loss: 0.3327 - val_accuracy: 0.8798\n",
      "Epoch 14/30\n",
      "1719/1719 [==============================] - 2s 943us/step - loss: 0.3024 - accuracy: 0.8916 - val_loss: 0.3287 - val_accuracy: 0.8804\n",
      "Epoch 15/30\n",
      "1719/1719 [==============================] - 2s 986us/step - loss: 0.2957 - accuracy: 0.8938 - val_loss: 0.3331 - val_accuracy: 0.8798\n",
      "Epoch 16/30\n",
      "1719/1719 [==============================] - 2s 968us/step - loss: 0.2890 - accuracy: 0.8961 - val_loss: 0.3259 - val_accuracy: 0.8870\n",
      "Epoch 17/30\n",
      "1719/1719 [==============================] - 2s 968us/step - loss: 0.2833 - accuracy: 0.8976 - val_loss: 0.3219 - val_accuracy: 0.8848\n",
      "Epoch 18/30\n",
      "1719/1719 [==============================] - 2s 967us/step - loss: 0.2773 - accuracy: 0.9001 - val_loss: 0.3038 - val_accuracy: 0.8936\n",
      "Epoch 19/30\n",
      "1719/1719 [==============================] - 2s 931us/step - loss: 0.2738 - accuracy: 0.9012 - val_loss: 0.3035 - val_accuracy: 0.8926\n",
      "Epoch 20/30\n",
      "1719/1719 [==============================] - 2s 966us/step - loss: 0.2674 - accuracy: 0.9035 - val_loss: 0.3190 - val_accuracy: 0.8850\n",
      "Epoch 21/30\n",
      "1719/1719 [==============================] - 2s 947us/step - loss: 0.2626 - accuracy: 0.9054 - val_loss: 0.3198 - val_accuracy: 0.8866\n",
      "Epoch 22/30\n",
      "1719/1719 [==============================] - 2s 923us/step - loss: 0.2575 - accuracy: 0.9071 - val_loss: 0.3024 - val_accuracy: 0.8906\n",
      "Epoch 23/30\n",
      "1719/1719 [==============================] - 2s 921us/step - loss: 0.2534 - accuracy: 0.9091 - val_loss: 0.2989 - val_accuracy: 0.8932\n",
      "Epoch 24/30\n",
      "1719/1719 [==============================] - 2s 953us/step - loss: 0.2491 - accuracy: 0.9094 - val_loss: 0.3053 - val_accuracy: 0.8868\n",
      "Epoch 25/30\n",
      "1719/1719 [==============================] - 2s 987us/step - loss: 0.2447 - accuracy: 0.9107 - val_loss: 0.2944 - val_accuracy: 0.8982\n",
      "Epoch 26/30\n",
      "1719/1719 [==============================] - 2s 980us/step - loss: 0.2407 - accuracy: 0.9129 - val_loss: 0.3187 - val_accuracy: 0.8872\n",
      "Epoch 27/30\n",
      "1719/1719 [==============================] - 2s 956us/step - loss: 0.2361 - accuracy: 0.9147 - val_loss: 0.2917 - val_accuracy: 0.8982\n",
      "Epoch 28/30\n",
      "1719/1719 [==============================] - 2s 965us/step - loss: 0.2321 - accuracy: 0.9163 - val_loss: 0.3066 - val_accuracy: 0.8904\n",
      "Epoch 29/30\n",
      "1719/1719 [==============================] - 2s 940us/step - loss: 0.2292 - accuracy: 0.9169 - val_loss: 0.2937 - val_accuracy: 0.8958\n",
      "Epoch 30/30\n",
      "1719/1719 [==============================] - 2s 939us/step - loss: 0.2258 - accuracy: 0.9175 - val_loss: 0.2958 - val_accuracy: 0.8906\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e558cb-9fd4-4877-849e-95d0ad4c4382",
   "metadata": {},
   "source": [
    "fitの出力であるHistoryをプロットする。\n",
    "\n",
    "Historyは以下の要素を含む。\n",
    "- params: トレーニングパラメータ\n",
    "- epoch: epochのリスト\n",
    "- history: epochごとのlossとmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80f33db8-8c20-444e-ba4c-a3b11733c31a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283034e3-7c61-4e76-a47f-2f70a7b25b6c",
   "metadata": {},
   "source": [
    "テストデータに対するエラーを見積もる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b9bac4b8-6fb3-4f7e-a1a6-8dc86c93810d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 771us/step - loss: 57.7798 - accuracy: 0.8566\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[57.77980041503906, 0.8565999865531921]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61bde22-48c8-469b-aba0-fb8528999b7c",
   "metadata": {},
   "source": [
    "### Using the model to make predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b95921b-af88-471c-b5db-dc26d42ab8df",
   "metadata": {},
   "source": [
    "テストデータの一部を使って予測を試す。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4423c7e-b256-4311-8668-e04942937a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 46ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new=X_test[:3]\n",
    "y_proba=model.predict(X_new)\n",
    "y_proba.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c82411f-1b1b-49d0-b1f4-c224554afc0c",
   "metadata": {},
   "source": [
    "one-hotベクトルのようになっているが、実際は各クラスの確率が出ている。  \n",
    "`np.argmax`で最大のインデックスを取得する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5cde3b0e-ecb3-4bb2-97b6-3157c241f4dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#y_pred=model.predict_classes(X_new) # deprecated\n",
    "y_pred=np.argmax(y_proba, axis=-1) \n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d9dbc626-d9a4-4043-be78-1e131740a685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ankle boot', 'Pullover', 'Trouser'], dtype='<U11')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(class_names)[y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe057c97-9701-4834-a614-9b42384f9c80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1], dtype=uint8)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_new= y_test[:3]\n",
    "y_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1897363-6381-491a-a134-6267bed12b91",
   "metadata": {},
   "source": [
    "## Building a Regression MLP Using the Sequential API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eae5841-f27c-48e0-a6ec-c882ab8073c4",
   "metadata": {},
   "source": [
    "回帰問題としてカリフォルニア住宅価格を扱う。\n",
    "\n",
    "[California Housing dataset](https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset): 1990のUSセンサス。\n",
    "\n",
    "X: 8属性\n",
    "- MedInc: median income in block group\n",
    "- HouseAge: median house age in block group\n",
    "- AveRooms: average number of rooms per household\n",
    "- AveBedrms: average number of bedrooms per household\n",
    "- Population: block group population\n",
    "- AveOccup: average number of household members\n",
    "- Latitude: block group latitude\n",
    "- Longitude: block group longitude\n",
    "\n",
    "y: 住宅価格の中央値、単位$100,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "634b70d2-df89-4a47-96c8-cf98db28812d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing=fetch_california_housing()\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target)\n",
    "X_train, X_valid, y_train, y_valid=train_test_split(X_train_full, y_train_full)\n",
    "\n",
    "scaler=StandardScaler()\n",
    "X_train=scaler.fit_transform(X_train)\n",
    "X_valid=scaler.transform(X_valid)\n",
    "X_test=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2ead8c2d-2672-44e5-b944-3b7c4cbd44d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _california_housing_dataset:\n",
      "\n",
      "California Housing dataset\n",
      "--------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 20640\n",
      "\n",
      "    :Number of Attributes: 8 numeric, predictive attributes and the target\n",
      "\n",
      "    :Attribute Information:\n",
      "        - MedInc        median income in block group\n",
      "        - HouseAge      median house age in block group\n",
      "        - AveRooms      average number of rooms per household\n",
      "        - AveBedrms     average number of bedrooms per household\n",
      "        - Population    block group population\n",
      "        - AveOccup      average number of household members\n",
      "        - Latitude      block group latitude\n",
      "        - Longitude     block group longitude\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "This dataset was obtained from the StatLib repository.\n",
      "https://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html\n",
      "\n",
      "The target variable is the median house value for California districts,\n",
      "expressed in hundreds of thousands of dollars ($100,000).\n",
      "\n",
      "This dataset was derived from the 1990 U.S. census, using one row per census\n",
      "block group. A block group is the smallest geographical unit for which the U.S.\n",
      "Census Bureau publishes sample data (a block group typically has a population\n",
      "of 600 to 3,000 people).\n",
      "\n",
      "An household is a group of people residing within a home. Since the average\n",
      "number of rooms and bedrooms in this dataset are provided per household, these\n",
      "columns may take surpinsingly large values for block groups with few households\n",
      "and many empty houses, such as vacation resorts.\n",
      "\n",
      "It can be downloaded/loaded using the\n",
      ":func:`sklearn.datasets.fetch_california_housing` function.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n",
      "      Statistics and Probability Letters, 33 (1997) 291-297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(housing.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "50082072-1a15-497c-8d3c-786a57007ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11610, 8)\n",
      "['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude']\n",
      "[1.341 1.596 2.25 ]\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(housing.feature_names)\n",
    "print(y_train[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c44b88c-41bd-410b-8f5e-76c85b386057",
   "metadata": {},
   "source": [
    "分類器と同様にSequential APIを用いる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9341f745-4284-4151-943f-d84f210d071b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d29b6f91-cdbb-4ce6-94a6-f256530aea56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.7714 - val_loss: 10.1615\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 956us/step - loss: 1.0303 - val_loss: 3.0817\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 960us/step - loss: 0.5494 - val_loss: 0.4056\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 966us/step - loss: 0.4066 - val_loss: 0.3793\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 964us/step - loss: 0.3936 - val_loss: 0.3776\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 979us/step - loss: 0.3846 - val_loss: 0.3611\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 981us/step - loss: 0.3804 - val_loss: 0.3546\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 946us/step - loss: 0.3755 - val_loss: 0.3626\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 948us/step - loss: 0.3705 - val_loss: 0.3546\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 938us/step - loss: 0.3693 - val_loss: 0.3507\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 950us/step - loss: 0.3657 - val_loss: 0.3430\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 936us/step - loss: 0.3604 - val_loss: 0.3402\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 930us/step - loss: 0.3593 - val_loss: 0.3472\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 967us/step - loss: 0.3652 - val_loss: 0.3391\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 945us/step - loss: 0.3560 - val_loss: 0.3340\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 948us/step - loss: 0.3544 - val_loss: 0.3297\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 955us/step - loss: 0.3495 - val_loss: 0.3448\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 957us/step - loss: 0.3490 - val_loss: 0.3353\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 960us/step - loss: 0.3460 - val_loss: 0.3344\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 968us/step - loss: 0.3480 - val_loss: 0.3391\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "87cf2661-0e8d-4eb1-974f-ac41aa7740a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 609us/step - loss: 0.3846\n"
     ]
    }
   ],
   "source": [
    "mse_test=model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8d424d01-117e-4cea-8b2e-4bd570ef0a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n"
     ]
    }
   ],
   "source": [
    "X_new=X_test[:3]\n",
    "y_pred=model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8cf5e2af-452a-4cc3-9329-2d7e8673d24b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3845856487751007"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a7bec5cf-7149-4d96-a5dc-0265744bea6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9691032]\n",
      " [2.848493 ]\n",
      " [2.7095976]]\n",
      "[0.894 1.375 2.952]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)\n",
    "print(y_test[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cc15bb-f192-4fb2-9748-60c84f6153d1",
   "metadata": {},
   "source": [
    "## Building Complex Models Using the Functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a164965b-8d55-453c-b62a-2c4eb907d43a",
   "metadata": {},
   "source": [
    "より複雑なネットワークを構築するにはFunctional APIを用いる。\n",
    "\n",
    "前層を関数の引数のように与えているのがFuctionalの所以。この時点ではデータは処理しておらず接続を指定しているだけ。\n",
    "\n",
    "[Input](https://www.tensorflow.org/api_docs/python/tf/keras/Input)\n",
    "\n",
    "[Concatenate](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Concatenate): 使い方が違うだけで[concatenate](https://www.tensorflow.org/api_docs/python/tf/keras/layers/concatenate)と同じ。\n",
    "\n",
    "[Model](https://www.tensorflow.org/api_docs/python/tf/keras/Model)\n",
    "\n",
    "concatの部分で入力と2層の隠れ層出力を結合している(concatなので足すのではなく繋いでいる)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "05fce635-6bf9-4865-b523-c4092a68d16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_=keras.layers.Input(shape=X_train.shape[1:])\n",
    "hidden1=keras.layers.Dense(30, activation=\"relu\")(input_)\n",
    "hidden2=keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat=keras.layers.Concatenate()([input_,hidden2])\n",
    "output=keras.layers.Dense(1)(concat)\n",
    "model=keras.models.Model(inputs=[input_], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e44b3f4a-e015-4a71-b0a0-52d039819650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 8)]          0           []                               \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 30)           270         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 30)           930         ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 38)           0           ['input_1[0][0]',                \n",
      "                                                                  'dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 1)            39          ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,239\n",
      "Trainable params: 1,239\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4abcd785-1a77-4c60-88a0-b9258ed861fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.8757 - val_loss: 0.8398\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7515 - val_loss: 0.7291\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6691 - val_loss: 0.6706\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6197 - val_loss: 0.6282\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5828 - val_loss: 0.5963\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5549 - val_loss: 0.5717\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5333 - val_loss: 0.5512\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5151 - val_loss: 0.5362\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4999 - val_loss: 0.5216\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4878 - val_loss: 0.5095\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4767 - val_loss: 0.4995\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4671 - val_loss: 0.4909\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4585 - val_loss: 0.4832\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4517 - val_loss: 0.4752\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4447 - val_loss: 0.4687\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4388 - val_loss: 0.4624\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4330 - val_loss: 0.4578\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4284 - val_loss: 0.4528\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4235 - val_loss: 0.4502\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4197 - val_loss: 0.4448\n",
      "162/162 [==============================] - 0s 646us/step - loss: 0.4357\n",
      "1/1 [==============================] - 0s 31ms/step\n"
     ]
    }
   ],
   "source": [
    "# SGDのlrを1e-3にすると計算が安定\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
    "history=model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))\n",
    "mse_test=model.evaluate(X_test,y_test)\n",
    "y_pred=model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6cbea270-7e9a-410b-909c-e1688a6a6fb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43570390343666077"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6dcf0abd-8d50-4257-8520-628f9e469a15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.1152503],\n",
       "       [1.1895642],\n",
       "       [3.3124235]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48243a6-dd28-4d66-be7c-c4907d9fa3c6",
   "metadata": {},
   "source": [
    "インプットが２つの場合を考える。\n",
    "\n",
    "カリフォルニアデータセットのうち、 インデックス0-4の特徴量（５つ）をinput_A、2-７の特徴量（６つ）をinput_Bとする。input_Bは2層MLPを通しinput_Aと結合する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "36dc61da-9a4b-46a2-80e8-271d3e50185d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A=keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B=keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden1=keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2=keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat=keras.layers.concatenate([input_A,hidden2])\n",
    "output=keras.layers.Dense(1, name = \"output\")(concat)\n",
    "model=keras.models.Model(inputs=[input_A, input_B], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "79c9114c-31b0-445d-9e30-6335eb7abe73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " deep_input (InputLayer)        [(None, 6)]          0           []                               \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 30)           210         ['deep_input[0][0]']             \n",
      "                                                                                                  \n",
      " wide_input (InputLayer)        [(None, 5)]          0           []                               \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 30)           930         ['dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 35)           0           ['wide_input[0][0]',             \n",
      "                                                                  'dense_9[0][0]']                \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 1)            36          ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,176\n",
      "Trainable params: 1,176\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f34b3b4d-70aa-4b5c-bca6-6fccc049cd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddc18d9-1e72-48ca-8136-b958a3b9333e",
   "metadata": {},
   "source": [
    "データをモデルに合わせて次のように分離。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b08e6b35-46ad-44dd-8d54-571fd279341b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_A, X_train_B = X_train[:,:5], X_train[:, 2:]\n",
    "X_valid_A, X_valid_B = X_valid[:,:5], X_valid[:, 2:]\n",
    "X_test_A, X_test_B = X_test[:,:5], X_test[:, 2:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8370ac37-1e4c-4fd6-93ed-0814e389f02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.7151 - val_loss: 0.8653\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7898 - val_loss: 0.7672\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7182 - val_loss: 0.7153\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6739 - val_loss: 0.6789\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6395 - val_loss: 0.6464\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6105 - val_loss: 0.6210\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5853 - val_loss: 0.5995\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5636 - val_loss: 0.5782\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5441 - val_loss: 0.5600\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5277 - val_loss: 0.5459\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5135 - val_loss: 0.5334\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5019 - val_loss: 0.5238\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4919 - val_loss: 0.5148\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4834 - val_loss: 0.5074\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4762 - val_loss: 0.5001\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4695 - val_loss: 0.4942\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4641 - val_loss: 0.4897\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4590 - val_loss: 0.4851\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4542 - val_loss: 0.4809\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4499 - val_loss: 0.4764\n",
      "162/162 [==============================] - 0s 690us/step - loss: 0.4661\n",
      "1/1 [==============================] - 0s 30ms/step\n"
     ]
    }
   ],
   "source": [
    "history=model.fit((X_train_A, X_train_B), y_train, epochs=20, validation_data=((X_valid_A, X_valid_B), y_valid))\n",
    "mse_test=model.evaluate((X_test_A,X_test_B),y_test)\n",
    "y_pred=model.predict((X_new_A,X_new_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233cb42a-6780-438e-9c9f-0741578f2da9",
   "metadata": {},
   "source": [
    "アウトプットが２つの場合。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bc6f61eb-95ba-416d-9afb-3a5ba0925e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A=keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B=keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden1=keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2=keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat=keras.layers.concatenate([input_A,hidden2])\n",
    "output=keras.layers.Dense(1, name = \"main_output\")(concat)\n",
    "aux_output=keras.layers.Dense(1, name = \"aux_output\")(hidden2)\n",
    "model=keras.models.Model(inputs=[input_A, input_B], outputs=[output, aux_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "adee0122-2294-4031-805d-d3f1938da12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " deep_input (InputLayer)        [(None, 6)]          0           []                               \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 30)           210         ['deep_input[0][0]']             \n",
      "                                                                                                  \n",
      " wide_input (InputLayer)        [(None, 5)]          0           []                               \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 30)           930         ['dense_10[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 35)           0           ['wide_input[0][0]',             \n",
      "                                                                  'dense_11[0][0]']               \n",
      "                                                                                                  \n",
      " main_output (Dense)            (None, 1)            36          ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " aux_output (Dense)             (None, 1)            31          ['dense_11[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,207\n",
      "Trainable params: 1,207\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee52e33-d272-4d01-8fe8-07915fa7c44e",
   "metadata": {},
   "source": [
    "アウトプットごとに損失関数が必要。コンパイル時にlossのリストを渡す（１つしか渡さなかった場合全てのアウトプットに対して同じ損失を用いることになる）。デフォルトではそれぞれのlossを計算し和をとる。それぞれに重みを持たせることができるのでmain_outputにより大きな重みづけをする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a8e29e1a-72e9-4e1e-85e4-4669270b0b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=[\"mse\", \"mse\"], loss_weights=[0.9, 0.1], optimizer=keras.optimizers.SGD(learning_rate=1e-3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f92caf1-8c95-42a8-b4ca-60a6043f05fd",
   "metadata": {},
   "source": [
    "訓練時にはアウトプットごとにラベルが必要だが、ここでは同じラベルをタプルで与える。実用上は何を学習させたいかによる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7bf6680f-73bc-4273-8d55-17d45e1f296a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 2.6884 - main_output_loss: 2.3355 - aux_output_loss: 5.8648 - val_loss: 1.4544 - val_main_output_loss: 1.0946 - val_aux_output_loss: 4.6928\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.2771 - main_output_loss: 1.0018 - aux_output_loss: 3.7545 - val_loss: 1.0467 - val_main_output_loss: 0.8322 - val_aux_output_loss: 2.9775\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.9297 - main_output_loss: 0.7515 - aux_output_loss: 2.5338 - val_loss: 0.8755 - val_main_output_loss: 0.7354 - val_aux_output_loss: 2.1365\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.8086 - main_output_loss: 0.6811 - aux_output_loss: 1.9560 - val_loss: 0.7863 - val_main_output_loss: 0.6815 - val_aux_output_loss: 1.7295\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.7399 - main_output_loss: 0.6374 - aux_output_loss: 1.6628 - val_loss: 0.7320 - val_main_output_loss: 0.6449 - val_aux_output_loss: 1.5162\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.6951 - main_output_loss: 0.6065 - aux_output_loss: 1.4927 - val_loss: 0.6934 - val_main_output_loss: 0.6148 - val_aux_output_loss: 1.4009\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.6614 - main_output_loss: 0.5804 - aux_output_loss: 1.3907 - val_loss: 0.6646 - val_main_output_loss: 0.5912 - val_aux_output_loss: 1.3258\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.6344 - main_output_loss: 0.5585 - aux_output_loss: 1.3179 - val_loss: 0.6419 - val_main_output_loss: 0.5718 - val_aux_output_loss: 1.2724\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.6121 - main_output_loss: 0.5400 - aux_output_loss: 1.2616 - val_loss: 0.6234 - val_main_output_loss: 0.5558 - val_aux_output_loss: 1.2324\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5932 - main_output_loss: 0.5234 - aux_output_loss: 1.2212 - val_loss: 0.6061 - val_main_output_loss: 0.5406 - val_aux_output_loss: 1.1957\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5772 - main_output_loss: 0.5098 - aux_output_loss: 1.1841 - val_loss: 0.5917 - val_main_output_loss: 0.5279 - val_aux_output_loss: 1.1660\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5630 - main_output_loss: 0.4975 - aux_output_loss: 1.1526 - val_loss: 0.5806 - val_main_output_loss: 0.5184 - val_aux_output_loss: 1.1402\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5513 - main_output_loss: 0.4875 - aux_output_loss: 1.1253 - val_loss: 0.5705 - val_main_output_loss: 0.5098 - val_aux_output_loss: 1.1170\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5407 - main_output_loss: 0.4784 - aux_output_loss: 1.1013 - val_loss: 0.5619 - val_main_output_loss: 0.5029 - val_aux_output_loss: 1.0936\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5320 - main_output_loss: 0.4713 - aux_output_loss: 1.0788 - val_loss: 0.5533 - val_main_output_loss: 0.4955 - val_aux_output_loss: 1.0731\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5253 - main_output_loss: 0.4663 - aux_output_loss: 1.0564 - val_loss: 0.5464 - val_main_output_loss: 0.4900 - val_aux_output_loss: 1.0538\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5182 - main_output_loss: 0.4605 - aux_output_loss: 1.0378 - val_loss: 0.5402 - val_main_output_loss: 0.4853 - val_aux_output_loss: 1.0351\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5122 - main_output_loss: 0.4559 - aux_output_loss: 1.0184 - val_loss: 0.5351 - val_main_output_loss: 0.4815 - val_aux_output_loss: 1.0172\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5069 - main_output_loss: 0.4521 - aux_output_loss: 1.0005 - val_loss: 0.5299 - val_main_output_loss: 0.4778 - val_aux_output_loss: 0.9993\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5019 - main_output_loss: 0.4485 - aux_output_loss: 0.9828 - val_loss: 0.5255 - val_main_output_loss: 0.4746 - val_aux_output_loss: 0.9830\n"
     ]
    }
   ],
   "source": [
    "history=model.fit((X_train_A, X_train_B), [y_train, y_train], epochs=20, validation_data=((X_valid_A, X_valid_B), (y_valid, y_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "14acfefc-8743-474b-a579-1ff6357440e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 882us/step - loss: 0.5073 - main_output_loss: 0.4526 - aux_output_loss: 0.9992\n"
     ]
    }
   ],
   "source": [
    "total_loss, main_loss, aux_loss=model.evaluate((X_test_A,X_test_B),(y_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "676e6d05-81d0-4dee-a92f-a0ea4f6f848f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa55827a3b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 33ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_main, y_pred_aux=model.predict((X_new_A,X_new_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c2a86864-dad6-4dbc-8eb2-b7ac3b22d4aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.381964  ]\n",
      " [0.89944094]\n",
      " [3.301559  ]]\n",
      "[[1.6999665]\n",
      " [1.5514565]\n",
      " [1.9337424]]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred_main)\n",
    "print(y_pred_aux)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a66fbb6-b7f9-4186-a814-07a585a760a5",
   "metadata": {},
   "source": [
    "## Using the Subclassing API to Build Dynamic Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f209e49c-d6d4-4875-a083-58e0ca1b1996",
   "metadata": {},
   "source": [
    "こういう時にSubclassing APIを用いる。\n",
    "- ダイナミックな振る舞い: loops, varying shapes, conditional branch\n",
    "- imperative（命令型） programming (<==>declarative:宣言型)\n",
    "\n",
    "コンストラクタに必要な層を記述し、`call`メソッドにネットワークを書く。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "18401be7-7e95-4b35-aa55-8e47e7ffc5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeepModel(keras.Model):\n",
    "    def __init__(self, units=30, activation='relu', **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1 = keras.layers.Dense(units, activation=activation)\n",
    "        self.hidden2 = keras.layers.Dense(units, activation=activation)\n",
    "        self.main_output=keras.layers.Dense(1)\n",
    "        self.aux_output=keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        input_A, input_B = inputs\n",
    "        hidden1 = self.hidden1(input_B)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat= keras.layers.concatenate([input_A, hidden2])\n",
    "        main_output=self.main_output(concat)\n",
    "        aux_output=self.aux_output(hidden2)\n",
    "        return main_output, aux_output\n",
    "\n",
    "model = WideAndDeepModel(30, activation='relu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "59b8cc69-8a3c-4f2a-aefa-353183999ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 2.8622 - output_1_loss: 2.7261 - output_2_loss: 4.0875 - val_loss: 1.7130 - val_output_1_loss: 1.5640 - val_output_2_loss: 3.0534\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.0804 - output_1_loss: 0.9221 - output_2_loss: 2.5049 - val_loss: 0.9339 - val_output_1_loss: 0.7941 - val_output_2_loss: 2.1919\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.8478 - output_1_loss: 0.7316 - output_2_loss: 1.8934 - val_loss: 0.7892 - val_output_1_loss: 0.6755 - val_output_2_loss: 1.8122\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7559 - output_1_loss: 0.6633 - output_2_loss: 1.5892 - val_loss: 0.7280 - val_output_1_loss: 0.6281 - val_output_2_loss: 1.6276\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.7045 - output_1_loss: 0.6237 - output_2_loss: 1.4311 - val_loss: 0.6855 - val_output_1_loss: 0.5938 - val_output_2_loss: 1.5103\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.6684 - output_1_loss: 0.5936 - output_2_loss: 1.3417 - val_loss: 0.6459 - val_output_1_loss: 0.5616 - val_output_2_loss: 1.4043\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.6416 - output_1_loss: 0.5710 - output_2_loss: 1.2770 - val_loss: 0.6209 - val_output_1_loss: 0.5418 - val_output_2_loss: 1.3322\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.6188 - output_1_loss: 0.5511 - output_2_loss: 1.2284 - val_loss: 0.5981 - val_output_1_loss: 0.5238 - val_output_2_loss: 1.2670\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.6001 - output_1_loss: 0.5346 - output_2_loss: 1.1890 - val_loss: 0.5797 - val_output_1_loss: 0.5096 - val_output_2_loss: 1.2102\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5839 - output_1_loss: 0.5207 - output_2_loss: 1.1528 - val_loss: 0.5723 - val_output_1_loss: 0.5059 - val_output_2_loss: 1.1697\n",
      "162/162 [==============================] - 0s 855us/step - loss: 0.6262 - output_1_loss: 0.5482 - output_2_loss: 1.3281\n",
      "1/1 [==============================] - 0s 35ms/step\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mse', loss_weights=[0.9,0.1], optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
    "history=model.fit((X_train_A, X_train_B), (y_train, y_train), epochs=10,\n",
    "                  validation_data=((X_valid_A, X_valid_B),(y_valid, y_valid)))\n",
    "total_loss, main_loss, aux_loss= model.evaluate((X_test_A, X_test_B),(y_test, y_test))\n",
    "y_pred_main, y_pred_aux= model.predict((X_new_A, X_new_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cb4284-8ca3-4747-8287-e31be6d1aaca",
   "metadata": {},
   "source": [
    "## Saving and Restoring a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4568a318-5aff-4113-b066-95a5f844609e",
   "metadata": {},
   "source": [
    "動作確認のため簡単なモデルを作成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "17348f8a-0df5-4e1f-8787-2d7b14533297",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ac44287a-dda8-48f1-9767-2733b1686047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.3774 - val_loss: 0.5655\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 971us/step - loss: 0.4676 - val_loss: 0.4645\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 964us/step - loss: 0.4225 - val_loss: 0.4441\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 964us/step - loss: 0.4090 - val_loss: 0.4291\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 958us/step - loss: 0.3993 - val_loss: 0.4211\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 963us/step - loss: 0.3918 - val_loss: 0.4217\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 966us/step - loss: 0.3891 - val_loss: 0.4119\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 979us/step - loss: 0.3849 - val_loss: 0.4064\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 985us/step - loss: 0.3795 - val_loss: 0.4052\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 964us/step - loss: 0.3786 - val_loss: 0.4016\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 977us/step - loss: 0.3737 - val_loss: 0.3942\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 992us/step - loss: 0.3728 - val_loss: 0.3923\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 986us/step - loss: 0.3683 - val_loss: 0.3939\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 976us/step - loss: 0.3670 - val_loss: 0.3877\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 969us/step - loss: 0.3652 - val_loss: 0.4051\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 984us/step - loss: 0.3640 - val_loss: 0.3898\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 977us/step - loss: 0.3598 - val_loss: 0.3804\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 986us/step - loss: 0.3583 - val_loss: 0.3843\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 995us/step - loss: 0.3554 - val_loss: 0.3794\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 983us/step - loss: 0.3545 - val_loss: 0.3850\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d35f328c-d486-4f9f-975c-56006b9b7206",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a2be0e1f-b1fb-441d-8ead-d7c9f6cf6168",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c7a4ac64-e92b-47dc-bfc9-d9aa60596abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 657us/step - loss: 0.3954\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3953877389431"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3720d410-bbd3-4edf-a3fc-26e98d9408bc",
   "metadata": {},
   "source": [
    "## Using Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e3c4ab25-2158-416b-a750-18e3ee944848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 0s 807us/step - loss: 0.3535\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 0s 802us/step - loss: 0.3554\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 0s 791us/step - loss: 0.3501\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 0s 793us/step - loss: 0.3495\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 0s 792us/step - loss: 0.3476\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 0s 792us/step - loss: 0.3495\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 0s 798us/step - loss: 0.3461\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 0s 788us/step - loss: 0.3470\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 0s 784us/step - loss: 0.3490\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 0s 790us/step - loss: 0.3412\n"
     ]
    }
   ],
   "source": [
    "checkpoint_cb=keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\")\n",
    "history=model.fit(X_train, y_train, epochs=10, callbacks=[checkpoint_cb])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f29f11b-68de-409f-8bd1-6b27f330caa2",
   "metadata": {},
   "source": [
    "検証データを使っている場合は`save_best_only`で最も性能の良かったモデルのみ保存できる。\n",
    "保存したモデルをリストアすると、性能の良かったエポックのモデルを再現できる。\n",
    "\n",
    "これはアーリーストッピングとして使うことができる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ce75af87-eb0f-4b52-a5a0-287f62519170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3435 - val_loss: 0.3990\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 0s 992us/step - loss: 0.3406 - val_loss: 0.3628\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 0s 983us/step - loss: 0.3444 - val_loss: 0.3660\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 0s 992us/step - loss: 0.3363 - val_loss: 0.3657\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3420 - val_loss: 0.3607\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 0s 985us/step - loss: 0.3417 - val_loss: 0.3604\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3340 - val_loss: 0.3550\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 0s 987us/step - loss: 0.3421 - val_loss: 0.3575\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 0s 997us/step - loss: 0.3316 - val_loss: 0.3641\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 0s 987us/step - loss: 0.3344 - val_loss: 0.3606\n"
     ]
    }
   ],
   "source": [
    "checkpoint_cb=keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\", save_best_only=True)\n",
    "history=model.fit(X_train, y_train, epochs=10, \n",
    "                  validation_data=(X_valid, y_valid),\n",
    "                  callbacks=[checkpoint_cb])\n",
    "# roll back to best model\n",
    "model = keras.models.load_model(\"my_keras_model.h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8106519a-71ca-46a0-9bb2-9c96ad3d92ec",
   "metadata": {},
   "source": [
    "EarlyStopping専用のコールバックも準備されている。\n",
    "\n",
    "[EarlyStopping](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping)：検証データの改善がなくなったら訓練を終了する。\n",
    "\n",
    "チェックポイントの保存と組み合わせて使用することもできる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "312d5451-bb10-451a-ad6e-d8f55bcfebe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.callbacks.EarlyStopping object at 0x7fa5dcb989a0>\n"
     ]
    }
   ],
   "source": [
    "print(early_stopping_cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "81788167-5912-400b-9fc0-50695cc3f079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3415 - val_loss: 0.3568\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 0s 992us/step - loss: 0.3336 - val_loss: 0.3592\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 990us/step - loss: 0.3309 - val_loss: 0.3632\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 0s 992us/step - loss: 0.3318 - val_loss: 0.3577\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 977us/step - loss: 0.3340 - val_loss: 0.3599\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3288 - val_loss: 0.3621\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3295 - val_loss: 0.3519\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 0s 985us/step - loss: 0.3269 - val_loss: 0.3525\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 0s 991us/step - loss: 0.3253 - val_loss: 0.3553\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 0s 979us/step - loss: 0.3265 - val_loss: 0.3545\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 0s 984us/step - loss: 0.3256 - val_loss: 0.3843\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 993us/step - loss: 0.3298 - val_loss: 0.3492\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 0s 974us/step - loss: 0.3234 - val_loss: 0.3540\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 0s 988us/step - loss: 0.3225 - val_loss: 0.3496\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3244 - val_loss: 0.3459\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 0s 972us/step - loss: 0.3211 - val_loss: 0.3530\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 0s 983us/step - loss: 0.3296 - val_loss: 0.3476\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 0s 991us/step - loss: 0.3210 - val_loss: 0.3448\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 0s 985us/step - loss: 0.3179 - val_loss: 0.3532\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 0s 985us/step - loss: 0.3240 - val_loss: 0.3452\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 0s 977us/step - loss: 0.3206 - val_loss: 0.3462\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3205 - val_loss: 0.3418\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3169 - val_loss: 0.4336\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3199 - val_loss: 0.3417\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3165 - val_loss: 0.3489\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3204 - val_loss: 0.3427\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 0s 994us/step - loss: 0.3151 - val_loss: 0.3709\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3136 - val_loss: 0.3445\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 0s 995us/step - loss: 0.3219 - val_loss: 0.3395\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 0s 991us/step - loss: 0.3235 - val_loss: 0.3489\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 0s 972us/step - loss: 0.3225 - val_loss: 0.3417\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 0s 988us/step - loss: 0.3118 - val_loss: 0.3462\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 0s 981us/step - loss: 0.3144 - val_loss: 0.3383\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 0s 971us/step - loss: 0.3148 - val_loss: 0.3392\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 0s 990us/step - loss: 0.3112 - val_loss: 0.3399\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 0s 997us/step - loss: 0.3134 - val_loss: 0.3473\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3121 - val_loss: 0.3626\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 0s 972us/step - loss: 0.3136 - val_loss: 0.3411\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 0s 982us/step - loss: 0.3140 - val_loss: 0.3400\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 0s 972us/step - loss: 0.3140 - val_loss: 0.3446\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3101 - val_loss: 0.3402\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3107 - val_loss: 0.3372\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 0s 998us/step - loss: 0.3355 - val_loss: 0.3364\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 0s 987us/step - loss: 0.3113 - val_loss: 0.3457\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 0s 976us/step - loss: 0.3135 - val_loss: 0.3541\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 0s 970us/step - loss: 0.3090 - val_loss: 0.3365\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 0s 967us/step - loss: 0.3120 - val_loss: 0.3422\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 0s 974us/step - loss: 0.3163 - val_loss: 0.3484\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 0s 964us/step - loss: 0.3089 - val_loss: 0.3405\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 0s 984us/step - loss: 0.3110 - val_loss: 0.3375\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 0s 995us/step - loss: 0.3191 - val_loss: 0.4349\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 0s 991us/step - loss: 0.3135 - val_loss: 0.3390\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 0s 979us/step - loss: 0.3089 - val_loss: 0.3404\n"
     ]
    }
   ],
   "source": [
    "early_stopping_cb=keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "history=model.fit(X_train, y_train, epochs=100, \n",
    "                  validation_data=(X_valid, y_valid),\n",
    "                  callbacks=[checkpoint_cb, early_stopping_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a7b425-be41-4138-ad7f-b7950bf2d04d",
   "metadata": {},
   "source": [
    "カスタムコールバック。\n",
    "\n",
    "[Callback](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/Callback)\n",
    "\n",
    "訓練中の検証損失と訓練損失の比を表示する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5c5da3ab-fc72-4be7-bc58-e4c32d4e6841",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintValTrainRatioCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        print(\"\\nval/train: {:.2f}\".format(logs[\"val_loss\"]/logs[\"loss\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c7c3ea25-b325-4d03-9e2a-a9dffe3e80fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "328/363 [==========================>...] - ETA: 0s - loss: 0.3139\n",
      "val/train: 1.09\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3108 - val_loss: 0.3388\n",
      "Epoch 2/100\n",
      "319/363 [=========================>....] - ETA: 0s - loss: 0.3122\n",
      "val/train: 1.59\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3087 - val_loss: 0.4896\n",
      "Epoch 3/100\n",
      "324/363 [=========================>....] - ETA: 0s - loss: 0.3150\n",
      "val/train: 1.07\n",
      "363/363 [==============================] - 0s 995us/step - loss: 0.3154 - val_loss: 0.3389\n",
      "Epoch 4/100\n",
      "330/363 [==========================>...] - ETA: 0s - loss: 0.3100\n",
      "val/train: 1.10\n",
      "363/363 [==============================] - 0s 976us/step - loss: 0.3087 - val_loss: 0.3403\n",
      "Epoch 5/100\n",
      "320/363 [=========================>....] - ETA: 0s - loss: 0.3110\n",
      "val/train: 1.09\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3100 - val_loss: 0.3388\n",
      "Epoch 6/100\n",
      "321/363 [=========================>....] - ETA: 0s - loss: 0.3033\n",
      "val/train: 1.08\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3103 - val_loss: 0.3336\n",
      "Epoch 7/100\n",
      "325/363 [=========================>....] - ETA: 0s - loss: 0.3172\n",
      "val/train: 1.07\n",
      "363/363 [==============================] - 0s 991us/step - loss: 0.3157 - val_loss: 0.3392\n",
      "Epoch 8/100\n",
      "326/363 [=========================>....] - ETA: 0s - loss: 0.3085\n",
      "val/train: 1.10\n",
      "363/363 [==============================] - 0s 983us/step - loss: 0.3071 - val_loss: 0.3369\n",
      "Epoch 9/100\n",
      "330/363 [==========================>...] - ETA: 0s - loss: 0.3220\n",
      "val/train: 1.06\n",
      "363/363 [==============================] - 0s 977us/step - loss: 0.3205 - val_loss: 0.3395\n",
      "Epoch 10/100\n",
      "333/363 [==========================>...] - ETA: 0s - loss: 0.3092\n",
      "val/train: 1.10\n",
      "363/363 [==============================] - 0s 977us/step - loss: 0.3097 - val_loss: 0.3393\n",
      "Epoch 11/100\n",
      "331/363 [==========================>...] - ETA: 0s - loss: 0.3076\n",
      "val/train: 1.08\n",
      "363/363 [==============================] - 0s 978us/step - loss: 0.3099 - val_loss: 0.3357\n",
      "Epoch 12/100\n",
      "332/363 [==========================>...] - ETA: 0s - loss: 0.3081\n",
      "val/train: 1.09\n",
      "363/363 [==============================] - 0s 981us/step - loss: 0.3070 - val_loss: 0.3334\n",
      "Epoch 13/100\n",
      "331/363 [==========================>...] - ETA: 0s - loss: 0.3075\n",
      "val/train: 1.09\n",
      "363/363 [==============================] - 0s 982us/step - loss: 0.3075 - val_loss: 0.3338\n",
      "Epoch 14/100\n",
      "328/363 [==========================>...] - ETA: 0s - loss: 0.3088\n",
      "val/train: 1.11\n",
      "363/363 [==============================] - 0s 990us/step - loss: 0.3073 - val_loss: 0.3417\n",
      "Epoch 15/100\n",
      "319/363 [=========================>....] - ETA: 0s - loss: 0.3065\n",
      "val/train: 1.11\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3068 - val_loss: 0.3413\n",
      "Epoch 16/100\n",
      "332/363 [==========================>...] - ETA: 0s - loss: 0.3048\n",
      "val/train: 1.10\n",
      "363/363 [==============================] - 0s 973us/step - loss: 0.3063 - val_loss: 0.3354\n",
      "Epoch 17/100\n",
      "330/363 [==========================>...] - ETA: 0s - loss: 0.3096\n",
      "val/train: 1.09\n",
      "363/363 [==============================] - 0s 982us/step - loss: 0.3069 - val_loss: 0.3343\n",
      "Epoch 18/100\n",
      "335/363 [==========================>...] - ETA: 0s - loss: 0.3117\n",
      "val/train: 1.10\n",
      "363/363 [==============================] - 0s 968us/step - loss: 0.3066 - val_loss: 0.3363\n",
      "Epoch 19/100\n",
      "337/363 [==========================>...] - ETA: 0s - loss: 0.3102\n",
      "val/train: 1.08\n",
      "363/363 [==============================] - 0s 969us/step - loss: 0.3076 - val_loss: 0.3319\n",
      "Epoch 20/100\n",
      "318/363 [=========================>....] - ETA: 0s - loss: 0.3037\n",
      "val/train: 1.10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3049 - val_loss: 0.3359\n",
      "Epoch 21/100\n",
      "325/363 [=========================>....] - ETA: 0s - loss: 0.3055\n",
      "val/train: 1.09\n",
      "363/363 [==============================] - 0s 993us/step - loss: 0.3049 - val_loss: 0.3333\n",
      "Epoch 22/100\n",
      "327/363 [==========================>...] - ETA: 0s - loss: 0.3052\n",
      "val/train: 1.09\n",
      "363/363 [==============================] - 0s 988us/step - loss: 0.3045 - val_loss: 0.3333\n",
      "Epoch 23/100\n",
      "319/363 [=========================>....] - ETA: 0s - loss: 0.3013\n",
      "val/train: 1.09\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3049 - val_loss: 0.3320\n",
      "Epoch 24/100\n",
      "313/363 [========================>.....] - ETA: 0s - loss: 0.3058\n",
      "val/train: 1.10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3183 - val_loss: 0.3487\n",
      "Epoch 25/100\n",
      "323/363 [=========================>....] - ETA: 0s - loss: 0.3127\n",
      "val/train: 1.07\n",
      "363/363 [==============================] - 0s 999us/step - loss: 0.3123 - val_loss: 0.3349\n",
      "Epoch 26/100\n",
      "325/363 [=========================>....] - ETA: 0s - loss: 0.3065\n",
      "val/train: 1.11\n",
      "363/363 [==============================] - 0s 996us/step - loss: 0.3056 - val_loss: 0.3379\n",
      "Epoch 27/100\n",
      "316/363 [=========================>....] - ETA: 0s - loss: 0.3074\n",
      "val/train: 1.09\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3052 - val_loss: 0.3324\n",
      "Epoch 28/100\n",
      "313/363 [========================>.....] - ETA: 0s - loss: 0.3074\n",
      "val/train: 1.07\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3099 - val_loss: 0.3331\n",
      "Epoch 29/100\n",
      "326/363 [=========================>....] - ETA: 0s - loss: 0.3058\n",
      "val/train: 1.12\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3055 - val_loss: 0.3407\n"
     ]
    }
   ],
   "source": [
    "custom_cb= PrintValTrainRatioCallback()\n",
    "history=model.fit(X_train, y_train, epochs=100, \n",
    "                  validation_data=(X_valid, y_valid),\n",
    "                  callbacks=[custom_cb, early_stopping_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d73e96-6d70-498c-b072-9a2b6a359fa9",
   "metadata": {},
   "source": [
    "## Using TensorBoard for Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fe3dd4fa-788d-4a84-aa53-d6d7f2eedf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id=time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir=get_run_logdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3e7f2f5f-06e6-46d6-ac5a-6bdb2d55a01b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3180 - val_loss: 0.3015\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 0s 960us/step - loss: 0.3177 - val_loss: 0.2932\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 0s 955us/step - loss: 0.3168 - val_loss: 0.2976\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 0s 979us/step - loss: 0.3153 - val_loss: 0.3020\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 0s 971us/step - loss: 0.3137 - val_loss: 0.2975\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 0s 969us/step - loss: 0.3138 - val_loss: 0.2970\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 0s 948us/step - loss: 0.3128 - val_loss: 0.3027\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 0s 955us/step - loss: 0.3126 - val_loss: 0.2939\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 0s 942us/step - loss: 0.3158 - val_loss: 0.3050\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 0s 954us/step - loss: 0.3129 - val_loss: 0.2906\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 0s 953us/step - loss: 0.3119 - val_loss: 0.3167\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 0s 935us/step - loss: 0.3128 - val_loss: 0.2967\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 0s 944us/step - loss: 0.3104 - val_loss: 0.2973\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 0s 936us/step - loss: 0.3121 - val_loss: 0.3017\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 0s 952us/step - loss: 0.3117 - val_loss: 0.3005\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 0s 939us/step - loss: 0.3118 - val_loss: 0.2936\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 0s 941us/step - loss: 0.3104 - val_loss: 0.2994\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 0s 942us/step - loss: 0.3099 - val_loss: 0.2980\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 0s 956us/step - loss: 0.3089 - val_loss: 0.3022\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 0s 959us/step - loss: 0.3086 - val_loss: 0.2962\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 0s 940us/step - loss: 0.3104 - val_loss: 0.3185\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 0s 951us/step - loss: 0.3100 - val_loss: 0.3022\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 0s 955us/step - loss: 0.3085 - val_loss: 0.3017\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 0s 951us/step - loss: 0.3098 - val_loss: 0.2932\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 0s 955us/step - loss: 0.3084 - val_loss: 0.2898\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 0s 951us/step - loss: 0.3092 - val_loss: 0.2995\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 0s 957us/step - loss: 0.3092 - val_loss: 0.2924\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 0s 955us/step - loss: 0.3063 - val_loss: 0.2992\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 0s 977us/step - loss: 0.3070 - val_loss: 0.3056\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 0s 963us/step - loss: 0.3089 - val_loss: 0.3059\n"
     ]
    }
   ],
   "source": [
    "tensorboard_cb=keras.callbacks.TensorBoard(run_logdir)\n",
    "history=model.fit(X_train, y_train, epochs=30,\n",
    "                  validation_data=(X_valid, y_valid),\n",
    "                  callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "10ab4fb4-1c64-4897-a262-069bfa2ca5d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Could not find `tensorboard`. Please ensure that your PATH\n",
       "contains an executable `tensorboard` program, or explicitly specify\n",
       "the path to a TensorBoard binary by setting the `TENSORBOARD_BINARY`\n",
       "environment variable."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./my_logs --port=6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "624d20fa-11be-4f7d-a1f4-61112fdb2133",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorboard` not found.\n"
     ]
    }
   ],
   "source": [
    "%tensorboard --logdir=./my_logs --port=6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8d22dafc-b064-4136-8660-5996544fce70",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_logdir=get_run_logdir()\n",
    "writer=tf.summary.create_file_writer(test_logdir)\n",
    "with writer.as_default():\n",
    "    for step in range(1, 1000 + 1):\n",
    "        tf.summary.scalar('my_scaler', np.sin(step/10), step = step)\n",
    "        data=(np.random.randn(100)+2) * step/100\n",
    "        tf.summary.histogram('my_hist', data, buckets =50, step = step)\n",
    "        images=np.random.rand(2,32,32,3)\n",
    "        tf.summary.image('my_images', images * step / 1000, step = step)\n",
    "        texts=[\"The step is \" + str(step), \"Its square is \" + str(step**2)]\n",
    "        tf.summary.text('my_text', texts, step = step)\n",
    "        sine_wave=tf.math.sin(tf.range(12000)/48000 *2*np.pi*step)\n",
    "        audio=tf.reshape(tf.cast(sine_wave, tf.float32), [1, -1,1])\n",
    "        tf.summary.audio('my_audio', audio, sample_rate=48000, step=step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a95e045-191d-4348-bedd-c66f14e3e801",
   "metadata": {},
   "source": [
    "# Fine-Tuning Neural Network Hyperparameters\n",
    "ハイパーパラメータ探索のためにsklearnのGridSearchやRandomizedSearchを使いたい。そのような場合、Kerasのモデルをラップしてsklearnのモデルとして扱えるようにする。\n",
    "\n",
    "まずKerasのモデルを作りコンパイルする関数を作る。引数にハイパーパラメータを与える。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "428fcec4-7816-46f0-ab37-4648ec4806f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape = [8]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation='relu'))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimizer=keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    model.compile(loss='mse', optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e7ade0-ca7c-4a85-81c4-999ac11ff078",
   "metadata": {},
   "source": [
    "ラッパークラス。\n",
    "\n",
    "[KerasRegressor](https://keras.io/ja/scikit-learn-api/):sklearnのregressorインターフェースを実装。\n",
    "\n",
    "ただこれを使うとDeprecationWarningが出て代わりに[Sci-Keras](https://github.com/adriangb/scikeras)を使うよう促される。[移行のための資料](https://www.adriangb.com/scikeras/stable/migration.html)。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0b33687-103c-4d45-9fd3-b4c3fbb58250",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1674/1371180924.py:1: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  keras_reg=keras.wrappers.scikit_learn.KerasRegressor(build_model)\n"
     ]
    }
   ],
   "source": [
    "keras_reg=keras.wrappers.scikit_learn.KerasRegressor(build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b825e92f-df24-4100-9ca2-cd63a85071ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scikeras.wrappers import KerasRegressor\n",
    "keras_reg=KerasRegressor(build_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7198202f-2cc5-4239-880c-1d28be5b574f",
   "metadata": {},
   "source": [
    "表面的にはsklearnのモデルとして振る舞うが内部はkerasのモデルになっている。kwargs経由で引数が渡されているっぽい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b7b5d41-7b7a-46c0-8201-e31fd99a50bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "  1/363 [..............................] - ETA: 53s - loss: 11.0541"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tuffy/venvs/.tf/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - 1s 1ms/step - loss: 1.3768 - val_loss: 0.7167\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 0s 992us/step - loss: 0.7990 - val_loss: 0.8212\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 985us/step - loss: 0.8758 - val_loss: 0.5496\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5512 - val_loss: 0.4930\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5046 - val_loss: 0.4774\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4886 - val_loss: 0.4684\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4775 - val_loss: 0.4599\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 0s 994us/step - loss: 0.4688 - val_loss: 0.4501\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4614 - val_loss: 0.4451\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 0s 993us/step - loss: 0.4552 - val_loss: 0.4409\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4506 - val_loss: 0.4351\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4466 - val_loss: 0.4330\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4432 - val_loss: 0.4303\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4396 - val_loss: 0.4271\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4366 - val_loss: 0.4235\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4336 - val_loss: 0.4210\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4303 - val_loss: 0.4187\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4277 - val_loss: 0.4145\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4251 - val_loss: 0.4133\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4229 - val_loss: 0.4107\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4203 - val_loss: 0.4077\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 0s 995us/step - loss: 0.4179 - val_loss: 0.4073\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 0s 977us/step - loss: 0.4161 - val_loss: 0.4042\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 0s 976us/step - loss: 0.4139 - val_loss: 0.4024\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 0s 998us/step - loss: 0.4116 - val_loss: 0.4000\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4096 - val_loss: 0.4000\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4076 - val_loss: 0.3999\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4057 - val_loss: 0.3968\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4042 - val_loss: 0.3933\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4017 - val_loss: 0.3930\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4000 - val_loss: 0.3903\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3985 - val_loss: 0.3900\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 0s 988us/step - loss: 0.3963 - val_loss: 0.3876\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 0s 996us/step - loss: 0.3944 - val_loss: 0.3862\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3926 - val_loss: 0.3839\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 0s 993us/step - loss: 0.3911 - val_loss: 0.3830\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 0s 980us/step - loss: 0.3893 - val_loss: 0.3815\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 0s 995us/step - loss: 0.3873 - val_loss: 0.3828\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 0s 1000us/step - loss: 0.3866 - val_loss: 0.3793\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 0s 996us/step - loss: 0.3852 - val_loss: 0.3795\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3831 - val_loss: 0.3786\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 0s 987us/step - loss: 0.3820 - val_loss: 0.3763\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 0s 978us/step - loss: 0.3823 - val_loss: 0.3758\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 0s 995us/step - loss: 0.3790 - val_loss: 0.3752\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 0s 997us/step - loss: 0.3782 - val_loss: 0.3760\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 0s 984us/step - loss: 0.3770 - val_loss: 0.3727\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 0s 993us/step - loss: 0.3761 - val_loss: 0.3724\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 0s 999us/step - loss: 0.3748 - val_loss: 0.3712\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3743 - val_loss: 0.3698\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3742 - val_loss: 0.3691\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 0s 988us/step - loss: 0.3724 - val_loss: 0.3705\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 0s 994us/step - loss: 0.3712 - val_loss: 0.3685\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3697 - val_loss: 0.3686\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 0s 999us/step - loss: 0.3684 - val_loss: 0.3670\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 0s 987us/step - loss: 0.3674 - val_loss: 0.3661\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 0s 996us/step - loss: 0.3665 - val_loss: 0.3656\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3648 - val_loss: 0.3675\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3644 - val_loss: 0.3662\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3638 - val_loss: 0.3642\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 0s 990us/step - loss: 0.3632 - val_loss: 0.3636\n",
      "Epoch 61/100\n",
      "363/363 [==============================] - 0s 989us/step - loss: 0.3622 - val_loss: 0.3628\n",
      "Epoch 62/100\n",
      "363/363 [==============================] - 0s 988us/step - loss: 0.3609 - val_loss: 0.3611\n",
      "Epoch 63/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3607 - val_loss: 0.3606\n",
      "Epoch 64/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3600 - val_loss: 0.3605\n",
      "Epoch 65/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3592 - val_loss: 0.3591\n",
      "Epoch 66/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3579 - val_loss: 0.3641\n",
      "Epoch 67/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3580 - val_loss: 0.3588\n",
      "Epoch 68/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3565 - val_loss: 0.3579\n",
      "Epoch 69/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3560 - val_loss: 0.3576\n",
      "Epoch 70/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3574 - val_loss: 0.3591\n",
      "Epoch 71/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3557 - val_loss: 0.3558\n",
      "Epoch 72/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3556 - val_loss: 0.3552\n",
      "Epoch 73/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3542 - val_loss: 0.3562\n",
      "Epoch 74/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3528 - val_loss: 0.3558\n",
      "Epoch 75/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3520 - val_loss: 0.3550\n",
      "Epoch 76/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3517 - val_loss: 0.3564\n",
      "Epoch 77/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3515 - val_loss: 0.3569\n",
      "Epoch 78/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3514 - val_loss: 0.3547\n",
      "Epoch 79/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3510 - val_loss: 0.3542\n",
      "Epoch 80/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3566 - val_loss: 0.3529\n",
      "Epoch 81/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3488 - val_loss: 0.3550\n",
      "Epoch 82/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3495 - val_loss: 0.3554\n",
      "Epoch 83/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3482 - val_loss: 0.3516\n",
      "Epoch 84/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3487 - val_loss: 0.3516\n",
      "Epoch 85/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3472 - val_loss: 0.3536\n",
      "Epoch 86/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3531 - val_loss: 0.3515\n",
      "Epoch 87/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3467 - val_loss: 0.3548\n",
      "Epoch 88/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3527 - val_loss: 0.3503\n",
      "Epoch 89/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3519 - val_loss: 0.3513\n",
      "Epoch 90/100\n",
      "363/363 [==============================] - 0s 995us/step - loss: 0.3450 - val_loss: 0.3504\n",
      "Epoch 91/100\n",
      "363/363 [==============================] - 0s 984us/step - loss: 0.3454 - val_loss: 0.3492\n",
      "Epoch 92/100\n",
      "363/363 [==============================] - 0s 979us/step - loss: 0.3444 - val_loss: 0.3492\n",
      "Epoch 93/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3440 - val_loss: 0.3621\n",
      "Epoch 94/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3441 - val_loss: 0.3500\n",
      "Epoch 95/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3427 - val_loss: 0.3499\n",
      "Epoch 96/100\n",
      "363/363 [==============================] - 0s 987us/step - loss: 0.3449 - val_loss: 0.3487\n",
      "Epoch 97/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3422 - val_loss: 0.3488\n",
      "Epoch 98/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3413 - val_loss: 0.3492\n",
      "Epoch 99/100\n",
      "363/363 [==============================] - 0s 993us/step - loss: 0.3410 - val_loss: 0.3485\n",
      "Epoch 100/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3406 - val_loss: 0.3480\n",
      "162/162 [==============================] - 0s 533us/step\n",
      "0.7362852918410829\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "[2.8486905 2.4350681 2.4499483]\n"
     ]
    }
   ],
   "source": [
    "keras_reg.fit(X_train, y_train, epochs=100,\n",
    "             validation_data=(X_valid, y_valid),\n",
    "             callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n",
    "mse_test=keras_reg.score(X_test, y_test)\n",
    "print(mse_test)\n",
    "y_pred=keras_reg.predict(X_new)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0fed7f-6139-4412-982d-6ddc98104c0c",
   "metadata": {},
   "source": [
    "ランダムサーチ。ランダムサーチはK-fold交差検証なので検証データはここでは使わずEarlyStoppingのみで使っている。\n",
    "\n",
    "[reciprocal](https://pageperso.lis-lab.fr/~francois.denis/IAAM1/scipy-html-1.0.0/generated/scipy.stats.reciprocal.html): reciprocal=逆数。逆数分布とか対数一様分布とか呼ばれる。[loguniform](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.loguniform.html#scipy.stats.loguniform)が新しいdocだとヒットする。pdfは\n",
    "$$\n",
    "f(x,a,b)=\\frac{1}{x \\log(b/a)}\n",
    "$$\n",
    "\n",
    "$a<x<b$、aとbを与えて乱数を生成している。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17956288-9681-445f-9537-0cb9fa09cc73",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.8513 - val_loss: 2.5415\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.8818 - val_loss: 1.2637\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0535 - val_loss: 0.8349\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7738 - val_loss: 0.6798\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6703 - val_loss: 0.6210\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6291 - val_loss: 0.5963\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6099 - val_loss: 0.5837\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5993 - val_loss: 0.5761\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5921 - val_loss: 0.5705\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5865 - val_loss: 0.5656\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5817 - val_loss: 0.5615\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5775 - val_loss: 0.5574\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5736 - val_loss: 0.5538\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5700 - val_loss: 0.5505\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5668 - val_loss: 0.5474\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5637 - val_loss: 0.5444\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5609 - val_loss: 0.5416\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5584 - val_loss: 0.5391\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5561 - val_loss: 0.5371\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1000us/step - loss: 0.5539 - val_loss: 0.5351\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5519 - val_loss: 0.5333\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5501 - val_loss: 0.5311\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5484 - val_loss: 0.5295\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5468 - val_loss: 0.5278\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5455 - val_loss: 0.5266\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5440 - val_loss: 0.5256\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5428 - val_loss: 0.5238\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5418 - val_loss: 0.5232\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5408 - val_loss: 0.5219\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5398 - val_loss: 0.5206\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5389 - val_loss: 0.5195\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5382 - val_loss: 0.5196\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5375 - val_loss: 0.5191\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5368 - val_loss: 0.5179\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5361 - val_loss: 0.5170\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5354 - val_loss: 0.5159\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5350 - val_loss: 0.5153\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5346 - val_loss: 0.5158\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5340 - val_loss: 0.5157\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5337 - val_loss: 0.5153\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5333 - val_loss: 0.5153\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5329 - val_loss: 0.5136\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5327 - val_loss: 0.5133\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5323 - val_loss: 0.5126\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5321 - val_loss: 0.5128\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5318 - val_loss: 0.5123\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5317 - val_loss: 0.5120\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5314 - val_loss: 0.5126\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5312 - val_loss: 0.5127\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5310 - val_loss: 0.5115\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5309 - val_loss: 0.5111\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5305 - val_loss: 0.5102\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5307 - val_loss: 0.5105\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5305 - val_loss: 0.5109\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5304 - val_loss: 0.5106\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5302 - val_loss: 0.5113\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5301 - val_loss: 0.5103\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5300 - val_loss: 0.5113\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5300 - val_loss: 0.5110\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5299 - val_loss: 0.5101\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5297 - val_loss: 0.5112\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5297 - val_loss: 0.5116\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5298 - val_loss: 0.5103\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5295 - val_loss: 0.5090\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5296 - val_loss: 0.5106\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5293 - val_loss: 0.5089\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5296 - val_loss: 0.5100\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5295 - val_loss: 0.5097\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5294 - val_loss: 0.5087\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5294 - val_loss: 0.5102\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5294 - val_loss: 0.5102\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5290 - val_loss: 0.5081\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5292 - val_loss: 0.5078\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5296 - val_loss: 0.5084\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5290 - val_loss: 0.5075\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5292 - val_loss: 0.5074\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5294 - val_loss: 0.5077\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5294 - val_loss: 0.5095\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5293 - val_loss: 0.5101\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5292 - val_loss: 0.5093\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5290 - val_loss: 0.5082\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5293 - val_loss: 0.5083\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5291 - val_loss: 0.5101\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5292 - val_loss: 0.5096\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5291 - val_loss: 0.5085\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5292 - val_loss: 0.5100\n",
      "121/121 [==============================] - 0s 606us/step - loss: 0.5171\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.8790 - val_loss: 2.5507\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.9675 - val_loss: 1.4554\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2468 - val_loss: 1.0379\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9626 - val_loss: 0.8688\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8421 - val_loss: 0.7939\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7844 - val_loss: 0.7549\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7515 - val_loss: 0.7304\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7291 - val_loss: 0.7122\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7115 - val_loss: 0.6971\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6963 - val_loss: 0.6836\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6828 - val_loss: 0.6716\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6705 - val_loss: 0.6607\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6593 - val_loss: 0.6507\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6488 - val_loss: 0.6417\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6392 - val_loss: 0.6333\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6302 - val_loss: 0.6256\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6219 - val_loss: 0.6184\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6143 - val_loss: 0.6119\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6072 - val_loss: 0.6060\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6005 - val_loss: 0.6007\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5944 - val_loss: 0.5957\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5888 - val_loss: 0.5911\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5835 - val_loss: 0.5869\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5786 - val_loss: 0.5832\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5741 - val_loss: 0.5796\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5699 - val_loss: 0.5767\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5660 - val_loss: 0.5737\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5623 - val_loss: 0.5712\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5589 - val_loss: 0.5686\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5558 - val_loss: 0.5664\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5529 - val_loss: 0.5645\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5502 - val_loss: 0.5627\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5476 - val_loss: 0.5611\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5453 - val_loss: 0.5600\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5431 - val_loss: 0.5588\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5411 - val_loss: 0.5575\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5392 - val_loss: 0.5564\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5375 - val_loss: 0.5554\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5359 - val_loss: 0.5547\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5344 - val_loss: 0.5539\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5330 - val_loss: 0.5535\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5316 - val_loss: 0.5529\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5304 - val_loss: 0.5523\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5293 - val_loss: 0.5518\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5283 - val_loss: 0.5516\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5273 - val_loss: 0.5512\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5263 - val_loss: 0.5510\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5255 - val_loss: 0.5511\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5246 - val_loss: 0.5507\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5239 - val_loss: 0.5504\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5232 - val_loss: 0.5501\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5226 - val_loss: 0.5500\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5220 - val_loss: 0.5502\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5214 - val_loss: 0.5499\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5209 - val_loss: 0.5501\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5204 - val_loss: 0.5500\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5199 - val_loss: 0.5500\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5195 - val_loss: 0.5503\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5191 - val_loss: 0.5500\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5187 - val_loss: 0.5502\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5184 - val_loss: 0.5504\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5180 - val_loss: 0.5504\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5177 - val_loss: 0.5506\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5174 - val_loss: 0.5507\n",
      "121/121 [==============================] - 0s 628us/step - loss: 0.7190\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5.5588 - val_loss: 3.2153\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.3837 - val_loss: 1.5900\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2887 - val_loss: 0.9841\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8859 - val_loss: 0.7581\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7315 - val_loss: 0.6690\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6686 - val_loss: 0.6313\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6403 - val_loss: 0.6130\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6250 - val_loss: 0.6022\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6147 - val_loss: 0.5940\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6070 - val_loss: 0.5874\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6004 - val_loss: 0.5817\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5946 - val_loss: 0.5766\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5892 - val_loss: 0.5716\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5845 - val_loss: 0.5671\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5800 - val_loss: 0.5627\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5758 - val_loss: 0.5595\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5721 - val_loss: 0.5556\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5687 - val_loss: 0.5529\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5656 - val_loss: 0.5498\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5626 - val_loss: 0.5472\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5599 - val_loss: 0.5443\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5574 - val_loss: 0.5424\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5550 - val_loss: 0.5391\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5531 - val_loss: 0.5372\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5511 - val_loss: 0.5351\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5493 - val_loss: 0.5335\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5476 - val_loss: 0.5315\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5462 - val_loss: 0.5305\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5447 - val_loss: 0.5293\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5432 - val_loss: 0.5269\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5423 - val_loss: 0.5264\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5409 - val_loss: 0.5246\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5401 - val_loss: 0.5241\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5392 - val_loss: 0.5230\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5383 - val_loss: 0.5223\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5375 - val_loss: 0.5228\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5366 - val_loss: 0.5212\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5360 - val_loss: 0.5204\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5353 - val_loss: 0.5189\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5348 - val_loss: 0.5193\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5340 - val_loss: 0.5175\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5338 - val_loss: 0.5169\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5330 - val_loss: 0.5156\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5329 - val_loss: 0.5177\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5324 - val_loss: 0.5171\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5318 - val_loss: 0.5149\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5318 - val_loss: 0.5152\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5314 - val_loss: 0.5152\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5311 - val_loss: 0.5146\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5308 - val_loss: 0.5158\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5306 - val_loss: 0.5150\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5300 - val_loss: 0.5128\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5302 - val_loss: 0.5127\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5297 - val_loss: 0.5118\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5296 - val_loss: 0.5143\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5290 - val_loss: 0.5114\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5294 - val_loss: 0.5110\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5295 - val_loss: 0.5123\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5292 - val_loss: 0.5123\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5291 - val_loss: 0.5115\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5289 - val_loss: 0.5120\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5285 - val_loss: 0.5103\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5287 - val_loss: 0.5102\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5287 - val_loss: 0.5106\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5282 - val_loss: 0.5095\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5286 - val_loss: 0.5112\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5283 - val_loss: 0.5127\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5282 - val_loss: 0.5140\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5279 - val_loss: 0.5104\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5275 - val_loss: 0.5084\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5281 - val_loss: 0.5085\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5281 - val_loss: 0.5083\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5280 - val_loss: 0.5108\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 999us/step - loss: 0.5278 - val_loss: 0.5094\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5279 - val_loss: 0.5099\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5277 - val_loss: 0.5126\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5279 - val_loss: 0.5123\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5279 - val_loss: 0.5107\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5277 - val_loss: 0.5112\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5278 - val_loss: 0.5113\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5274 - val_loss: 0.5093\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5273 - val_loss: 0.5081\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5276 - val_loss: 0.5098\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5272 - val_loss: 0.5080\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5276 - val_loss: 0.5081\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5275 - val_loss: 0.5079\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5276 - val_loss: 0.5088\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5275 - val_loss: 0.5091\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5269 - val_loss: 0.5073\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5273 - val_loss: 0.5069\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5275 - val_loss: 0.5100\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5270 - val_loss: 0.5078\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5275 - val_loss: 0.5082\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5272 - val_loss: 0.5077\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5272 - val_loss: 0.5070\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5275 - val_loss: 0.5077\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5270 - val_loss: 0.5066\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5273 - val_loss: 0.5072\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5278 - val_loss: 0.5081\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5274 - val_loss: 0.5083\n",
      "121/121 [==============================] - 0s 614us/step - loss: 0.5204\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2126 - val_loss: 0.9269\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3378 - val_loss: 1.1960\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.7729 - val_loss: 0.5344\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5098 - val_loss: 0.4705\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4691 - val_loss: 0.4416\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4520 - val_loss: 0.4341\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4432 - val_loss: 0.4234\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4360 - val_loss: 0.4160\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4287 - val_loss: 0.4116\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4235 - val_loss: 0.4160\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4201 - val_loss: 0.4041\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4160 - val_loss: 0.3997\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4122 - val_loss: 0.3984\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4085 - val_loss: 0.3948\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4052 - val_loss: 0.3936\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4028 - val_loss: 0.3958\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4009 - val_loss: 0.3921\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3974 - val_loss: 0.3896\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3958 - val_loss: 0.3911\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3944 - val_loss: 0.3873\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3920 - val_loss: 0.3861\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3905 - val_loss: 0.3822\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3887 - val_loss: 0.3816\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3887 - val_loss: 0.3851\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3896 - val_loss: 0.3803\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3855 - val_loss: 0.3777\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3824 - val_loss: 0.3767\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3813 - val_loss: 0.3776\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3790 - val_loss: 0.3757\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3787 - val_loss: 0.3750\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3794 - val_loss: 0.3736\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3755 - val_loss: 0.3711\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3765 - val_loss: 0.3715\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3764 - val_loss: 0.3701\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3725 - val_loss: 0.3703\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3708 - val_loss: 0.3680\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3695 - val_loss: 0.3677\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3693 - val_loss: 0.3753\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3689 - val_loss: 0.3674\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3665 - val_loss: 0.3686\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3656 - val_loss: 0.3654\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3647 - val_loss: 0.3636\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3639 - val_loss: 0.3624\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3650 - val_loss: 0.3674\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3628 - val_loss: 0.3634\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3610 - val_loss: 0.3638\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3613 - val_loss: 0.3614\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3597 - val_loss: 0.3726\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3623 - val_loss: 0.3597\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3630 - val_loss: 0.3606\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3566 - val_loss: 0.3597\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3659 - val_loss: 0.3576\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3587 - val_loss: 0.3576\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3572 - val_loss: 0.3564\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3603 - val_loss: 0.3567\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3531 - val_loss: 0.3591\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3542 - val_loss: 0.3559\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3526 - val_loss: 0.3725\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3562 - val_loss: 0.3540\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3513 - val_loss: 0.3568\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3695 - val_loss: 0.3529\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3522 - val_loss: 0.3525\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3500 - val_loss: 0.3519\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3500 - val_loss: 0.3519\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3484 - val_loss: 0.3526\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3490 - val_loss: 0.3542\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3477 - val_loss: 0.3524\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3504 - val_loss: 0.3524\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3490 - val_loss: 0.3518\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3472 - val_loss: 0.3491\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3456 - val_loss: 0.3495\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3470 - val_loss: 0.3486\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3458 - val_loss: 0.3512\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3437 - val_loss: 0.3470\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3440 - val_loss: 0.3487\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3430 - val_loss: 0.3505\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3421 - val_loss: 0.3485\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3409 - val_loss: 0.3465\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3409 - val_loss: 0.3468\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3431 - val_loss: 0.3474\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3732 - val_loss: 0.3472\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3424 - val_loss: 0.3446\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3396 - val_loss: 0.3443\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3399 - val_loss: 0.3436\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3388 - val_loss: 0.3461\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3397 - val_loss: 0.3422\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3380 - val_loss: 0.3438\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3374 - val_loss: 0.3412\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3364 - val_loss: 0.3428\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3362 - val_loss: 0.3436\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3370 - val_loss: 0.3433\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3354 - val_loss: 0.3412\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3354 - val_loss: 0.3407\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3351 - val_loss: 0.3417\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3344 - val_loss: 0.3406\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3334 - val_loss: 0.3399\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3337 - val_loss: 0.3419\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3323 - val_loss: 0.3413\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3339 - val_loss: 0.3641\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3605 - val_loss: 0.3387\n",
      "121/121 [==============================] - 0s 650us/step - loss: 0.3278\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1059 - val_loss: 0.8051\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6233 - val_loss: 0.6400\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5605 - val_loss: 0.5465\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5228 - val_loss: 0.5006\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4998 - val_loss: 0.4793\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4851 - val_loss: 0.4682\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4740 - val_loss: 0.4612\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4667 - val_loss: 0.4536\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4590 - val_loss: 0.4549\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4538 - val_loss: 0.4475\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4495 - val_loss: 0.4435\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4440 - val_loss: 0.4394\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4400 - val_loss: 0.4365\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4360 - val_loss: 0.4350\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4322 - val_loss: 0.4309\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4290 - val_loss: 0.4294\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4256 - val_loss: 0.4227\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4231 - val_loss: 0.4218\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4191 - val_loss: 0.4190\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4174 - val_loss: 0.4175\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4143 - val_loss: 0.4161\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4121 - val_loss: 0.4157\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4100 - val_loss: 0.4117\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4074 - val_loss: 0.4106\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4049 - val_loss: 0.4081\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4036 - val_loss: 0.4072\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4013 - val_loss: 0.4039\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3993 - val_loss: 0.4046\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3972 - val_loss: 0.4004\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3955 - val_loss: 0.4006\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3936 - val_loss: 0.3978\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3921 - val_loss: 0.3969\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3905 - val_loss: 0.3947\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3878 - val_loss: 0.3968\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3868 - val_loss: 0.3942\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3853 - val_loss: 0.3920\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3835 - val_loss: 0.3912\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3824 - val_loss: 0.3877\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3808 - val_loss: 0.3860\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3794 - val_loss: 0.3846\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3773 - val_loss: 0.3844\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3761 - val_loss: 0.3837\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3749 - val_loss: 0.3826\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3734 - val_loss: 0.3818\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3716 - val_loss: 0.3804\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3710 - val_loss: 0.3788\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3687 - val_loss: 0.3780\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3684 - val_loss: 0.3749\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3665 - val_loss: 0.3784\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3654 - val_loss: 0.3751\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3643 - val_loss: 0.3723\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3630 - val_loss: 0.3756\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3616 - val_loss: 0.3701\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3600 - val_loss: 0.3685\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3588 - val_loss: 0.3705\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3582 - val_loss: 0.3697\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3564 - val_loss: 0.3668\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3550 - val_loss: 0.3661\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3536 - val_loss: 0.3664\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3528 - val_loss: 0.3641\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3522 - val_loss: 0.3630\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3510 - val_loss: 0.3651\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3497 - val_loss: 0.3617\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3489 - val_loss: 0.3610\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3465 - val_loss: 0.3607\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3459 - val_loss: 0.3599\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3454 - val_loss: 0.3610\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3445 - val_loss: 0.3634\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3439 - val_loss: 0.3577\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3423 - val_loss: 0.3615\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3418 - val_loss: 0.3562\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3404 - val_loss: 0.3619\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3394 - val_loss: 0.3561\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3387 - val_loss: 0.3561\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3378 - val_loss: 0.3559\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3374 - val_loss: 0.3540\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3359 - val_loss: 0.3552\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3352 - val_loss: 0.3549\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3344 - val_loss: 0.3532\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3336 - val_loss: 0.3518\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3317 - val_loss: 0.3519\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3315 - val_loss: 0.3509\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3299 - val_loss: 0.3531\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3307 - val_loss: 0.3517\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3293 - val_loss: 0.3513\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3284 - val_loss: 0.3516\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3271 - val_loss: 0.3496\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3267 - val_loss: 0.3488\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3256 - val_loss: 0.3585\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3255 - val_loss: 0.3484\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3249 - val_loss: 0.3497\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3242 - val_loss: 0.3483\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3236 - val_loss: 0.3513\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3230 - val_loss: 0.3455\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3220 - val_loss: 0.3448\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3222 - val_loss: 0.3444\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3210 - val_loss: 0.3461\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3204 - val_loss: 0.3437\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3199 - val_loss: 0.3491\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3202 - val_loss: 0.3442\n",
      "121/121 [==============================] - 0s 641us/step - loss: 0.3664\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 1.3501 - val_loss: 1.0085\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3500 - val_loss: 0.6842\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6912 - val_loss: 0.5720\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5652 - val_loss: 0.5140\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5175 - val_loss: 0.4836\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4924 - val_loss: 0.4632\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4742 - val_loss: 0.4546\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4630 - val_loss: 0.4415\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4535 - val_loss: 0.4352\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4464 - val_loss: 0.4306\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4408 - val_loss: 0.4254\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4356 - val_loss: 0.4241\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4313 - val_loss: 0.4181\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4279 - val_loss: 0.4141\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4246 - val_loss: 0.4140\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4212 - val_loss: 0.4098\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4179 - val_loss: 0.4064\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4157 - val_loss: 0.4063\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4129 - val_loss: 0.4028\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4109 - val_loss: 0.4022\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4085 - val_loss: 0.3982\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4068 - val_loss: 0.3969\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4042 - val_loss: 0.3954\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4026 - val_loss: 0.3937\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4018 - val_loss: 0.3921\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3999 - val_loss: 0.3902\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3968 - val_loss: 0.3898\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3955 - val_loss: 0.3896\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3940 - val_loss: 0.3890\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3937 - val_loss: 0.3925\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3936 - val_loss: 0.3850\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3904 - val_loss: 0.3851\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3887 - val_loss: 0.3837\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3872 - val_loss: 0.3829\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3863 - val_loss: 0.3807\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3852 - val_loss: 0.3786\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3835 - val_loss: 0.3804\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3859 - val_loss: 0.3826\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3822 - val_loss: 0.3773\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3808 - val_loss: 0.3754\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3797 - val_loss: 0.3759\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3791 - val_loss: 0.3742\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3774 - val_loss: 0.3733\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3765 - val_loss: 0.3723\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3761 - val_loss: 0.3728\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3746 - val_loss: 0.3724\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3750 - val_loss: 0.3726\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3735 - val_loss: 0.3706\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3720 - val_loss: 0.3696\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3710 - val_loss: 0.3702\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3709 - val_loss: 0.3687\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3696 - val_loss: 0.3679\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3685 - val_loss: 0.3685\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3681 - val_loss: 0.3669\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3671 - val_loss: 0.3683\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3661 - val_loss: 0.3671\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3655 - val_loss: 0.3662\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3658 - val_loss: 0.3653\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3646 - val_loss: 0.3644\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3632 - val_loss: 0.3646\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3629 - val_loss: 0.3669\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3622 - val_loss: 0.3633\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3623 - val_loss: 0.3664\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3608 - val_loss: 0.3631\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3611 - val_loss: 0.3633\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3590 - val_loss: 0.3650\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3592 - val_loss: 0.3624\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3585 - val_loss: 0.3615\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3580 - val_loss: 0.3608\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3564 - val_loss: 0.3620\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3570 - val_loss: 0.3646\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3564 - val_loss: 0.3604\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3584 - val_loss: 0.3616\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3552 - val_loss: 0.3594\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3584 - val_loss: 0.3601\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3547 - val_loss: 0.3617\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3535 - val_loss: 0.3622\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3536 - val_loss: 0.3583\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3554 - val_loss: 0.3589\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3516 - val_loss: 0.3606\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3517 - val_loss: 0.3585\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3548 - val_loss: 0.3592\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3502 - val_loss: 0.3568\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3508 - val_loss: 0.3668\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3823 - val_loss: 0.3611\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3509 - val_loss: 0.3555\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3499 - val_loss: 0.3550\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3493 - val_loss: 0.3559\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3508 - val_loss: 0.3550\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3479 - val_loss: 0.3547\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3475 - val_loss: 0.3549\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3457 - val_loss: 0.3539\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3474 - val_loss: 0.3538\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3470 - val_loss: 0.3555\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3454 - val_loss: 0.3529\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3445 - val_loss: 0.3516\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3475 - val_loss: 0.3529\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3449 - val_loss: 0.3528\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3434 - val_loss: 0.3515\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3467 - val_loss: 0.3512\n",
      "121/121 [==============================] - 0s 640us/step - loss: 0.3459\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.7602 - val_loss: 1.7896\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.1910 - val_loss: 0.6125\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5865 - val_loss: 0.5242\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5182 - val_loss: 0.4745\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4805 - val_loss: 0.4477\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4577 - val_loss: 0.4341\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4444 - val_loss: 0.4137\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4302 - val_loss: 0.4036\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4291 - val_loss: 0.4020\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4189 - val_loss: 0.4012\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4145 - val_loss: 0.3918\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4069 - val_loss: 0.3909\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4044 - val_loss: 0.3862\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4015 - val_loss: 0.3892\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4008 - val_loss: 0.3928\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3996 - val_loss: 0.3818\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3993 - val_loss: 0.3804\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4017 - val_loss: 0.3807\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3987 - val_loss: 0.3794\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3927 - val_loss: 0.3782\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3884 - val_loss: 0.3738\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3873 - val_loss: 0.3718\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3839 - val_loss: 0.3721\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3869 - val_loss: 0.3726\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3846 - val_loss: 0.3708\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3839 - val_loss: 0.3725\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3845 - val_loss: 0.3693\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3793 - val_loss: 0.3698\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3762 - val_loss: 0.3702\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3905 - val_loss: 0.3719\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3974 - val_loss: 0.3704\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3869 - val_loss: 0.3713\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3750 - val_loss: 0.3644\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3714 - val_loss: 0.3631\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3736 - val_loss: 0.3690\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3902 - val_loss: 0.3657\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3770 - val_loss: 0.3624\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3686 - val_loss: 0.3613\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3676 - val_loss: 0.3804\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4237 - val_loss: 0.3659\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3725 - val_loss: 0.3651\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3785 - val_loss: 0.3691\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3682 - val_loss: 0.3621\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3651 - val_loss: 0.3593\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3632 - val_loss: 0.3616\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3615 - val_loss: 0.3600\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3607 - val_loss: 0.3600\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3599 - val_loss: 0.3567\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3595 - val_loss: 0.3578\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3580 - val_loss: 0.3567\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3572 - val_loss: 0.3590\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3561 - val_loss: 0.3546\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3552 - val_loss: 0.3580\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3632 - val_loss: 0.3566\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3545 - val_loss: 0.3552\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3552 - val_loss: 0.3531\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3552 - val_loss: 0.3546\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3528 - val_loss: 0.3561\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3522 - val_loss: 0.3533\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3515 - val_loss: 0.3533\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3498 - val_loss: 0.3552\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3507 - val_loss: 0.3511\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3500 - val_loss: 0.3528\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3484 - val_loss: 0.3533\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3486 - val_loss: 0.3504\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3481 - val_loss: 0.3543\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3479 - val_loss: 0.3508\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3474 - val_loss: 0.3502\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3469 - val_loss: 0.3510\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3459 - val_loss: 0.3484\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3453 - val_loss: 0.3502\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3451 - val_loss: 0.3472\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3441 - val_loss: 0.3488\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3442 - val_loss: 0.3485\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3428 - val_loss: 0.3539\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3432 - val_loss: 0.3461\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3424 - val_loss: 0.3506\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3425 - val_loss: 0.3491\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3423 - val_loss: 0.3501\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3423 - val_loss: 0.3567\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3765 - val_loss: 0.3458\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3461 - val_loss: 0.3445\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3413 - val_loss: 0.3433\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3467 - val_loss: 0.3490\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3476 - val_loss: 0.3441\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3396 - val_loss: 0.3438\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3394 - val_loss: 0.3426\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3386 - val_loss: 0.3420\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3376 - val_loss: 0.3422\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3367 - val_loss: 0.3432\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3379 - val_loss: 0.3407\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3389 - val_loss: 0.3415\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3370 - val_loss: 0.3446\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3367 - val_loss: 0.3470\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3353 - val_loss: 0.3395\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3353 - val_loss: 0.3415\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3358 - val_loss: 0.3386\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3344 - val_loss: 0.3399\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3341 - val_loss: 0.3421\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3351 - val_loss: 0.3421\n",
      "121/121 [==============================] - 0s 635us/step - loss: 0.3317\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0601 - val_loss: 0.6639\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6280 - val_loss: 0.5771\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5628 - val_loss: 0.5274\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5228 - val_loss: 0.4976\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4966 - val_loss: 0.4796\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4796 - val_loss: 0.4654\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4680 - val_loss: 0.4583\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4583 - val_loss: 0.4524\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4514 - val_loss: 0.4457\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4456 - val_loss: 0.4400\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4401 - val_loss: 0.4367\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4361 - val_loss: 0.4339\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4323 - val_loss: 0.4292\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4283 - val_loss: 0.4288\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4253 - val_loss: 0.4244\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4212 - val_loss: 0.4223\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4197 - val_loss: 0.4186\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4159 - val_loss: 0.4167\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4142 - val_loss: 0.4136\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4107 - val_loss: 0.4132\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4085 - val_loss: 0.4093\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4064 - val_loss: 0.4061\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4043 - val_loss: 0.4059\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4017 - val_loss: 0.4054\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4001 - val_loss: 0.4017\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3980 - val_loss: 0.4004\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3956 - val_loss: 0.3977\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3937 - val_loss: 0.3964\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3920 - val_loss: 0.3964\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3897 - val_loss: 0.3934\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3880 - val_loss: 0.3935\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3866 - val_loss: 0.3904\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3839 - val_loss: 0.3936\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3842 - val_loss: 0.3888\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3817 - val_loss: 0.3872\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3810 - val_loss: 0.3853\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3784 - val_loss: 0.3844\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3773 - val_loss: 0.3835\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3765 - val_loss: 0.3823\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3746 - val_loss: 0.3858\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3738 - val_loss: 0.3831\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3715 - val_loss: 0.3808\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3708 - val_loss: 0.3782\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3698 - val_loss: 0.3775\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3687 - val_loss: 0.3757\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3669 - val_loss: 0.3789\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3662 - val_loss: 0.3744\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3649 - val_loss: 0.3732\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3639 - val_loss: 0.3737\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3624 - val_loss: 0.3717\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3612 - val_loss: 0.3721\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3601 - val_loss: 0.3705\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3586 - val_loss: 0.3699\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3580 - val_loss: 0.3709\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3570 - val_loss: 0.3689\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3560 - val_loss: 0.3676\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3549 - val_loss: 0.3697\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3544 - val_loss: 0.3666\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3531 - val_loss: 0.3665\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3516 - val_loss: 0.3675\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3510 - val_loss: 0.3663\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3505 - val_loss: 0.3679\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3492 - val_loss: 0.3679\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3488 - val_loss: 0.3648\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3488 - val_loss: 0.3635\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3471 - val_loss: 0.3656\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3472 - val_loss: 0.3625\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3457 - val_loss: 0.3619\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3445 - val_loss: 0.3616\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3445 - val_loss: 0.3587\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3432 - val_loss: 0.3590\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3426 - val_loss: 0.3578\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3421 - val_loss: 0.3591\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3411 - val_loss: 0.3588\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3405 - val_loss: 0.3578\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3399 - val_loss: 0.3550\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3396 - val_loss: 0.3566\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3386 - val_loss: 0.3604\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3378 - val_loss: 0.3566\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3368 - val_loss: 0.3547\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3361 - val_loss: 0.3572\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3353 - val_loss: 0.3562\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3354 - val_loss: 0.3521\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3346 - val_loss: 0.3544\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3346 - val_loss: 0.3553\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3339 - val_loss: 0.3534\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3329 - val_loss: 0.3519\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3335 - val_loss: 0.3509\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3323 - val_loss: 0.3504\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3309 - val_loss: 0.3500\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3298 - val_loss: 0.3517\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3306 - val_loss: 0.3500\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3302 - val_loss: 0.3518\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3311 - val_loss: 0.3492\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3289 - val_loss: 0.3549\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3286 - val_loss: 0.3493\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3277 - val_loss: 0.3465\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3281 - val_loss: 0.3457\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3275 - val_loss: 0.3457\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3265 - val_loss: 0.3466\n",
      "121/121 [==============================] - 0s 640us/step - loss: 0.3846\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4099 - val_loss: 0.9773\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3719 - val_loss: 0.6696\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6545 - val_loss: 0.5577\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5623 - val_loss: 0.5210\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5306 - val_loss: 0.4986\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5105 - val_loss: 0.4811\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4952 - val_loss: 0.4700\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4843 - val_loss: 0.4595\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4749 - val_loss: 0.4537\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4675 - val_loss: 0.4472\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4621 - val_loss: 0.4448\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4566 - val_loss: 0.4395\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4520 - val_loss: 0.4332\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4485 - val_loss: 0.4302\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4447 - val_loss: 0.4291\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4418 - val_loss: 0.4246\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4389 - val_loss: 0.4241\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4361 - val_loss: 0.4212\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4339 - val_loss: 0.4204\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4317 - val_loss: 0.4186\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4297 - val_loss: 0.4151\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4267 - val_loss: 0.4141\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4255 - val_loss: 0.4117\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4227 - val_loss: 0.4102\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4200 - val_loss: 0.4072\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4178 - val_loss: 0.4080\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4157 - val_loss: 0.4043\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4138 - val_loss: 0.4067\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4118 - val_loss: 0.4023\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4094 - val_loss: 0.4015\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4078 - val_loss: 0.3984\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4068 - val_loss: 0.3967\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4039 - val_loss: 0.3947\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4032 - val_loss: 0.3936\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4007 - val_loss: 0.3927\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3995 - val_loss: 0.3925\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3983 - val_loss: 0.3929\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3966 - val_loss: 0.3903\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3979 - val_loss: 0.3921\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3950 - val_loss: 0.3904\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3944 - val_loss: 0.3882\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3918 - val_loss: 0.3864\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3902 - val_loss: 0.3906\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3895 - val_loss: 0.3842\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3893 - val_loss: 0.3832\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3872 - val_loss: 0.3948\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3864 - val_loss: 0.3813\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3852 - val_loss: 0.3808\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3831 - val_loss: 0.3794\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3822 - val_loss: 0.3787\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3813 - val_loss: 0.3776\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3801 - val_loss: 0.3791\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3790 - val_loss: 0.3753\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3784 - val_loss: 0.3748\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3765 - val_loss: 0.3749\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3764 - val_loss: 0.3835\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3771 - val_loss: 0.3739\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3743 - val_loss: 0.3745\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3732 - val_loss: 0.3725\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3730 - val_loss: 0.3719\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3712 - val_loss: 0.3709\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3704 - val_loss: 0.3705\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3692 - val_loss: 0.3694\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3688 - val_loss: 0.3690\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3680 - val_loss: 0.3732\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3749 - val_loss: 0.3681\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3671 - val_loss: 0.3672\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3683 - val_loss: 0.3675\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3654 - val_loss: 0.3663\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3644 - val_loss: 0.3689\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3633 - val_loss: 0.3678\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3631 - val_loss: 0.3645\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3623 - val_loss: 0.3656\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3630 - val_loss: 0.3647\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3614 - val_loss: 0.3637\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3611 - val_loss: 0.3626\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3602 - val_loss: 0.3644\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3598 - val_loss: 0.3633\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3594 - val_loss: 0.3625\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3585 - val_loss: 0.3632\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3610 - val_loss: 0.3622\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3608 - val_loss: 0.3653\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3571 - val_loss: 0.3616\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3568 - val_loss: 0.3617\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3560 - val_loss: 0.3626\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3559 - val_loss: 0.3598\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3553 - val_loss: 0.3587\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3549 - val_loss: 0.3640\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3588 - val_loss: 0.3577\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3534 - val_loss: 0.3583\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3529 - val_loss: 0.3587\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3515 - val_loss: 0.3580\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3541 - val_loss: 0.3582\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3520 - val_loss: 0.3574\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3514 - val_loss: 0.3565\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3513 - val_loss: 0.3596\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3503 - val_loss: 0.3564\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3565 - val_loss: 0.3599\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3606 - val_loss: 0.3564\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3502 - val_loss: 0.3569\n",
      "121/121 [==============================] - 0s 663us/step - loss: 0.3559\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.1457 - val_loss: 0.5400\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6686 - val_loss: 0.9109\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1292 - val_loss: 3.0907\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "121/121 [==============================] - 0s 707us/step - loss: nan\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8090 - val_loss: 0.5543\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5083 - val_loss: 0.4582\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4546 - val_loss: 0.4243\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4295 - val_loss: 0.4100\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4096 - val_loss: 0.3949\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3925 - val_loss: 0.3837\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3785 - val_loss: 0.3903\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3677 - val_loss: 0.3679\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3593 - val_loss: 0.3968\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3502 - val_loss: 0.3751\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3427 - val_loss: 0.3525\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3372 - val_loss: 0.3637\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3304 - val_loss: 0.3775\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3219 - val_loss: 0.3659\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3179 - val_loss: 0.3512\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3136 - val_loss: 0.3443\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3085 - val_loss: 0.3357\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3061 - val_loss: 0.3252\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2989 - val_loss: 0.3386\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2990 - val_loss: 0.3246\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2975 - val_loss: 0.3222\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2954 - val_loss: 0.3243\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2907 - val_loss: 0.3293\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2892 - val_loss: 0.3493\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2848 - val_loss: 0.3228\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2818 - val_loss: 0.3211\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2838 - val_loss: 0.3133\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2786 - val_loss: 0.3138\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2764 - val_loss: 0.3683\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2756 - val_loss: 0.3861\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2742 - val_loss: 0.3146\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2730 - val_loss: 0.3161\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2727 - val_loss: 0.3065\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2686 - val_loss: 0.3342\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2673 - val_loss: 0.3185\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2687 - val_loss: 0.3040\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2667 - val_loss: 0.3168\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2622 - val_loss: 0.3099\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2619 - val_loss: 0.3313\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2638 - val_loss: 0.3077\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2634 - val_loss: 0.3036\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2624 - val_loss: 0.3084\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2602 - val_loss: 0.3022\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2587 - val_loss: 0.3160\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2585 - val_loss: 0.3087\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2571 - val_loss: 0.3018\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2555 - val_loss: 0.3015\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2531 - val_loss: 0.3089\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2554 - val_loss: 0.3075\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2536 - val_loss: 0.2956\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2497 - val_loss: 0.3139\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2512 - val_loss: 0.3097\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2521 - val_loss: 0.3029\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2492 - val_loss: 0.3010\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2499 - val_loss: 0.3006\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2496 - val_loss: 0.2970\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2487 - val_loss: 0.3229\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2471 - val_loss: 0.2984\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2481 - val_loss: 0.3689\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2468 - val_loss: 0.3003\n",
      "121/121 [==============================] - 0s 698us/step - loss: 0.3466\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 1.3701 - val_loss: 0.5516\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8826 - val_loss: 0.4480\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4406 - val_loss: 0.4563\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4400 - val_loss: 0.4026\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4101 - val_loss: 0.3839\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3876 - val_loss: 0.3817\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3740 - val_loss: 0.3673\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3630 - val_loss: 0.3782\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3592 - val_loss: 0.3639\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3550 - val_loss: 0.3552\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3473 - val_loss: 0.3449\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3434 - val_loss: 0.3412\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3385 - val_loss: 0.3421\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3369 - val_loss: 0.3454\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3314 - val_loss: 0.3579\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3281 - val_loss: 0.3342\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3223 - val_loss: 0.3341\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3197 - val_loss: 0.3211\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3167 - val_loss: 0.3220\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3138 - val_loss: 0.3396\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3090 - val_loss: 0.3328\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3107 - val_loss: 0.3195\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3048 - val_loss: 0.3435\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3087 - val_loss: 0.3079\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3031 - val_loss: 0.3410\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3031 - val_loss: 0.3168\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3011 - val_loss: 0.3114\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2972 - val_loss: 0.3424\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2978 - val_loss: 0.3083\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2991 - val_loss: 0.3042\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2939 - val_loss: 0.3114\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2934 - val_loss: 0.3171\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2895 - val_loss: 0.3247\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2913 - val_loss: 0.3367\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2911 - val_loss: 0.3088\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2912 - val_loss: 0.3015\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2875 - val_loss: 0.3056\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2841 - val_loss: 0.3041\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2863 - val_loss: 0.3122\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2857 - val_loss: 0.3206\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2849 - val_loss: 0.3019\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2827 - val_loss: 0.3055\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2804 - val_loss: 0.3119\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2808 - val_loss: 0.3100\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2826 - val_loss: 0.2969\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2801 - val_loss: 0.3147\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2773 - val_loss: 0.3037\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2761 - val_loss: 0.3040\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2766 - val_loss: 0.3013\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2747 - val_loss: 0.2955\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2774 - val_loss: 0.2970\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2709 - val_loss: 0.2993\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2725 - val_loss: 0.3082\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2713 - val_loss: 0.3089\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2722 - val_loss: 0.3206\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2728 - val_loss: 0.3063\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2721 - val_loss: 0.3042\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2693 - val_loss: 0.3114\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2668 - val_loss: 0.2939\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2680 - val_loss: 0.3092\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2658 - val_loss: 0.3057\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2668 - val_loss: 0.3000\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2627 - val_loss: 0.3095\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2666 - val_loss: 0.3021\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2626 - val_loss: 0.3277\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2635 - val_loss: 0.2996\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2631 - val_loss: 0.3189\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2589 - val_loss: 0.3035\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2631 - val_loss: 0.3075\n",
      "121/121 [==============================] - 0s 696us/step - loss: 0.2910\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 3.8666 - val_loss: 2.2290\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.7365 - val_loss: 1.2048\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1709 - val_loss: 0.9196\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8948 - val_loss: 0.7895\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7807 - val_loss: 0.7294\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7310 - val_loss: 0.6980\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7050 - val_loss: 0.6776\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6877 - val_loss: 0.6630\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6744 - val_loss: 0.6503\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6628 - val_loss: 0.6391\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6522 - val_loss: 0.6287\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6425 - val_loss: 0.6193\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6334 - val_loss: 0.6108\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6249 - val_loss: 0.6024\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6166 - val_loss: 0.5948\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6091 - val_loss: 0.5871\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6017 - val_loss: 0.5800\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5947 - val_loss: 0.5732\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5881 - val_loss: 0.5671\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5818 - val_loss: 0.5609\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5758 - val_loss: 0.5549\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5702 - val_loss: 0.5496\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5646 - val_loss: 0.5440\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5595 - val_loss: 0.5389\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5544 - val_loss: 0.5343\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5495 - val_loss: 0.5292\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5448 - val_loss: 0.5254\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5405 - val_loss: 0.5204\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5362 - val_loss: 0.5164\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5320 - val_loss: 0.5122\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5282 - val_loss: 0.5083\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5245 - val_loss: 0.5046\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5207 - val_loss: 0.5008\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5174 - val_loss: 0.4975\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5140 - val_loss: 0.4940\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5107 - val_loss: 0.4907\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5076 - val_loss: 0.4877\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5046 - val_loss: 0.4846\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5016 - val_loss: 0.4818\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4989 - val_loss: 0.4788\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4962 - val_loss: 0.4762\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4936 - val_loss: 0.4737\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4912 - val_loss: 0.4710\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4887 - val_loss: 0.4688\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4865 - val_loss: 0.4662\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4842 - val_loss: 0.4641\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4821 - val_loss: 0.4621\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4800 - val_loss: 0.4600\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4781 - val_loss: 0.4578\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4761 - val_loss: 0.4558\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4743 - val_loss: 0.4538\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4725 - val_loss: 0.4519\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4707 - val_loss: 0.4501\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4690 - val_loss: 0.4485\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4673 - val_loss: 0.4468\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4657 - val_loss: 0.4454\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4641 - val_loss: 0.4440\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4626 - val_loss: 0.4423\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4612 - val_loss: 0.4409\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4598 - val_loss: 0.4392\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4585 - val_loss: 0.4380\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4570 - val_loss: 0.4368\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4557 - val_loss: 0.4353\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4544 - val_loss: 0.4341\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4531 - val_loss: 0.4329\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4519 - val_loss: 0.4317\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4508 - val_loss: 0.4307\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4494 - val_loss: 0.4296\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4485 - val_loss: 0.4283\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4472 - val_loss: 0.4272\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4462 - val_loss: 0.4261\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4450 - val_loss: 0.4249\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4440 - val_loss: 0.4238\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4427 - val_loss: 0.4236\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4418 - val_loss: 0.4222\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4411 - val_loss: 0.4212\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4398 - val_loss: 0.4202\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4389 - val_loss: 0.4195\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4380 - val_loss: 0.4184\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4370 - val_loss: 0.4177\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4361 - val_loss: 0.4168\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4352 - val_loss: 0.4159\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4343 - val_loss: 0.4153\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4335 - val_loss: 0.4144\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4325 - val_loss: 0.4137\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4318 - val_loss: 0.4129\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4310 - val_loss: 0.4122\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4300 - val_loss: 0.4115\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4293 - val_loss: 0.4107\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4287 - val_loss: 0.4102\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4278 - val_loss: 0.4094\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4271 - val_loss: 0.4086\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4263 - val_loss: 0.4082\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4257 - val_loss: 0.4075\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4249 - val_loss: 0.4068\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4243 - val_loss: 0.4065\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4237 - val_loss: 0.4059\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4228 - val_loss: 0.4053\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4223 - val_loss: 0.4043\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4216 - val_loss: 0.4039\n",
      "121/121 [==============================] - 0s 701us/step - loss: 0.4177\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 3.7888 - val_loss: 2.2485\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5137 - val_loss: 1.0860\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9379 - val_loss: 0.9057\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8167 - val_loss: 0.8292\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7552 - val_loss: 0.7766\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7153 - val_loss: 0.7397\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6881 - val_loss: 0.7099\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6681 - val_loss: 0.6882\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6519 - val_loss: 0.6699\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6386 - val_loss: 0.6526\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6269 - val_loss: 0.6379\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6164 - val_loss: 0.6242\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6069 - val_loss: 0.6118\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5982 - val_loss: 0.6019\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5902 - val_loss: 0.5911\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5826 - val_loss: 0.5819\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5755 - val_loss: 0.5732\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5688 - val_loss: 0.5651\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5625 - val_loss: 0.5583\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5566 - val_loss: 0.5510\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5510 - val_loss: 0.5449\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5458 - val_loss: 0.5390\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5407 - val_loss: 0.5335\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5359 - val_loss: 0.5282\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5313 - val_loss: 0.5233\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5270 - val_loss: 0.5186\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5228 - val_loss: 0.5143\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5187 - val_loss: 0.5100\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5151 - val_loss: 0.5060\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5113 - val_loss: 0.5023\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5079 - val_loss: 0.4986\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5045 - val_loss: 0.4952\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5013 - val_loss: 0.4918\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4981 - val_loss: 0.4887\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4951 - val_loss: 0.4858\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4923 - val_loss: 0.4829\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4896 - val_loss: 0.4801\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4866 - val_loss: 0.4780\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4844 - val_loss: 0.4750\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4818 - val_loss: 0.4726\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4795 - val_loss: 0.4703\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4772 - val_loss: 0.4681\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4749 - val_loss: 0.4659\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4728 - val_loss: 0.4640\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4706 - val_loss: 0.4620\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4688 - val_loss: 0.4600\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4668 - val_loss: 0.4582\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4649 - val_loss: 0.4564\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4631 - val_loss: 0.4547\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4613 - val_loss: 0.4530\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4596 - val_loss: 0.4514\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4579 - val_loss: 0.4498\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4563 - val_loss: 0.4484\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4547 - val_loss: 0.4469\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4531 - val_loss: 0.4455\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4515 - val_loss: 0.4441\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4501 - val_loss: 0.4429\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4486 - val_loss: 0.4415\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4472 - val_loss: 0.4403\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4457 - val_loss: 0.4392\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4445 - val_loss: 0.4380\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4431 - val_loss: 0.4370\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4418 - val_loss: 0.4358\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4406 - val_loss: 0.4347\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4393 - val_loss: 0.4338\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4380 - val_loss: 0.4327\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4369 - val_loss: 0.4318\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4358 - val_loss: 0.4309\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4346 - val_loss: 0.4301\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4335 - val_loss: 0.4292\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4325 - val_loss: 0.4283\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4315 - val_loss: 0.4275\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4304 - val_loss: 0.4266\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4294 - val_loss: 0.4259\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4284 - val_loss: 0.4252\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4275 - val_loss: 0.4243\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4265 - val_loss: 0.4235\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4256 - val_loss: 0.4231\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4248 - val_loss: 0.4221\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4238 - val_loss: 0.4212\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4229 - val_loss: 0.4206\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4221 - val_loss: 0.4199\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4212 - val_loss: 0.4192\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4204 - val_loss: 0.4187\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4196 - val_loss: 0.4180\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4187 - val_loss: 0.4176\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4180 - val_loss: 0.4166\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4171 - val_loss: 0.4160\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4164 - val_loss: 0.4155\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4156 - val_loss: 0.4148\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4148 - val_loss: 0.4142\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4141 - val_loss: 0.4141\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4133 - val_loss: 0.4135\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4126 - val_loss: 0.4125\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4118 - val_loss: 0.4120\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4111 - val_loss: 0.4113\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4103 - val_loss: 0.4110\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4097 - val_loss: 0.4102\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4090 - val_loss: 0.4097\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4082 - val_loss: 0.4097\n",
      "121/121 [==============================] - 0s 695us/step - loss: 0.4466\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 3.5386 - val_loss: 2.1261\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.6740 - val_loss: 1.1355\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0827 - val_loss: 0.8831\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8621 - val_loss: 0.7759\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7755 - val_loss: 0.7258\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7341 - val_loss: 0.6978\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7087 - val_loss: 0.6770\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6901 - val_loss: 0.6609\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6753 - val_loss: 0.6477\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6624 - val_loss: 0.6360\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6508 - val_loss: 0.6257\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6405 - val_loss: 0.6160\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6309 - val_loss: 0.6069\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6219 - val_loss: 0.5984\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6132 - val_loss: 0.5904\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6051 - val_loss: 0.5835\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5980 - val_loss: 0.5757\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5904 - val_loss: 0.5697\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5839 - val_loss: 0.5626\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5774 - val_loss: 0.5568\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5715 - val_loss: 0.5507\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5656 - val_loss: 0.5447\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5600 - val_loss: 0.5393\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5548 - val_loss: 0.5344\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5499 - val_loss: 0.5299\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5452 - val_loss: 0.5250\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5408 - val_loss: 0.5208\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5363 - val_loss: 0.5169\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5325 - val_loss: 0.5127\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5285 - val_loss: 0.5090\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5248 - val_loss: 0.5052\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5212 - val_loss: 0.5017\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5177 - val_loss: 0.4985\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5145 - val_loss: 0.4954\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5114 - val_loss: 0.4919\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5085 - val_loss: 0.4893\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5055 - val_loss: 0.4864\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5028 - val_loss: 0.4837\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5002 - val_loss: 0.4811\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4976 - val_loss: 0.4789\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4950 - val_loss: 0.4761\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4928 - val_loss: 0.4740\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4904 - val_loss: 0.4717\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4883 - val_loss: 0.4699\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4861 - val_loss: 0.4674\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4841 - val_loss: 0.4655\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4821 - val_loss: 0.4636\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4801 - val_loss: 0.4619\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4783 - val_loss: 0.4600\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4765 - val_loss: 0.4582\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4747 - val_loss: 0.4565\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4730 - val_loss: 0.4551\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4712 - val_loss: 0.4533\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4696 - val_loss: 0.4516\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4678 - val_loss: 0.4504\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4662 - val_loss: 0.4491\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4646 - val_loss: 0.4475\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4632 - val_loss: 0.4458\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4616 - val_loss: 0.4445\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4600 - val_loss: 0.4430\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4587 - val_loss: 0.4417\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4572 - val_loss: 0.4403\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4557 - val_loss: 0.4390\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4545 - val_loss: 0.4375\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4530 - val_loss: 0.4369\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4516 - val_loss: 0.4356\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4504 - val_loss: 0.4345\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4491 - val_loss: 0.4331\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4478 - val_loss: 0.4317\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4464 - val_loss: 0.4304\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4453 - val_loss: 0.4294\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4439 - val_loss: 0.4287\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4427 - val_loss: 0.4273\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4412 - val_loss: 0.4267\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4403 - val_loss: 0.4254\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4391 - val_loss: 0.4241\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4380 - val_loss: 0.4229\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4368 - val_loss: 0.4224\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4356 - val_loss: 0.4212\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4345 - val_loss: 0.4199\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4334 - val_loss: 0.4198\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4323 - val_loss: 0.4183\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4313 - val_loss: 0.4175\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4303 - val_loss: 0.4167\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4292 - val_loss: 0.4160\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4282 - val_loss: 0.4149\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4272 - val_loss: 0.4141\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4263 - val_loss: 0.4135\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4252 - val_loss: 0.4126\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4244 - val_loss: 0.4115\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4233 - val_loss: 0.4105\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4226 - val_loss: 0.4101\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4216 - val_loss: 0.4099\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4208 - val_loss: 0.4087\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4199 - val_loss: 0.4079\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4191 - val_loss: 0.4075\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4183 - val_loss: 0.4068\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4174 - val_loss: 0.4060\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4167 - val_loss: 0.4053\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4157 - val_loss: 0.4051\n",
      "121/121 [==============================] - 0s 706us/step - loss: 0.4191\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 0.9576 - val_loss: 0.8349\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3628 - val_loss: 0.4833\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.5780 - val_loss: 0.4905\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5945 - val_loss: 0.4205\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "121/121 [==============================] - 0s 705us/step - loss: nan\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 0.7437 - val_loss: 0.4636\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4490 - val_loss: 0.4250\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4188 - val_loss: 0.4098\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4026 - val_loss: 0.4096\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3887 - val_loss: 0.4647\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3776 - val_loss: 0.3832\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3695 - val_loss: 0.3783\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3621 - val_loss: 0.3896\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3576 - val_loss: 0.3679\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3487 - val_loss: 0.3565\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3461 - val_loss: 0.3520\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3387 - val_loss: 0.3549\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3363 - val_loss: 0.3621\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3344 - val_loss: 0.3563\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3307 - val_loss: 0.3537\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3243 - val_loss: 0.3409\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3212 - val_loss: 0.3576\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3215 - val_loss: 0.3513\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3176 - val_loss: 0.3363\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3134 - val_loss: 0.3389\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3107 - val_loss: 0.3488\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3127 - val_loss: 0.3418\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3066 - val_loss: 0.3432\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3057 - val_loss: 0.3302\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3025 - val_loss: 0.3348\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3006 - val_loss: 0.3313\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2995 - val_loss: 0.3232\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2974 - val_loss: 0.3397\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2991 - val_loss: 0.3496\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2964 - val_loss: 0.3348\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2934 - val_loss: 0.3313\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2928 - val_loss: 0.3180\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2919 - val_loss: 0.3246\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2898 - val_loss: 0.3202\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2877 - val_loss: 0.3171\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2879 - val_loss: 0.3239\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2830 - val_loss: 0.3278\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2851 - val_loss: 0.3125\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2863 - val_loss: 0.3434\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2817 - val_loss: 0.3147\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2808 - val_loss: 0.3288\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2813 - val_loss: 0.3439\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2813 - val_loss: 0.3149\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2793 - val_loss: 0.3127\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2759 - val_loss: 0.3070\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2780 - val_loss: 0.3081\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2767 - val_loss: 0.3171\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2772 - val_loss: 0.3250\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2744 - val_loss: 0.3299\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2760 - val_loss: 0.3072\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2735 - val_loss: 0.3056\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2726 - val_loss: 0.3202\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2707 - val_loss: 0.3182\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2705 - val_loss: 0.3137\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2693 - val_loss: 0.3024\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2701 - val_loss: 0.3143\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2669 - val_loss: 0.3253\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2667 - val_loss: 0.3021\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2703 - val_loss: 0.3054\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2667 - val_loss: 0.3204\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2661 - val_loss: 0.3117\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2690 - val_loss: 0.3002\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2652 - val_loss: 0.3109\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2652 - val_loss: 0.3128\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2644 - val_loss: 0.3002\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2637 - val_loss: 0.3086\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2629 - val_loss: 0.3177\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2651 - val_loss: 0.3037\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2627 - val_loss: 0.3091\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2618 - val_loss: 0.3004\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2598 - val_loss: 0.3110\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2615 - val_loss: 0.3200\n",
      "121/121 [==============================] - 0s 667us/step - loss: 0.3398\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 1.6117 - val_loss: 1.4093\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6347 - val_loss: 0.6314\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5498 - val_loss: 0.4338\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4300 - val_loss: 0.4123\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4177 - val_loss: 0.4075\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4076 - val_loss: 0.4067\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4069 - val_loss: 0.3874\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3960 - val_loss: 0.3868\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3866 - val_loss: 0.3752\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3785 - val_loss: 0.3840\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3707 - val_loss: 0.3683\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3666 - val_loss: 0.3623\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3597 - val_loss: 0.3824\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3558 - val_loss: 0.3605\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3528 - val_loss: 0.3548\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3477 - val_loss: 0.3716\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3441 - val_loss: 0.3514\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3410 - val_loss: 0.3532\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3362 - val_loss: 0.3425\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3341 - val_loss: 0.3482\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3305 - val_loss: 0.3400\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3294 - val_loss: 0.3471\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3258 - val_loss: 0.3295\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3231 - val_loss: 0.3400\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3220 - val_loss: 0.3273\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3193 - val_loss: 0.3401\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3186 - val_loss: 0.3437\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3141 - val_loss: 0.3311\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3143 - val_loss: 0.3216\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3113 - val_loss: 0.3233\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3094 - val_loss: 0.3219\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3063 - val_loss: 0.3205\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3063 - val_loss: 0.3301\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3060 - val_loss: 0.3263\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3035 - val_loss: 0.3429\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3034 - val_loss: 0.3222\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3027 - val_loss: 0.3198\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3016 - val_loss: 0.3157\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2993 - val_loss: 0.3107\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2975 - val_loss: 0.3198\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2969 - val_loss: 0.3396\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2964 - val_loss: 0.3191\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2964 - val_loss: 0.3168\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2938 - val_loss: 0.3137\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2941 - val_loss: 0.3278\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2932 - val_loss: 0.3085\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2917 - val_loss: 0.3170\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2894 - val_loss: 0.3236\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2905 - val_loss: 0.3147\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2891 - val_loss: 0.3114\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2885 - val_loss: 0.3143\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2866 - val_loss: 0.3119\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2846 - val_loss: 0.3235\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2876 - val_loss: 0.3138\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2840 - val_loss: 0.3158\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2813 - val_loss: 0.3054\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2823 - val_loss: 0.3070\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2819 - val_loss: 0.3027\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2821 - val_loss: 0.3090\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2794 - val_loss: 0.3085\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2819 - val_loss: 0.3076\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2796 - val_loss: 0.3144\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2791 - val_loss: 0.3170\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2965 - val_loss: 0.3837\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4449 - val_loss: 0.3170\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2947 - val_loss: 0.3120\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2873 - val_loss: 0.3078\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2863 - val_loss: 0.3023\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2839 - val_loss: 0.3081\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2830 - val_loss: 0.3086\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2820 - val_loss: 0.3123\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2796 - val_loss: 0.3163\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2787 - val_loss: 0.3161\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2798 - val_loss: 0.3070\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2768 - val_loss: 0.3046\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2794 - val_loss: 0.3057\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2770 - val_loss: 0.3048\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2767 - val_loss: 0.3106\n",
      "121/121 [==============================] - 0s 689us/step - loss: 0.2897\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 3.0697 - val_loss: 1.3632\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2252 - val_loss: 1.0385\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9788 - val_loss: 0.8552\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8173 - val_loss: 0.7248\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7138 - val_loss: 0.6564\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6541 - val_loss: 0.6136\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6216 - val_loss: 0.5855\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5952 - val_loss: 0.5626\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5734 - val_loss: 0.5432\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5558 - val_loss: 0.5277\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5407 - val_loss: 0.5133\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5283 - val_loss: 0.5011\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5174 - val_loss: 0.4918\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5091 - val_loss: 0.4834\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5021 - val_loss: 0.4770\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4958 - val_loss: 0.4702\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4903 - val_loss: 0.4647\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4851 - val_loss: 0.4605\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4804 - val_loss: 0.4552\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4756 - val_loss: 0.4525\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4724 - val_loss: 0.4484\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4682 - val_loss: 0.4446\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4651 - val_loss: 0.4418\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4620 - val_loss: 0.4388\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4587 - val_loss: 0.4366\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4561 - val_loss: 0.4332\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4535 - val_loss: 0.4314\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4508 - val_loss: 0.4289\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4487 - val_loss: 0.4273\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4460 - val_loss: 0.4255\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4441 - val_loss: 0.4248\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4418 - val_loss: 0.4221\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4393 - val_loss: 0.4211\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4376 - val_loss: 0.4199\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4355 - val_loss: 0.4180\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4340 - val_loss: 0.4154\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4324 - val_loss: 0.4142\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4305 - val_loss: 0.4131\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4286 - val_loss: 0.4118\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4274 - val_loss: 0.4119\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4260 - val_loss: 0.4103\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4244 - val_loss: 0.4083\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4231 - val_loss: 0.4068\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4216 - val_loss: 0.4070\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4205 - val_loss: 0.4055\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4189 - val_loss: 0.4041\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4178 - val_loss: 0.4038\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4167 - val_loss: 0.4017\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4157 - val_loss: 0.4012\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4146 - val_loss: 0.4004\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4135 - val_loss: 0.4013\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4123 - val_loss: 0.3987\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4111 - val_loss: 0.3974\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4103 - val_loss: 0.3978\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4094 - val_loss: 0.3970\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4083 - val_loss: 0.3963\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4070 - val_loss: 0.3956\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4065 - val_loss: 0.3964\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4054 - val_loss: 0.3947\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4048 - val_loss: 0.3933\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4033 - val_loss: 0.3938\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4029 - val_loss: 0.3915\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4019 - val_loss: 0.3913\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4008 - val_loss: 0.3893\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4002 - val_loss: 0.3888\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3994 - val_loss: 0.3894\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3986 - val_loss: 0.3890\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3981 - val_loss: 0.3876\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3966 - val_loss: 0.3872\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3965 - val_loss: 0.3868\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3956 - val_loss: 0.3857\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3949 - val_loss: 0.3850\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3943 - val_loss: 0.3842\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3932 - val_loss: 0.3852\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3926 - val_loss: 0.3837\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3920 - val_loss: 0.3828\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3911 - val_loss: 0.3827\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3904 - val_loss: 0.3825\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3896 - val_loss: 0.3813\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3889 - val_loss: 0.3820\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3883 - val_loss: 0.3816\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3877 - val_loss: 0.3789\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3868 - val_loss: 0.3820\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3862 - val_loss: 0.3812\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3856 - val_loss: 0.3787\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3850 - val_loss: 0.3777\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3843 - val_loss: 0.3782\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3837 - val_loss: 0.3769\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3830 - val_loss: 0.3783\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3822 - val_loss: 0.3789\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3821 - val_loss: 0.3757\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3813 - val_loss: 0.3758\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3805 - val_loss: 0.3754\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3798 - val_loss: 0.3754\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3793 - val_loss: 0.3747\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3789 - val_loss: 0.3740\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3783 - val_loss: 0.3740\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3776 - val_loss: 0.3737\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3766 - val_loss: 0.3758\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3767 - val_loss: 0.3720\n",
      "121/121 [==============================] - 0s 687us/step - loss: 0.3664\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.3803 - val_loss: 0.8238\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7164 - val_loss: 0.6907\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6399 - val_loss: 0.6283\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5947 - val_loss: 0.5858\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5627 - val_loss: 0.5564\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5391 - val_loss: 0.5370\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5212 - val_loss: 0.5173\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5071 - val_loss: 0.5036\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4963 - val_loss: 0.4924\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4877 - val_loss: 0.4845\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4807 - val_loss: 0.4775\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4747 - val_loss: 0.4709\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4691 - val_loss: 0.4660\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4642 - val_loss: 0.4616\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4600 - val_loss: 0.4566\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4558 - val_loss: 0.4538\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4522 - val_loss: 0.4516\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4490 - val_loss: 0.4466\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4458 - val_loss: 0.4438\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4433 - val_loss: 0.4414\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4403 - val_loss: 0.4386\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4372 - val_loss: 0.4373\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4351 - val_loss: 0.4355\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4328 - val_loss: 0.4324\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4306 - val_loss: 0.4303\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4278 - val_loss: 0.4297\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4268 - val_loss: 0.4272\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4247 - val_loss: 0.4249\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4225 - val_loss: 0.4232\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4211 - val_loss: 0.4214\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4192 - val_loss: 0.4203\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4171 - val_loss: 0.4194\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4155 - val_loss: 0.4187\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4144 - val_loss: 0.4171\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4125 - val_loss: 0.4158\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4109 - val_loss: 0.4142\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4094 - val_loss: 0.4140\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4079 - val_loss: 0.4119\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4066 - val_loss: 0.4109\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4052 - val_loss: 0.4099\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4035 - val_loss: 0.4082\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4015 - val_loss: 0.4085\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4001 - val_loss: 0.4074\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3988 - val_loss: 0.4050\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3973 - val_loss: 0.4038\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3954 - val_loss: 0.4047\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3938 - val_loss: 0.4021\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3929 - val_loss: 0.3991\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3914 - val_loss: 0.3987\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3900 - val_loss: 0.3961\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3883 - val_loss: 0.3967\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3872 - val_loss: 0.3937\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3861 - val_loss: 0.3931\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3848 - val_loss: 0.3920\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3837 - val_loss: 0.3907\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3825 - val_loss: 0.3901\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3815 - val_loss: 0.3889\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3801 - val_loss: 0.3877\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3795 - val_loss: 0.3869\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3785 - val_loss: 0.3852\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3775 - val_loss: 0.3849\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3766 - val_loss: 0.3843\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3754 - val_loss: 0.3830\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3743 - val_loss: 0.3830\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3731 - val_loss: 0.3822\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3721 - val_loss: 0.3806\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3715 - val_loss: 0.3798\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3702 - val_loss: 0.3794\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3692 - val_loss: 0.3794\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3687 - val_loss: 0.3774\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3678 - val_loss: 0.3773\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3667 - val_loss: 0.3768\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3658 - val_loss: 0.3764\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3652 - val_loss: 0.3749\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3641 - val_loss: 0.3747\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3632 - val_loss: 0.3736\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3630 - val_loss: 0.3731\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3623 - val_loss: 0.3732\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3612 - val_loss: 0.3724\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3604 - val_loss: 0.3716\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3595 - val_loss: 0.3710\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3595 - val_loss: 0.3697\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3584 - val_loss: 0.3708\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3575 - val_loss: 0.3714\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3574 - val_loss: 0.3677\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3563 - val_loss: 0.3683\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3553 - val_loss: 0.3672\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3543 - val_loss: 0.3676\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3533 - val_loss: 0.3683\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3532 - val_loss: 0.3649\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3526 - val_loss: 0.3642\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3515 - val_loss: 0.3654\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3508 - val_loss: 0.3639\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3501 - val_loss: 0.3631\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3491 - val_loss: 0.3650\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3489 - val_loss: 0.3620\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3475 - val_loss: 0.3668\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3470 - val_loss: 0.3615\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3463 - val_loss: 0.3607\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3453 - val_loss: 0.3602\n",
      "121/121 [==============================] - 0s 693us/step - loss: 0.3779\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.1998 - val_loss: 0.8957\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6930 - val_loss: 0.6133\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6210 - val_loss: 0.5836\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5938 - val_loss: 0.5634\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5727 - val_loss: 0.5457\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5548 - val_loss: 0.5323\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5399 - val_loss: 0.5187\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5271 - val_loss: 0.5073\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5157 - val_loss: 0.4977\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5062 - val_loss: 0.4889\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4975 - val_loss: 0.4825\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4892 - val_loss: 0.4735\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4829 - val_loss: 0.4695\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4773 - val_loss: 0.4646\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4723 - val_loss: 0.4620\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4673 - val_loss: 0.4577\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4635 - val_loss: 0.4536\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4600 - val_loss: 0.4510\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4563 - val_loss: 0.4474\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4540 - val_loss: 0.4457\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4520 - val_loss: 0.4475\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4483 - val_loss: 0.4437\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4459 - val_loss: 0.4447\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4443 - val_loss: 0.4379\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4422 - val_loss: 0.4382\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4402 - val_loss: 0.4342\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4381 - val_loss: 0.4313\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4368 - val_loss: 0.4352\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4353 - val_loss: 0.4306\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4338 - val_loss: 0.4308\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4308 - val_loss: 0.4259\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4300 - val_loss: 0.4288\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4282 - val_loss: 0.4237\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4267 - val_loss: 0.4263\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4255 - val_loss: 0.4205\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4239 - val_loss: 0.4213\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4227 - val_loss: 0.4181\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4207 - val_loss: 0.4173\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4203 - val_loss: 0.4159\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4188 - val_loss: 0.4235\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4175 - val_loss: 0.4137\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4165 - val_loss: 0.4137\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4150 - val_loss: 0.4107\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4139 - val_loss: 0.4114\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4134 - val_loss: 0.4102\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4119 - val_loss: 0.4088\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4108 - val_loss: 0.4078\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4092 - val_loss: 0.4056\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4090 - val_loss: 0.4077\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4077 - val_loss: 0.4051\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4069 - val_loss: 0.4048\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4055 - val_loss: 0.4031\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4046 - val_loss: 0.4060\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4036 - val_loss: 0.4012\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4025 - val_loss: 0.4013\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4021 - val_loss: 0.3991\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4009 - val_loss: 0.4005\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3998 - val_loss: 0.4006\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3989 - val_loss: 0.3983\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3980 - val_loss: 0.3985\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3963 - val_loss: 0.3978\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3960 - val_loss: 0.3954\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3951 - val_loss: 0.3967\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3938 - val_loss: 0.3957\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3935 - val_loss: 0.3941\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3930 - val_loss: 0.3950\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3921 - val_loss: 0.3933\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3913 - val_loss: 0.3942\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3904 - val_loss: 0.3933\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3901 - val_loss: 0.3907\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3886 - val_loss: 0.3911\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3882 - val_loss: 0.3909\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3878 - val_loss: 0.3913\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3867 - val_loss: 0.3905\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3857 - val_loss: 0.3889\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3849 - val_loss: 0.3899\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3843 - val_loss: 0.3899\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3836 - val_loss: 0.3884\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3825 - val_loss: 0.3888\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3823 - val_loss: 0.3877\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3811 - val_loss: 0.3874\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3807 - val_loss: 0.3875\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3806 - val_loss: 0.3863\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3795 - val_loss: 0.3841\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3782 - val_loss: 0.3863\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3782 - val_loss: 0.3821\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3777 - val_loss: 0.3820\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3768 - val_loss: 0.3841\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3763 - val_loss: 0.3822\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3755 - val_loss: 0.3816\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3748 - val_loss: 0.3846\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3739 - val_loss: 0.3840\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3736 - val_loss: 0.3807\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3732 - val_loss: 0.3803\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3722 - val_loss: 0.3817\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3719 - val_loss: 0.3818\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3709 - val_loss: 0.3791\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3707 - val_loss: 0.3792\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3699 - val_loss: 0.3793\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3695 - val_loss: 0.3777\n",
      "121/121 [==============================] - 0s 720us/step - loss: 0.3750\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3592 - val_loss: 6.7264\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 10.5581 - val_loss: 774.6107\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2929.3389 - val_loss: 106570.3672\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 607413.5625 - val_loss: 14682928.0000\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 83301248.0000 - val_loss: 2018430208.0000\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 999us/step - loss: 4722416640.0000 - val_loss: 278060826624.0000\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1330290753536.0000 - val_loss: 38333354868736.0000\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 61065865986048.0000 - val_loss: 5328553860136960.0000\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 18372551537328128.0000 - val_loss: 717644985977012224.0000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1444229276365750272.0000 - val_loss: 99022923195087847424.0000\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 204436542222344650752.0000 - val_loss: 13614852299702069624832.0000\n",
      "121/121 [==============================] - 0s 604us/step - loss: 2094273891081501278208.0000\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9104 - val_loss: 0.5381\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5324 - val_loss: 0.5270\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5228 - val_loss: 0.5475\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5208 - val_loss: 0.5408\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5194 - val_loss: 0.5306\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5190 - val_loss: 0.5476\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5185 - val_loss: 0.5204\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5210 - val_loss: 0.5250\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5217 - val_loss: 0.5270\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5189 - val_loss: 0.5428\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5213 - val_loss: 0.5463\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 996us/step - loss: 0.5205 - val_loss: 0.5441\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5170 - val_loss: 0.5468\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5210 - val_loss: 0.5317\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5195 - val_loss: 0.5486\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5190 - val_loss: 0.5396\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5191 - val_loss: 0.5308\n",
      "121/121 [==============================] - 0s 615us/step - loss: 0.6431\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2256 - val_loss: 1.4319\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 13.8693 - val_loss: 32.2599\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 47.2084 - val_loss: 1089.6923\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 893.7189 - val_loss: 37247.9727\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 40396.6836 - val_loss: 1288422.7500\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 20090528.0000 - val_loss: 44155348.0000\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 763803904.0000 - val_loss: 1509348096.0000\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 22493220864.0000 - val_loss: 52027850752.0000\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 59614126080.0000 - val_loss: 1787219279872.0000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 24943412641792.0000 - val_loss: 61697490419712.0000\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 29905716772864.0000 - val_loss: 2180459467374592.0000\n",
      "121/121 [==============================] - 0s 617us/step - loss: 23381961342976.0000\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 3.2238 - val_loss: 1.7337\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5243 - val_loss: 1.0470\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9566 - val_loss: 0.8240\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8045 - val_loss: 0.7527\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7480 - val_loss: 0.7179\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7184 - val_loss: 0.6952\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6981 - val_loss: 0.6773\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6818 - val_loss: 0.6626\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6678 - val_loss: 0.6506\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6563 - val_loss: 0.6387\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6459 - val_loss: 0.6297\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6363 - val_loss: 0.6207\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6279 - val_loss: 0.6122\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6206 - val_loss: 0.6055\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6135 - val_loss: 0.5990\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6072 - val_loss: 0.5929\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6012 - val_loss: 0.5874\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5958 - val_loss: 0.5820\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5907 - val_loss: 0.5778\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5857 - val_loss: 0.5726\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5810 - val_loss: 0.5677\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5767 - val_loss: 0.5636\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5725 - val_loss: 0.5602\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5684 - val_loss: 0.5559\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5644 - val_loss: 0.5518\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5607 - val_loss: 0.5481\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5571 - val_loss: 0.5450\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5537 - val_loss: 0.5421\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5503 - val_loss: 0.5398\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5468 - val_loss: 0.5365\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5433 - val_loss: 0.5319\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5405 - val_loss: 0.5301\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5373 - val_loss: 0.5264\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5344 - val_loss: 0.5238\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5316 - val_loss: 0.5219\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5288 - val_loss: 0.5188\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5259 - val_loss: 0.5156\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5232 - val_loss: 0.5153\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5207 - val_loss: 0.5119\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5177 - val_loss: 0.5073\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5158 - val_loss: 0.5074\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5133 - val_loss: 0.5037\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5104 - val_loss: 0.5007\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5082 - val_loss: 0.4995\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5061 - val_loss: 0.5003\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5036 - val_loss: 0.4942\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5012 - val_loss: 0.4915\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5000 - val_loss: 0.4909\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4971 - val_loss: 0.4898\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4949 - val_loss: 0.4855\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4934 - val_loss: 0.4844\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4908 - val_loss: 0.4816\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4898 - val_loss: 0.4842\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4875 - val_loss: 0.4790\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4860 - val_loss: 0.4787\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4841 - val_loss: 0.4777\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4823 - val_loss: 0.4745\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4805 - val_loss: 0.4726\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4788 - val_loss: 0.4698\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4777 - val_loss: 0.4681\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4762 - val_loss: 0.4724\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4750 - val_loss: 0.4682\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4731 - val_loss: 0.4646\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4719 - val_loss: 0.4686\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4708 - val_loss: 0.4647\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4694 - val_loss: 0.4646\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4676 - val_loss: 0.4593\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4667 - val_loss: 0.4586\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4663 - val_loss: 0.4588\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4647 - val_loss: 0.4576\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4641 - val_loss: 0.4595\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4616 - val_loss: 0.4535\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4615 - val_loss: 0.4532\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4607 - val_loss: 0.4533\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4598 - val_loss: 0.4542\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4585 - val_loss: 0.4525\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4577 - val_loss: 0.4559\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4566 - val_loss: 0.4504\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4550 - val_loss: 0.4472\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4550 - val_loss: 0.4507\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4539 - val_loss: 0.4523\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4533 - val_loss: 0.4467\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4528 - val_loss: 0.4482\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4513 - val_loss: 0.4447\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4512 - val_loss: 0.4450\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4498 - val_loss: 0.4426\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4497 - val_loss: 0.4426\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4490 - val_loss: 0.4446\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4480 - val_loss: 0.4412\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4471 - val_loss: 0.4434\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4465 - val_loss: 0.4397\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4463 - val_loss: 0.4407\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4457 - val_loss: 0.4423\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4440 - val_loss: 0.4369\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4448 - val_loss: 0.4383\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4432 - val_loss: 0.4381\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4427 - val_loss: 0.4362\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4420 - val_loss: 0.4352\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4420 - val_loss: 0.4350\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4408 - val_loss: 0.4352\n",
      "121/121 [==============================] - 0s 669us/step - loss: 0.4302\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 4.6737 - val_loss: 3.1465\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.3055 - val_loss: 1.5969\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3156 - val_loss: 1.0475\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9827 - val_loss: 0.8659\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8412 - val_loss: 0.7693\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7520 - val_loss: 0.7036\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6917 - val_loss: 0.6605\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6525 - val_loss: 0.6327\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6274 - val_loss: 0.6146\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6110 - val_loss: 0.6020\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5997 - val_loss: 0.5925\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5912 - val_loss: 0.5847\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5842 - val_loss: 0.5779\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5782 - val_loss: 0.5714\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5726 - val_loss: 0.5654\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5673 - val_loss: 0.5596\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5623 - val_loss: 0.5544\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5578 - val_loss: 0.5493\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5535 - val_loss: 0.5443\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5494 - val_loss: 0.5397\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5455 - val_loss: 0.5354\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5417 - val_loss: 0.5312\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5382 - val_loss: 0.5273\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5347 - val_loss: 0.5234\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5314 - val_loss: 0.5200\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5282 - val_loss: 0.5165\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5251 - val_loss: 0.5133\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5223 - val_loss: 0.5101\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5195 - val_loss: 0.5072\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5168 - val_loss: 0.5045\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5142 - val_loss: 0.5018\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5118 - val_loss: 0.4993\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5093 - val_loss: 0.4970\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5072 - val_loss: 0.4947\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5051 - val_loss: 0.4927\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5030 - val_loss: 0.4907\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5010 - val_loss: 0.4891\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4991 - val_loss: 0.4872\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4973 - val_loss: 0.4856\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4956 - val_loss: 0.4840\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4939 - val_loss: 0.4827\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4923 - val_loss: 0.4812\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4908 - val_loss: 0.4802\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4892 - val_loss: 0.4788\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4877 - val_loss: 0.4781\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4862 - val_loss: 0.4767\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4849 - val_loss: 0.4758\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4836 - val_loss: 0.4746\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4823 - val_loss: 0.4734\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4810 - val_loss: 0.4723\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4797 - val_loss: 0.4711\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4785 - val_loss: 0.4700\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4773 - val_loss: 0.4690\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4761 - val_loss: 0.4679\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4749 - val_loss: 0.4669\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4738 - val_loss: 0.4661\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4727 - val_loss: 0.4652\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4716 - val_loss: 0.4645\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4705 - val_loss: 0.4638\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4695 - val_loss: 0.4624\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4685 - val_loss: 0.4616\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4675 - val_loss: 0.4611\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4665 - val_loss: 0.4600\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4655 - val_loss: 0.4596\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4648 - val_loss: 0.4585\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4639 - val_loss: 0.4577\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4631 - val_loss: 0.4569\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4621 - val_loss: 0.4559\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4613 - val_loss: 0.4553\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4605 - val_loss: 0.4548\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4595 - val_loss: 0.4540\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4590 - val_loss: 0.4535\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4582 - val_loss: 0.4530\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4574 - val_loss: 0.4523\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4567 - val_loss: 0.4518\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4559 - val_loss: 0.4509\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4552 - val_loss: 0.4507\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4546 - val_loss: 0.4500\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4537 - val_loss: 0.4490\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4530 - val_loss: 0.4483\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4522 - val_loss: 0.4480\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4515 - val_loss: 0.4474\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4508 - val_loss: 0.4465\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4501 - val_loss: 0.4461\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4493 - val_loss: 0.4456\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4487 - val_loss: 0.4450\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4478 - val_loss: 0.4449\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4474 - val_loss: 0.4439\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4466 - val_loss: 0.4431\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4459 - val_loss: 0.4424\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4453 - val_loss: 0.4419\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4447 - val_loss: 0.4416\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4441 - val_loss: 0.4409\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4435 - val_loss: 0.4406\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4429 - val_loss: 0.4399\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4423 - val_loss: 0.4395\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4416 - val_loss: 0.4392\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4411 - val_loss: 0.4387\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4405 - val_loss: 0.4381\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4399 - val_loss: 0.4380\n",
      "121/121 [==============================] - 0s 678us/step - loss: 0.5085\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 3.1668 - val_loss: 1.9741\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.7870 - val_loss: 1.2933\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2615 - val_loss: 1.0398\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0280 - val_loss: 0.9014\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8876 - val_loss: 0.8173\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8086 - val_loss: 0.7622\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7614 - val_loss: 0.7257\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7309 - val_loss: 0.7001\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7097 - val_loss: 0.6810\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6934 - val_loss: 0.6659\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6804 - val_loss: 0.6534\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6691 - val_loss: 0.6423\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6590 - val_loss: 0.6324\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6500 - val_loss: 0.6234\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6415 - val_loss: 0.6151\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6336 - val_loss: 0.6074\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6260 - val_loss: 0.5999\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6186 - val_loss: 0.5933\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6122 - val_loss: 0.5864\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6056 - val_loss: 0.5802\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5995 - val_loss: 0.5743\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5935 - val_loss: 0.5686\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5878 - val_loss: 0.5632\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5824 - val_loss: 0.5580\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5769 - val_loss: 0.5532\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5722 - val_loss: 0.5485\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5673 - val_loss: 0.5439\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5628 - val_loss: 0.5395\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5585 - val_loss: 0.5351\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5541 - val_loss: 0.5312\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5501 - val_loss: 0.5274\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5462 - val_loss: 0.5234\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5425 - val_loss: 0.5199\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5389 - val_loss: 0.5167\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5354 - val_loss: 0.5134\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5322 - val_loss: 0.5103\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5288 - val_loss: 0.5073\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5259 - val_loss: 0.5043\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5229 - val_loss: 0.5013\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5201 - val_loss: 0.4988\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5175 - val_loss: 0.4964\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5149 - val_loss: 0.4938\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5124 - val_loss: 0.4916\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5099 - val_loss: 0.4892\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5076 - val_loss: 0.4868\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5054 - val_loss: 0.4848\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5032 - val_loss: 0.4829\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5012 - val_loss: 0.4812\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4991 - val_loss: 0.4794\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4972 - val_loss: 0.4775\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4955 - val_loss: 0.4757\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4934 - val_loss: 0.4740\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4918 - val_loss: 0.4724\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4901 - val_loss: 0.4709\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4886 - val_loss: 0.4695\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4869 - val_loss: 0.4680\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4853 - val_loss: 0.4667\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4840 - val_loss: 0.4653\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4826 - val_loss: 0.4639\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4811 - val_loss: 0.4628\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4798 - val_loss: 0.4611\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4784 - val_loss: 0.4603\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4772 - val_loss: 0.4589\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4759 - val_loss: 0.4577\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4747 - val_loss: 0.4564\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4735 - val_loss: 0.4555\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4724 - val_loss: 0.4548\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4712 - val_loss: 0.4535\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4700 - val_loss: 0.4528\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4691 - val_loss: 0.4517\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4680 - val_loss: 0.4507\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4670 - val_loss: 0.4495\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4659 - val_loss: 0.4488\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4649 - val_loss: 0.4479\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4638 - val_loss: 0.4475\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4631 - val_loss: 0.4461\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4622 - val_loss: 0.4455\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4613 - val_loss: 0.4447\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4603 - val_loss: 0.4441\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4595 - val_loss: 0.4433\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4586 - val_loss: 0.4423\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4578 - val_loss: 0.4418\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4569 - val_loss: 0.4414\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4560 - val_loss: 0.4406\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4552 - val_loss: 0.4398\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4544 - val_loss: 0.4390\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4534 - val_loss: 0.4382\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4528 - val_loss: 0.4377\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4520 - val_loss: 0.4367\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4513 - val_loss: 0.4358\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4506 - val_loss: 0.4356\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4497 - val_loss: 0.4349\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4492 - val_loss: 0.4342\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4484 - val_loss: 0.4338\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4477 - val_loss: 0.4333\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4470 - val_loss: 0.4327\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4462 - val_loss: 0.4320\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4455 - val_loss: 0.4314\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4448 - val_loss: 0.4308\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4443 - val_loss: 0.4300\n",
      "121/121 [==============================] - 0s 682us/step - loss: 0.4421\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.0528 - val_loss: 0.8141\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8013 - val_loss: 0.6714\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6943 - val_loss: 0.5547\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5833 - val_loss: 0.5186\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5344 - val_loss: 0.4898\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5113 - val_loss: 0.4744\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5027 - val_loss: 0.4945\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4992 - val_loss: 0.4609\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4878 - val_loss: 0.4553\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4839 - val_loss: 0.4520\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4795 - val_loss: 0.4485\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4751 - val_loss: 0.4440\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4749 - val_loss: 0.4437\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4698 - val_loss: 0.4400\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4670 - val_loss: 0.4376\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4644 - val_loss: 0.4357\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4633 - val_loss: 0.4376\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4602 - val_loss: 0.4350\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4579 - val_loss: 0.4310\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4600 - val_loss: 0.4326\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4548 - val_loss: 0.4296\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4539 - val_loss: 0.4367\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4534 - val_loss: 0.4266\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4491 - val_loss: 0.4254\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4526 - val_loss: 0.4287\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4477 - val_loss: 0.4237\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4449 - val_loss: 0.4244\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4440 - val_loss: 0.4236\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4424 - val_loss: 0.4220\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4411 - val_loss: 0.4194\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4457 - val_loss: 0.4230\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4409 - val_loss: 0.4192\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4374 - val_loss: 0.4174\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4367 - val_loss: 0.4170\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4363 - val_loss: 0.4140\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4346 - val_loss: 0.4132\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4326 - val_loss: 0.4144\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4322 - val_loss: 0.4111\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4309 - val_loss: 0.4115\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4311 - val_loss: 0.4109\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4281 - val_loss: 0.4099\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4330 - val_loss: 0.4124\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4298 - val_loss: 0.4094\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4256 - val_loss: 0.4067\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4242 - val_loss: 0.4145\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4266 - val_loss: 0.4041\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4218 - val_loss: 0.4044\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4243 - val_loss: 0.4051\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4211 - val_loss: 0.4028\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4201 - val_loss: 0.4066\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4182 - val_loss: 0.4015\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4199 - val_loss: 0.4022\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4173 - val_loss: 0.4020\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4162 - val_loss: 0.3995\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4143 - val_loss: 0.3981\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4163 - val_loss: 0.3990\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4144 - val_loss: 0.3986\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4138 - val_loss: 0.4004\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4147 - val_loss: 0.3978\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4116 - val_loss: 0.3966\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4109 - val_loss: 0.3946\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4111 - val_loss: 0.3953\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4088 - val_loss: 0.3954\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4085 - val_loss: 0.3943\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4076 - val_loss: 0.3931\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4070 - val_loss: 0.3938\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4059 - val_loss: 0.3910\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4071 - val_loss: 0.4092\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4241 - val_loss: 0.3941\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4063 - val_loss: 0.3903\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4058 - val_loss: 0.3913\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4042 - val_loss: 0.3893\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4030 - val_loss: 0.3911\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4049 - val_loss: 0.3895\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4037 - val_loss: 0.3900\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4020 - val_loss: 0.3903\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4009 - val_loss: 0.3900\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4000 - val_loss: 0.3887\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3997 - val_loss: 0.3856\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3999 - val_loss: 0.3875\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4004 - val_loss: 0.3890\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3997 - val_loss: 0.3866\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3978 - val_loss: 0.3854\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4021 - val_loss: 0.3859\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3990 - val_loss: 0.3850\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3972 - val_loss: 0.3834\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4009 - val_loss: 0.3841\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3961 - val_loss: 0.3832\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3968 - val_loss: 0.3829\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3958 - val_loss: 0.3851\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4041 - val_loss: 0.3847\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3959 - val_loss: 0.3824\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3956 - val_loss: 0.3815\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3926 - val_loss: 0.3823\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3981 - val_loss: 0.3841\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3938 - val_loss: 0.3823\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3918 - val_loss: 0.3805\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3933 - val_loss: 0.3811\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3912 - val_loss: 0.3816\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3923 - val_loss: 0.4293\n",
      "121/121 [==============================] - 0s 634us/step - loss: 0.4320\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5491 - val_loss: 0.9522\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7248 - val_loss: 0.7507\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6244 - val_loss: 0.6411\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5736 - val_loss: 0.5771\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5444 - val_loss: 0.5327\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5225 - val_loss: 0.5052\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5071 - val_loss: 0.4884\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4954 - val_loss: 0.4783\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4873 - val_loss: 0.4710\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4810 - val_loss: 0.4673\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4756 - val_loss: 0.4663\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4718 - val_loss: 0.4645\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4679 - val_loss: 0.4641\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4643 - val_loss: 0.4635\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4617 - val_loss: 0.4650\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4593 - val_loss: 0.4628\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4568 - val_loss: 0.4660\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4552 - val_loss: 0.4618\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4535 - val_loss: 0.4613\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4514 - val_loss: 0.4603\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4498 - val_loss: 0.4600\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4481 - val_loss: 0.4622\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4465 - val_loss: 0.4607\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4451 - val_loss: 0.4580\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4433 - val_loss: 0.4607\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4425 - val_loss: 0.4574\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4410 - val_loss: 0.4572\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4397 - val_loss: 0.4559\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4381 - val_loss: 0.4552\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4372 - val_loss: 0.4529\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4358 - val_loss: 0.4536\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4337 - val_loss: 0.4526\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4330 - val_loss: 0.4497\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4318 - val_loss: 0.4483\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4308 - val_loss: 0.4479\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4293 - val_loss: 0.4458\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4281 - val_loss: 0.4437\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4268 - val_loss: 0.4424\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4263 - val_loss: 0.4381\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4248 - val_loss: 0.4382\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4240 - val_loss: 0.4353\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4228 - val_loss: 0.4356\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4213 - val_loss: 0.4350\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4207 - val_loss: 0.4318\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4197 - val_loss: 0.4292\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4179 - val_loss: 0.4285\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4172 - val_loss: 0.4252\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4164 - val_loss: 0.4254\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4152 - val_loss: 0.4234\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4145 - val_loss: 0.4220\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4126 - val_loss: 0.4208\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4117 - val_loss: 0.4209\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4111 - val_loss: 0.4189\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4097 - val_loss: 0.4171\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4087 - val_loss: 0.4161\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4073 - val_loss: 0.4179\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4067 - val_loss: 0.4129\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4056 - val_loss: 0.4122\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4046 - val_loss: 0.4116\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4035 - val_loss: 0.4119\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4024 - val_loss: 0.4111\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4014 - val_loss: 0.4097\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4012 - val_loss: 0.4077\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4002 - val_loss: 0.4073\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3997 - val_loss: 0.4056\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3984 - val_loss: 0.4049\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3977 - val_loss: 0.4038\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3964 - val_loss: 0.4038\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3957 - val_loss: 0.4031\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3954 - val_loss: 0.4012\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3947 - val_loss: 0.4020\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3941 - val_loss: 0.3994\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3934 - val_loss: 0.3991\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3920 - val_loss: 0.4004\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3924 - val_loss: 0.3974\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3911 - val_loss: 0.3972\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3896 - val_loss: 0.3969\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3896 - val_loss: 0.3955\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3889 - val_loss: 0.3955\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3884 - val_loss: 0.3956\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3876 - val_loss: 0.3949\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3873 - val_loss: 0.3942\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3856 - val_loss: 0.3936\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3857 - val_loss: 0.3936\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3853 - val_loss: 0.3947\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3850 - val_loss: 0.3942\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3841 - val_loss: 0.3923\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3832 - val_loss: 0.3914\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3831 - val_loss: 0.3905\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3827 - val_loss: 0.3910\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3817 - val_loss: 0.3914\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3813 - val_loss: 0.3892\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3807 - val_loss: 0.3906\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3805 - val_loss: 0.3884\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3801 - val_loss: 0.3887\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3799 - val_loss: 0.3878\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3794 - val_loss: 0.3886\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3779 - val_loss: 0.3887\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3783 - val_loss: 0.3865\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3775 - val_loss: 0.3895\n",
      "121/121 [==============================] - 0s 643us/step - loss: 0.4262\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.7310 - val_loss: 0.7894\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9798 - val_loss: 0.7516\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8193 - val_loss: 0.5689\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5592 - val_loss: 0.5198\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5303 - val_loss: 0.5010\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5142 - val_loss: 0.4887\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5019 - val_loss: 0.4801\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4913 - val_loss: 0.4715\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4818 - val_loss: 0.4630\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4777 - val_loss: 0.4593\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4739 - val_loss: 0.4619\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4666 - val_loss: 0.4482\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4652 - val_loss: 0.4455\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4593 - val_loss: 0.4427\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4534 - val_loss: 0.4401\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4526 - val_loss: 0.4367\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4481 - val_loss: 0.4345\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4430 - val_loss: 0.4359\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4405 - val_loss: 0.4317\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4379 - val_loss: 0.4274\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4373 - val_loss: 0.4410\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4349 - val_loss: 0.4231\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4311 - val_loss: 0.4267\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4299 - val_loss: 0.4217\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4271 - val_loss: 0.4228\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4277 - val_loss: 0.4200\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4257 - val_loss: 0.4161\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4225 - val_loss: 0.4156\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4216 - val_loss: 0.4138\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4205 - val_loss: 0.4140\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4206 - val_loss: 0.4145\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4179 - val_loss: 0.4115\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4163 - val_loss: 0.4116\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4150 - val_loss: 0.4081\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4146 - val_loss: 0.4141\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4147 - val_loss: 0.4078\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4118 - val_loss: 0.4052\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4107 - val_loss: 0.4064\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4096 - val_loss: 0.4054\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4089 - val_loss: 0.4032\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4070 - val_loss: 0.4017\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4062 - val_loss: 0.4014\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4055 - val_loss: 0.3999\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4050 - val_loss: 0.3999\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4031 - val_loss: 0.4000\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4043 - val_loss: 0.3997\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4013 - val_loss: 0.3989\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4016 - val_loss: 0.3949\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4009 - val_loss: 0.3953\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3993 - val_loss: 0.3943\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3995 - val_loss: 0.3935\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3979 - val_loss: 0.3926\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3966 - val_loss: 0.3981\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4071 - val_loss: 0.3929\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4032 - val_loss: 0.3935\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3978 - val_loss: 0.3903\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3995 - val_loss: 0.3923\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3942 - val_loss: 0.3886\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3928 - val_loss: 0.3909\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3932 - val_loss: 0.3899\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3918 - val_loss: 0.3993\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3938 - val_loss: 0.3906\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3927 - val_loss: 0.3872\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3941 - val_loss: 0.3880\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3895 - val_loss: 0.3847\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3882 - val_loss: 0.3864\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3900 - val_loss: 0.3916\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3867 - val_loss: 0.3906\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3923 - val_loss: 0.3845\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3917 - val_loss: 0.3840\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3874 - val_loss: 0.3816\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3855 - val_loss: 0.3849\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3885 - val_loss: 0.3821\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3847 - val_loss: 0.3819\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3847 - val_loss: 0.3846\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3837 - val_loss: 0.3808\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3831 - val_loss: 0.3808\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3816 - val_loss: 0.3822\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3821 - val_loss: 0.3798\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3813 - val_loss: 0.3793\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3852 - val_loss: 0.3806\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3841 - val_loss: 0.3785\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3804 - val_loss: 0.3797\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3798 - val_loss: 0.3774\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3805 - val_loss: 0.3765\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3899 - val_loss: 0.3793\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4038 - val_loss: 0.3782\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3792 - val_loss: 0.3764\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3787 - val_loss: 0.3764\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3824 - val_loss: 0.3806\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3890 - val_loss: 0.3750\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3782 - val_loss: 0.3767\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3772 - val_loss: 0.3749\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3780 - val_loss: 0.3752\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3760 - val_loss: 0.3762\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3775 - val_loss: 0.3744\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3832 - val_loss: 0.3773\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3995 - val_loss: 0.3746\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3836 - val_loss: 0.3753\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3799 - val_loss: 0.3728\n",
      "121/121 [==============================] - 0s 653us/step - loss: 0.3757\n",
      "Epoch 1/100\n",
      "  1/363 [..............................] - ETA: 54s - loss: 5.5193"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tuffy/venvs/.tf/lib/python3.10/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [-5.85485895e-01 -3.46677909e-01 -3.57387841e-01             nan\n",
      " -4.27793692e-01             nan -3.73092771e-01 -6.98091305e+20\n",
      " -4.60249235e-01 -4.11295513e-01]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - 1s 1ms/step - loss: 1.2644 - val_loss: 4.6440\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 0s 992us/step - loss: 9.0837 - val_loss: 0.5868\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 988us/step - loss: 0.8366 - val_loss: 0.5429\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 0s 994us/step - loss: 0.6175 - val_loss: 0.4787\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5165 - val_loss: 0.4552\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 0s 996us/step - loss: 0.4780 - val_loss: 0.4353\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 0s 990us/step - loss: 0.4553 - val_loss: 0.4337\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 0s 987us/step - loss: 0.4407 - val_loss: 0.4198\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 0s 986us/step - loss: 0.4304 - val_loss: 0.4139\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4238 - val_loss: 0.4115\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 0s 997us/step - loss: 0.4181 - val_loss: 0.4039\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 997us/step - loss: 0.4140 - val_loss: 0.4012\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 0s 982us/step - loss: 0.4096 - val_loss: 0.3982\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4064 - val_loss: 0.3963\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4030 - val_loss: 0.3947\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4003 - val_loss: 0.3900\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3976 - val_loss: 0.3875\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3946 - val_loss: 0.3864\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3920 - val_loss: 0.3863\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3897 - val_loss: 0.3818\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3874 - val_loss: 0.3790\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3854 - val_loss: 0.3776\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3833 - val_loss: 0.3758\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3812 - val_loss: 0.3759\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3788 - val_loss: 0.3741\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3770 - val_loss: 0.3713\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3755 - val_loss: 0.3690\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3730 - val_loss: 0.3680\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3714 - val_loss: 0.3685\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3693 - val_loss: 0.3665\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3681 - val_loss: 0.3682\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3666 - val_loss: 0.3655\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3655 - val_loss: 0.3631\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 0s 990us/step - loss: 0.3635 - val_loss: 0.3656\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 0s 990us/step - loss: 0.3627 - val_loss: 0.3614\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 0s 990us/step - loss: 0.3611 - val_loss: 0.3594\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3598 - val_loss: 0.3609\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 0s 988us/step - loss: 0.3588 - val_loss: 0.3609\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3579 - val_loss: 0.3592\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3567 - val_loss: 0.3579\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3565 - val_loss: 0.3553\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3545 - val_loss: 0.3579\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3535 - val_loss: 0.3536\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3522 - val_loss: 0.3532\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3519 - val_loss: 0.3538\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3508 - val_loss: 0.3539\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3524 - val_loss: 0.3514\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3502 - val_loss: 0.3523\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3488 - val_loss: 0.3515\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3471 - val_loss: 0.3514\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 0s 984us/step - loss: 0.3456 - val_loss: 0.3502\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3451 - val_loss: 0.3511\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 0s 996us/step - loss: 0.3442 - val_loss: 0.3479\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3428 - val_loss: 0.3487\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3458 - val_loss: 0.3471\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3421 - val_loss: 0.3466\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3410 - val_loss: 0.3459\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3405 - val_loss: 0.3450\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 0s 982us/step - loss: 0.3395 - val_loss: 0.3433\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 0s 994us/step - loss: 0.3381 - val_loss: 0.3461\n",
      "Epoch 61/100\n",
      "363/363 [==============================] - 0s 985us/step - loss: 0.3378 - val_loss: 0.3476\n",
      "Epoch 62/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3373 - val_loss: 0.3414\n",
      "Epoch 63/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3361 - val_loss: 0.3469\n",
      "Epoch 64/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3358 - val_loss: 0.3427\n",
      "Epoch 65/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3351 - val_loss: 0.3420\n",
      "Epoch 66/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3359 - val_loss: 0.3410\n",
      "Epoch 67/100\n",
      "363/363 [==============================] - 0s 993us/step - loss: 0.3334 - val_loss: 0.3450\n",
      "Epoch 68/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3325 - val_loss: 0.3435\n",
      "Epoch 69/100\n",
      "363/363 [==============================] - 0s 999us/step - loss: 0.3353 - val_loss: 0.3404\n",
      "Epoch 70/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3335 - val_loss: 0.3384\n",
      "Epoch 71/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3311 - val_loss: 0.3411\n",
      "Epoch 72/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3311 - val_loss: 0.3385\n",
      "Epoch 73/100\n",
      "363/363 [==============================] - 0s 999us/step - loss: 0.3334 - val_loss: 0.3355\n",
      "Epoch 74/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3335 - val_loss: 0.3389\n",
      "Epoch 75/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3352 - val_loss: 0.3397\n",
      "Epoch 76/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3297 - val_loss: 0.3460\n",
      "Epoch 77/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3415 - val_loss: 0.3352\n",
      "Epoch 78/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3280 - val_loss: 0.3376\n",
      "Epoch 79/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3268 - val_loss: 0.3397\n",
      "Epoch 80/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3267 - val_loss: 0.3340\n",
      "Epoch 81/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3258 - val_loss: 0.3357\n",
      "Epoch 82/100\n",
      "363/363 [==============================] - 0s 999us/step - loss: 0.3255 - val_loss: 0.3334\n",
      "Epoch 83/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3248 - val_loss: 0.3336\n",
      "Epoch 84/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3254 - val_loss: 0.3327\n",
      "Epoch 85/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3248 - val_loss: 0.3314\n",
      "Epoch 86/100\n",
      "363/363 [==============================] - 0s 998us/step - loss: 0.3235 - val_loss: 0.3315\n",
      "Epoch 87/100\n",
      "363/363 [==============================] - 0s 991us/step - loss: 0.3226 - val_loss: 0.3324\n",
      "Epoch 88/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3221 - val_loss: 0.3348\n",
      "Epoch 89/100\n",
      "363/363 [==============================] - 0s 985us/step - loss: 0.3237 - val_loss: 0.3351\n",
      "Epoch 90/100\n",
      "363/363 [==============================] - 0s 987us/step - loss: 0.3217 - val_loss: 0.3307\n",
      "Epoch 91/100\n",
      "363/363 [==============================] - 0s 998us/step - loss: 0.3215 - val_loss: 0.3337\n",
      "Epoch 92/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3218 - val_loss: 0.3302\n",
      "Epoch 93/100\n",
      "363/363 [==============================] - 0s 995us/step - loss: 0.3214 - val_loss: 0.3290\n",
      "Epoch 94/100\n",
      "363/363 [==============================] - 0s 989us/step - loss: 0.3195 - val_loss: 0.3297\n",
      "Epoch 95/100\n",
      "363/363 [==============================] - 0s 994us/step - loss: 0.3195 - val_loss: 0.3283\n",
      "Epoch 96/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3192 - val_loss: 0.3288\n",
      "Epoch 97/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3209 - val_loss: 0.3312\n",
      "Epoch 98/100\n",
      "363/363 [==============================] - 0s 997us/step - loss: 0.3187 - val_loss: 0.3273\n",
      "Epoch 99/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3201 - val_loss: 0.3276\n",
      "Epoch 100/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3176 - val_loss: 0.3269\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=&lt;keras.wrappers.scikit_learn.KerasRegressor object at 0x7fe705054700&gt;,\n",
       "                   param_distributions={&#x27;learning_rate&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7fe6dc319300&gt;,\n",
       "                                        &#x27;n_hidden&#x27;: [0, 1, 2, 3],\n",
       "                                        &#x27;n_neurons&#x27;: array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
       "       52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,\n",
       "       69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85,\n",
       "       86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=&lt;keras.wrappers.scikit_learn.KerasRegressor object at 0x7fe705054700&gt;,\n",
       "                   param_distributions={&#x27;learning_rate&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7fe6dc319300&gt;,\n",
       "                                        &#x27;n_hidden&#x27;: [0, 1, 2, 3],\n",
       "                                        &#x27;n_neurons&#x27;: array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
       "       52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,\n",
       "       69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85,\n",
       "       86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KerasRegressor</label><div class=\"sk-toggleable__content\"><pre>&lt;keras.wrappers.scikit_learn.KerasRegressor object at 0x7fe705054700&gt;</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KerasRegressor</label><div class=\"sk-toggleable__content\"><pre>&lt;keras.wrappers.scikit_learn.KerasRegressor object at 0x7fe705054700&gt;</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=<keras.wrappers.scikit_learn.KerasRegressor object at 0x7fe705054700>,\n",
       "                   param_distributions={'learning_rate': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7fe6dc319300>,\n",
       "                                        'n_hidden': [0, 1, 2, 3],\n",
       "                                        'n_neurons': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
       "       52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,\n",
       "       69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85,\n",
       "       86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distribs={\n",
    "    'n_hidden': [0,1,2,3],\n",
    "    'n_neurons': np.arange(1,100),\n",
    "    'learning_rate': reciprocal(3e-4, 3e-2),\n",
    "}\n",
    "\n",
    "rnd_search_cv=RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3)\n",
    "rnd_search_cv.fit(X_train, y_train, epochs=100,\n",
    "                 validation_data=(X_valid, y_valid),\n",
    "                 callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48144b61-6a49-4547-9bd1-55f4248bd5c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.004451635554021628, 'n_hidden': 1, 'n_neurons': 47}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8252831-9079-4fef-a073-8e1722b76f21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.3466779092947642"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3c559f7-37bb-422e-9966-69d2c768f1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=rnd_search_cv.best_estimator_.model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75dbd802-c429-49f6-b8e0-03dd9bcc3517",
   "metadata": {},
   "source": [
    "本で紹介されているハイパーパラメータチューニング用ライブラリ\n",
    "\n",
    "[Hyperopt](https://github.com/hyperopt/hyperopt): popular。\n",
    "\n",
    "[Hyperas](https://github.com/maxpumperla/hyperas), [kopt](https://github.com/Avsecz/kopt), [Talos](https://github.com/autonomio/talos):　dKerasモデルの最適化。有用。\n",
    "\n",
    "[Keras Tuner](https://keras.io/keras_tuner/): GoogleのKeras専用ライブラリ、使い勝手良。\n",
    "\n",
    "[Scikit-Optimize](https://scikit-optimize.github.io/stable/): 汎用。ベイズ最適化。\n",
    "\n",
    "[Spearmint](https://github.com/JasperSnoek/spearmint): ベイズ最適化。\n",
    "\n",
    "[Hyperband](https://github.com/zygmuntz/hyperband): 高速。Lisha Li et al.\n",
    "\n",
    "[Sklearn-Deap](https://github.com/rsteca/sklearn-deap): 進化計算。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3629b28-9ad0-4a34-b018-3422e65b74f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_tf",
   "language": "python",
   "name": "ml_tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
