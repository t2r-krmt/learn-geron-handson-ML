{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbe241a5-1ede-4685-91e1-52f633b781bc",
   "metadata": {
    "tags": []
   },
   "source": [
    "# From Biological to Artificial Neural Networks with Keras\n",
    "## The Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3dc933e2-47f5-4c9e-8914-98a97ad49343",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "iris=load_iris()\n",
    "X=iris.data[:,(2,3)]\n",
    "y=(iris.target==0).astype(np.int32)\n",
    "\n",
    "per_clf=Perceptron()\n",
    "per_clf.fit(X,y)\n",
    "\n",
    "y_pred=per_clf.predict([[2,0.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab2ba832-418e-41fc-856b-c3f33822b605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2275b3e2-61d4-4ab2-ba07-5d9c3a04b03c",
   "metadata": {},
   "source": [
    "# Implementing MLPs with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2437b9-b465-48e2-98b0-4fb7a49492f4",
   "metadata": {},
   "source": [
    "## Installing TensorFlow 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d57bcc0-ea24-425b-9b1c-172a6fe8171f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.1\n",
      "2.9.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1611948-1d08-4a21-b9ae-53a1783bc727",
   "metadata": {},
   "source": [
    "## Building an Image Classifier Using the Sequential API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c374eb49-5e16-46ac-a628-e68532d1da31",
   "metadata": {},
   "source": [
    "[fashion_mnist](https://keras.io/ja/datasets/#fashion-mnist): 10種類のファッションカテゴリの白黒画像。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c90fdd56-2c91-414f-865f-6df0d24e75fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist=keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test)=fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb2962bc-8c47-4407-9233-415d367c298e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "uint8\n"
     ]
    }
   ],
   "source": [
    "print(X_train_full.shape)\n",
    "print(X_train_full.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c200185c-5e47-4526-b4ee-690fc20d3b8b",
   "metadata": {},
   "source": [
    "訓練データと検証データに分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bb9ec3a-382c-4a3c-a69b-3a52dfc62ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, X_train=X_train_full[:5000] /255.0, X_train_full[5000:]/255.0\n",
    "y_valid, y_train=y_train_full[:5000], y_train_full[5000:]\n",
    "class_names=[\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "             \"Sandal\", \"Shirt\",\"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00616946-f092-4cbc-b808-43a163cf0fee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Coat'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names[y_train[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2baf5318-a295-4767-a6b0-101f756325a3",
   "metadata": {},
   "source": [
    "[Sequential](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential): レイヤーをスタックしたモデル。\n",
    "\n",
    "[Flatten](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Flatten): インプットの平坦化。\n",
    "\n",
    "[Dense](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense): densely-connected layer(全結合層）。引数にノード数、活性化層の指定、重みの初期化・正規化などがある。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98d56469-3d5f-4f96-bea6-142ff4e60c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-17 08:30:23.516978: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-17 08:30:23.598177: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-17 08:30:23.598297: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-17 08:30:23.598939: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-17 08:30:23.600147: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-17 08:30:23.600247: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-17 08:30:23.600329: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-17 08:30:24.069673: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-17 08:30:24.069797: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-17 08:30:24.069884: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-17 08:30:24.069956: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10237 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28,28]))\n",
    "model.add(keras.layers.Dense(300,activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(100,activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(10,activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651e4177-e236-4305-8647-2d5de74e530a",
   "metadata": {},
   "source": [
    "こういう書き方もできる\n",
    "```\n",
    "model=keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28,28]),\n",
    "    keras.layers.Dense(300,activation=\"relu\"),\n",
    "    keras.layers.Dense(100,activation=\"relu\"),\n",
    "    keras.layers.Dense(10,activation=\"softmax\")\n",
    "])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96f4de8d-83bf-46e0-b007-2c2a1acbdf72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 300)               235500    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               30100     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "378103d2-73d0-4619-bcbc-57f0c965a976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.reshaping.flatten.Flatten at 0x7fa6a76e39a0>,\n",
       " <keras.layers.core.dense.Dense at 0x7fa5e94f9450>,\n",
       " <keras.layers.core.dense.Dense at 0x7fa5e94fa110>,\n",
       " <keras.layers.core.dense.Dense at 0x7fa5e94fa290>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d040ebb-8c79-479f-842a-cea865d3aad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dense'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden1=model.layers[1]\n",
    "hidden1.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9cd8df9f-c377-4457-9085-352d4735bf47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer('dense') is hidden1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be60ca7f-1ea4-48fb-9a8a-c7514828faba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.02562279, -0.04368459,  0.01297612, ...,  0.06200144,\n",
       "         0.01040802, -0.05150122],\n",
       "       [ 0.01404244,  0.03016172, -0.05026346, ...,  0.04337574,\n",
       "        -0.03277767,  0.00190412],\n",
       "       [-0.0233185 ,  0.05650312,  0.05455136, ...,  0.07339451,\n",
       "         0.00934496,  0.04164387],\n",
       "       ...,\n",
       "       [-0.04683386, -0.05464973, -0.02458339, ...,  0.01695506,\n",
       "         0.03523325,  0.02918477],\n",
       "       [-0.03161748,  0.00814341,  0.01213507, ..., -0.01362381,\n",
       "        -0.0371596 , -0.01980399],\n",
       "       [ 0.03220171,  0.06527303, -0.01189899, ..., -0.02780654,\n",
       "        -0.0019358 , -0.05394789]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights, biases=hidden1.get_weights()\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "662b6ffa-24af-4d66-ad5a-de5aaa4121ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d311aeb2-7739-426d-be2c-edad66827ced",
   "metadata": {},
   "source": [
    "weightsはランダムに初期化された状態。biasesは0。Dense()の引数で`kernel_initializer`を指定すると異なる初期化法を使える。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5569da17-269c-4021-b607-620b6ccce1d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 300)\n",
      "(300,)\n"
     ]
    }
   ],
   "source": [
    "print(weights.shape)\n",
    "print(biases.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4537140e-7c79-4e0f-bcf4-a1b12b37b0c8",
   "metadata": {},
   "source": [
    "### Compiling the model\n",
    "損失関数やオプティマイザを指定するために`compile`が必要。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9fdcb91-893f-43e5-8bd1-b0a7c4f5ed89",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "             optimizer='sgd',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a42ede9-4a95-4d80-9547-50ca11dd8965",
   "metadata": {},
   "source": [
    "`sparse_categorical_crossentropy`は排他的な0-9のインデックスを求める今回の問題のような時に使用。  \n",
    "one-hotベクトルの場合は`categorical_crossentropy`を使う。  \n",
    "2値分類なら`binary_crossentropy`。その場合最終層の活性化は`sigmoid`にする。\n",
    "\n",
    "`optimizer='sgd'`は学習率が0.01固定なので、文字列指定よりも`optimizer=keras.optimizers.SGD(lr=???)`とするのが一般的。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db3d0ed-c9c1-4a83-8666-9c2a1c467121",
   "metadata": {},
   "source": [
    "### Training and evaluating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c940ae-06b5-410f-9d64-d048ae887851",
   "metadata": {},
   "source": [
    "訓練データだけでなく検証データも一緒に渡している（これはオプション）。エポックごとにlossとmetrics(ここではaccuracy)を測れる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32b8bdf1-a645-4b58-800a-fa559df06458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 157/1719 [=>............................] - ETA: 1s - loss: 1.4616 - accuracy: 0.5603"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-17 08:30:56.806195: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.7161 - accuracy: 0.7631 - val_loss: 0.5142 - val_accuracy: 0.8266\n",
      "Epoch 2/30\n",
      "1719/1719 [==============================] - 2s 976us/step - loss: 0.4897 - accuracy: 0.8301 - val_loss: 0.4421 - val_accuracy: 0.8530\n",
      "Epoch 3/30\n",
      "1719/1719 [==============================] - 2s 998us/step - loss: 0.4447 - accuracy: 0.8441 - val_loss: 0.4130 - val_accuracy: 0.8596\n",
      "Epoch 4/30\n",
      "1719/1719 [==============================] - 2s 993us/step - loss: 0.4177 - accuracy: 0.8547 - val_loss: 0.4266 - val_accuracy: 0.8470\n",
      "Epoch 5/30\n",
      "1719/1719 [==============================] - 2s 995us/step - loss: 0.3959 - accuracy: 0.8622 - val_loss: 0.4003 - val_accuracy: 0.8648\n",
      "Epoch 6/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3793 - accuracy: 0.8666 - val_loss: 0.3819 - val_accuracy: 0.8680\n",
      "Epoch 7/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3653 - accuracy: 0.8712 - val_loss: 0.3654 - val_accuracy: 0.8720\n",
      "Epoch 8/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3539 - accuracy: 0.8748 - val_loss: 0.3562 - val_accuracy: 0.8716\n",
      "Epoch 9/30\n",
      "1719/1719 [==============================] - 2s 994us/step - loss: 0.3434 - accuracy: 0.8779 - val_loss: 0.3610 - val_accuracy: 0.8702\n",
      "Epoch 10/30\n",
      "1719/1719 [==============================] - 2s 985us/step - loss: 0.3340 - accuracy: 0.8816 - val_loss: 0.3552 - val_accuracy: 0.8764\n",
      "Epoch 11/30\n",
      "1719/1719 [==============================] - 2s 995us/step - loss: 0.3253 - accuracy: 0.8844 - val_loss: 0.3307 - val_accuracy: 0.8804\n",
      "Epoch 12/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3171 - accuracy: 0.8855 - val_loss: 0.3703 - val_accuracy: 0.8686\n",
      "Epoch 13/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3109 - accuracy: 0.8872 - val_loss: 0.3258 - val_accuracy: 0.8848\n",
      "Epoch 14/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3037 - accuracy: 0.8908 - val_loss: 0.3369 - val_accuracy: 0.8788\n",
      "Epoch 15/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2972 - accuracy: 0.8938 - val_loss: 0.3212 - val_accuracy: 0.8880\n",
      "Epoch 16/30\n",
      "1719/1719 [==============================] - 2s 997us/step - loss: 0.2915 - accuracy: 0.8957 - val_loss: 0.3179 - val_accuracy: 0.8844\n",
      "Epoch 17/30\n",
      "1719/1719 [==============================] - 2s 980us/step - loss: 0.2855 - accuracy: 0.8975 - val_loss: 0.3184 - val_accuracy: 0.8856\n",
      "Epoch 18/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2807 - accuracy: 0.8984 - val_loss: 0.3209 - val_accuracy: 0.8846\n",
      "Epoch 19/30\n",
      "1719/1719 [==============================] - 2s 986us/step - loss: 0.2746 - accuracy: 0.9000 - val_loss: 0.3090 - val_accuracy: 0.8888\n",
      "Epoch 20/30\n",
      "1719/1719 [==============================] - 2s 971us/step - loss: 0.2694 - accuracy: 0.9033 - val_loss: 0.3036 - val_accuracy: 0.8908\n",
      "Epoch 21/30\n",
      "1719/1719 [==============================] - 2s 974us/step - loss: 0.2658 - accuracy: 0.9037 - val_loss: 0.3035 - val_accuracy: 0.8936\n",
      "Epoch 22/30\n",
      "1719/1719 [==============================] - 2s 999us/step - loss: 0.2604 - accuracy: 0.9048 - val_loss: 0.3059 - val_accuracy: 0.8904\n",
      "Epoch 23/30\n",
      "1719/1719 [==============================] - 2s 990us/step - loss: 0.2567 - accuracy: 0.9070 - val_loss: 0.3007 - val_accuracy: 0.8936\n",
      "Epoch 24/30\n",
      "1719/1719 [==============================] - 2s 969us/step - loss: 0.2508 - accuracy: 0.9098 - val_loss: 0.3049 - val_accuracy: 0.8894\n",
      "Epoch 25/30\n",
      "1719/1719 [==============================] - 2s 979us/step - loss: 0.2470 - accuracy: 0.9108 - val_loss: 0.3013 - val_accuracy: 0.8870\n",
      "Epoch 26/30\n",
      "1719/1719 [==============================] - 2s 985us/step - loss: 0.2430 - accuracy: 0.9117 - val_loss: 0.3375 - val_accuracy: 0.8834\n",
      "Epoch 27/30\n",
      "1719/1719 [==============================] - 2s 998us/step - loss: 0.2380 - accuracy: 0.9141 - val_loss: 0.2939 - val_accuracy: 0.8914\n",
      "Epoch 28/30\n",
      "1719/1719 [==============================] - 2s 970us/step - loss: 0.2346 - accuracy: 0.9154 - val_loss: 0.3122 - val_accuracy: 0.8864\n",
      "Epoch 29/30\n",
      "1719/1719 [==============================] - 2s 971us/step - loss: 0.2310 - accuracy: 0.9168 - val_loss: 0.3020 - val_accuracy: 0.8896\n",
      "Epoch 30/30\n",
      "1719/1719 [==============================] - 2s 988us/step - loss: 0.2277 - accuracy: 0.9179 - val_loss: 0.3065 - val_accuracy: 0.8856\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e558cb-9fd4-4877-849e-95d0ad4c4382",
   "metadata": {},
   "source": [
    "fitの出力であるHistoryをプロットする。\n",
    "\n",
    "Historyは以下の要素を含む。\n",
    "- params: トレーニングパラメータ\n",
    "- epoch: epochのリスト\n",
    "- history: epochごとのlossとmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80f33db8-8c20-444e-ba4c-a3b11733c31a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283034e3-7c61-4e76-a47f-2f70a7b25b6c",
   "metadata": {},
   "source": [
    "テストデータに対するエラーを見積もる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b9bac4b8-6fb3-4f7e-a1a6-8dc86c93810d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 771us/step - loss: 62.0189 - accuracy: 0.8450\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[62.01890182495117, 0.8450000286102295]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61bde22-48c8-469b-aba0-fb8528999b7c",
   "metadata": {},
   "source": [
    "### Using the model to make predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b95921b-af88-471c-b5db-dc26d42ab8df",
   "metadata": {},
   "source": [
    "テストデータの一部を使って予測を試す。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4423c7e-b256-4311-8668-e04942937a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 46ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new=X_test[:3]\n",
    "y_proba=model.predict(X_new)\n",
    "y_proba.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c82411f-1b1b-49d0-b1f4-c224554afc0c",
   "metadata": {},
   "source": [
    "one-hotベクトルのようになっているが、実際は各クラスの確率が出ている。  \n",
    "`np.argmax`で最大のインデックスを取得する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5cde3b0e-ecb3-4bb2-97b6-3157c241f4dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#y_pred=model.predict_classes(X_new) # deprecated\n",
    "y_pred=np.argmax(y_proba, axis=-1) \n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d9dbc626-d9a4-4043-be78-1e131740a685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ankle boot', 'Pullover', 'Trouser'], dtype='<U11')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(class_names)[y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe057c97-9701-4834-a614-9b42384f9c80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1], dtype=uint8)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_new= y_test[:3]\n",
    "y_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1897363-6381-491a-a134-6267bed12b91",
   "metadata": {},
   "source": [
    "## Building a Regression MLP Using the Sequential API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eae5841-f27c-48e0-a6ec-c882ab8073c4",
   "metadata": {},
   "source": [
    "回帰問題としてカリフォルニア住宅価格を扱う。\n",
    "\n",
    "[California Housing dataset](https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset): 1990のUSセンサス。\n",
    "\n",
    "X: 8属性\n",
    "- MedInc: median income in block group\n",
    "- HouseAge: median house age in block group\n",
    "- AveRooms: average number of rooms per household\n",
    "- AveBedrms: average number of bedrooms per household\n",
    "- Population: block group population\n",
    "- AveOccup: average number of household members\n",
    "- Latitude: block group latitude\n",
    "- Longitude: block group longitude\n",
    "\n",
    "y: 住宅価格の中央値、単位$100,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "634b70d2-df89-4a47-96c8-cf98db28812d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing=fetch_california_housing()\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target)\n",
    "X_train, X_valid, y_train, y_valid=train_test_split(X_train_full, y_train_full)\n",
    "\n",
    "scaler=StandardScaler()\n",
    "X_train=scaler.fit_transform(X_train)\n",
    "X_valid=scaler.transform(X_valid)\n",
    "X_test=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2ead8c2d-2672-44e5-b944-3b7c4cbd44d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _california_housing_dataset:\n",
      "\n",
      "California Housing dataset\n",
      "--------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 20640\n",
      "\n",
      "    :Number of Attributes: 8 numeric, predictive attributes and the target\n",
      "\n",
      "    :Attribute Information:\n",
      "        - MedInc        median income in block group\n",
      "        - HouseAge      median house age in block group\n",
      "        - AveRooms      average number of rooms per household\n",
      "        - AveBedrms     average number of bedrooms per household\n",
      "        - Population    block group population\n",
      "        - AveOccup      average number of household members\n",
      "        - Latitude      block group latitude\n",
      "        - Longitude     block group longitude\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "This dataset was obtained from the StatLib repository.\n",
      "https://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html\n",
      "\n",
      "The target variable is the median house value for California districts,\n",
      "expressed in hundreds of thousands of dollars ($100,000).\n",
      "\n",
      "This dataset was derived from the 1990 U.S. census, using one row per census\n",
      "block group. A block group is the smallest geographical unit for which the U.S.\n",
      "Census Bureau publishes sample data (a block group typically has a population\n",
      "of 600 to 3,000 people).\n",
      "\n",
      "An household is a group of people residing within a home. Since the average\n",
      "number of rooms and bedrooms in this dataset are provided per household, these\n",
      "columns may take surpinsingly large values for block groups with few households\n",
      "and many empty houses, such as vacation resorts.\n",
      "\n",
      "It can be downloaded/loaded using the\n",
      ":func:`sklearn.datasets.fetch_california_housing` function.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n",
      "      Statistics and Probability Letters, 33 (1997) 291-297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(housing.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "50082072-1a15-497c-8d3c-786a57007ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11610, 8)\n",
      "['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude']\n",
      "[0.557 2.132 3.596]\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(housing.feature_names)\n",
    "print(y_train[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c44b88c-41bd-410b-8f5e-76c85b386057",
   "metadata": {},
   "source": [
    "分類器と同様にSequential APIを用いる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9341f745-4284-4151-943f-d84f210d071b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d29b6f91-cdbb-4ce6-94a6-f256530aea56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.8794 - val_loss: 0.5465\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 975us/step - loss: 0.4864 - val_loss: 0.4844\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 968us/step - loss: 0.4400 - val_loss: 0.4477\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 977us/step - loss: 0.4157 - val_loss: 0.4315\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 958us/step - loss: 0.4278 - val_loss: 0.4347\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 965us/step - loss: 0.3946 - val_loss: 0.4114\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 993us/step - loss: 0.3949 - val_loss: 0.4043\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 970us/step - loss: 0.3818 - val_loss: 0.3975\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 996us/step - loss: 0.3756 - val_loss: 0.4006\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3774 - val_loss: 0.3912\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 985us/step - loss: 0.3710 - val_loss: 0.3875\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 972us/step - loss: 0.3683 - val_loss: 0.4029\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 978us/step - loss: 0.3687 - val_loss: 0.3860\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 991us/step - loss: 0.3619 - val_loss: 0.3817\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 989us/step - loss: 0.3595 - val_loss: 0.3773\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3572 - val_loss: 0.3810\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 972us/step - loss: 0.3573 - val_loss: 0.3887\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 984us/step - loss: 0.3540 - val_loss: 0.3762\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 986us/step - loss: 0.3516 - val_loss: 0.3717\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 990us/step - loss: 0.3518 - val_loss: 0.3688\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "87cf2661-0e8d-4eb1-974f-ac41aa7740a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 670us/step - loss: 0.3650\n"
     ]
    }
   ],
   "source": [
    "mse_test=model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d424d01-117e-4cea-8b2e-4bd570ef0a54",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m X_new\u001b[38;5;241m=\u001b[39mX_test[:\u001b[38;5;241m3\u001b[39m]\n\u001b[0;32m----> 2\u001b[0m y_pred\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(X_new)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "X_new=X_test[:3]\n",
    "y_pred=model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8cf5e2af-452a-4cc3-9329-2d7e8673d24b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3649982810020447"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a7bec5cf-7149-4d96-a5dc-0265744bea6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.2030156]\n",
      " [1.1833708]\n",
      " [3.4015732]]\n",
      "[1.917 1.518 3.246]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)\n",
    "print(y_test[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cc15bb-f192-4fb2-9748-60c84f6153d1",
   "metadata": {},
   "source": [
    "## Building Complex Models Using the Functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a164965b-8d55-453c-b62a-2c4eb907d43a",
   "metadata": {},
   "source": [
    "より複雑なネットワークを構築するにはFunctional APIを用いる。\n",
    "\n",
    "前層を関数の引数のように与えているのがFuctionalの所以。この時点ではデータは処理しておらず接続を指定しているだけ。\n",
    "\n",
    "[Input](https://www.tensorflow.org/api_docs/python/tf/keras/Input)\n",
    "\n",
    "[Concatenate](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Concatenate): 使い方が違うだけで[concatenate](https://www.tensorflow.org/api_docs/python/tf/keras/layers/concatenate)と同じ。\n",
    "\n",
    "[Model](https://www.tensorflow.org/api_docs/python/tf/keras/Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "05fce635-6bf9-4865-b523-c4092a68d16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_=keras.layers.Input(shape=X_train.shape[1:])\n",
    "hidden1=keras.layers.Dense(30, activation=\"relu\")(input_)\n",
    "hidden2=keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat=keras.layers.Concatenate()([input_,hidden2])\n",
    "output=keras.layers.Dense(1)(concat)\n",
    "model=keras.models.Model(inputs=[input_], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4abcd785-1a77-4c60-88a0-b9258ed861fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.8757 - val_loss: 0.8398\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7515 - val_loss: 0.7291\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6691 - val_loss: 0.6706\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6197 - val_loss: 0.6282\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5828 - val_loss: 0.5963\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5549 - val_loss: 0.5717\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5333 - val_loss: 0.5512\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5151 - val_loss: 0.5362\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4999 - val_loss: 0.5216\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4878 - val_loss: 0.5095\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4767 - val_loss: 0.4995\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4671 - val_loss: 0.4909\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4585 - val_loss: 0.4832\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4517 - val_loss: 0.4752\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4447 - val_loss: 0.4687\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4388 - val_loss: 0.4624\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4330 - val_loss: 0.4578\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4284 - val_loss: 0.4528\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4235 - val_loss: 0.4502\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4197 - val_loss: 0.4448\n",
      "162/162 [==============================] - 0s 646us/step - loss: 0.4357\n",
      "1/1 [==============================] - 0s 31ms/step\n"
     ]
    }
   ],
   "source": [
    "# SGDのlrを1e-3にすると計算が安定\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
    "history=model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))\n",
    "mse_test=model.evaluate(X_test,y_test)\n",
    "y_pred=model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6cbea270-7e9a-410b-909c-e1688a6a6fb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43570390343666077"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6dcf0abd-8d50-4257-8520-628f9e469a15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.1152503],\n",
       "       [1.1895642],\n",
       "       [3.3124235]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48243a6-dd28-4d66-be7c-c4907d9fa3c6",
   "metadata": {},
   "source": [
    "インプットが２つの場合を考える。\n",
    "\n",
    "カリフォルニアデータセットのうち、 インデックス0-4の特徴量（５つ）をinput_A、2-７の特徴量（６つ）をinput_Bとする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "36dc61da-9a4b-46a2-80e8-271d3e50185d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A=keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B=keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden1=keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2=keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat=keras.layers.concatenate([input_A,hidden2])\n",
    "output=keras.layers.Dense(1, name = \"output\")(concat)\n",
    "model=keras.models.Model(inputs=[input_A, input_B], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f34b3b4d-70aa-4b5c-bca6-6fccc049cd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddc18d9-1e72-48ca-8136-b958a3b9333e",
   "metadata": {},
   "source": [
    "データを次のように分離。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b08e6b35-46ad-44dd-8d54-571fd279341b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_A, X_train_B = X_train[:,:5], X_train[:, 2:]\n",
    "X_valid_A, X_valid_B = X_valid[:,:5], X_valid[:, 2:]\n",
    "X_test_A, X_test_B = X_test[:,:5], X_test[:, 2:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8370ac37-1e4c-4fd6-93ed-0814e389f02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.7151 - val_loss: 0.8653\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7898 - val_loss: 0.7672\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7182 - val_loss: 0.7153\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6739 - val_loss: 0.6789\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6395 - val_loss: 0.6464\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6105 - val_loss: 0.6210\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5853 - val_loss: 0.5995\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5636 - val_loss: 0.5782\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5441 - val_loss: 0.5600\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5277 - val_loss: 0.5459\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5135 - val_loss: 0.5334\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5019 - val_loss: 0.5238\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4919 - val_loss: 0.5148\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4834 - val_loss: 0.5074\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4762 - val_loss: 0.5001\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4695 - val_loss: 0.4942\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4641 - val_loss: 0.4897\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4590 - val_loss: 0.4851\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4542 - val_loss: 0.4809\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4499 - val_loss: 0.4764\n",
      "162/162 [==============================] - 0s 690us/step - loss: 0.4661\n",
      "1/1 [==============================] - 0s 30ms/step\n"
     ]
    }
   ],
   "source": [
    "history=model.fit((X_train_A, X_train_B), y_train, epochs=20, validation_data=((X_valid_A, X_valid_B), y_valid))\n",
    "mse_test=model.evaluate((X_test_A,X_test_B),y_test)\n",
    "y_pred=model.predict((X_new_A,X_new_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233cb42a-6780-438e-9c9f-0741578f2da9",
   "metadata": {},
   "source": [
    "アウトプットが２つの場合。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bc6f61eb-95ba-416d-9afb-3a5ba0925e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A=keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B=keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden1=keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2=keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat=keras.layers.concatenate([input_A,hidden2])\n",
    "output=keras.layers.Dense(1, name = \"main_output\")(concat)\n",
    "aux_output=keras.layers.Dense(1, name = \"aux_output\")(hidden2)\n",
    "model=keras.models.Model(inputs=[input_A, input_B], outputs=[output, aux_output])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee52e33-d272-4d01-8fe8-07915fa7c44e",
   "metadata": {},
   "source": [
    "アウトプットごとに損失関数が必要。コンパイル時にlossのリストを渡す（１つしか渡さなかった場合全てのアウトプットに対して同じ損失を用いることになる）。デフォルトではそれぞれのlossを計算し和をとる。それぞれに重みを持たせることができるのでmain_outputにより大きな重みづけをする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a8e29e1a-72e9-4e1e-85e4-4669270b0b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=[\"mse\", \"mse\"], loss_weights=[0.9, 0.1], optimizer=keras.optimizers.SGD(learning_rate=1e-3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f92caf1-8c95-42a8-b4ca-60a6043f05fd",
   "metadata": {},
   "source": [
    "訓練時にはアウトプットごとにラベルが必要だが、ここでは同じラベルをタプルで与える。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7bf6680f-73bc-4273-8d55-17d45e1f296a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 2.6884 - main_output_loss: 2.3355 - aux_output_loss: 5.8648 - val_loss: 1.4544 - val_main_output_loss: 1.0946 - val_aux_output_loss: 4.6928\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.2771 - main_output_loss: 1.0018 - aux_output_loss: 3.7545 - val_loss: 1.0467 - val_main_output_loss: 0.8322 - val_aux_output_loss: 2.9775\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.9297 - main_output_loss: 0.7515 - aux_output_loss: 2.5338 - val_loss: 0.8755 - val_main_output_loss: 0.7354 - val_aux_output_loss: 2.1365\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.8086 - main_output_loss: 0.6811 - aux_output_loss: 1.9560 - val_loss: 0.7863 - val_main_output_loss: 0.6815 - val_aux_output_loss: 1.7295\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.7399 - main_output_loss: 0.6374 - aux_output_loss: 1.6628 - val_loss: 0.7320 - val_main_output_loss: 0.6449 - val_aux_output_loss: 1.5162\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.6951 - main_output_loss: 0.6065 - aux_output_loss: 1.4927 - val_loss: 0.6934 - val_main_output_loss: 0.6148 - val_aux_output_loss: 1.4009\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.6614 - main_output_loss: 0.5804 - aux_output_loss: 1.3907 - val_loss: 0.6646 - val_main_output_loss: 0.5912 - val_aux_output_loss: 1.3258\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.6344 - main_output_loss: 0.5585 - aux_output_loss: 1.3179 - val_loss: 0.6419 - val_main_output_loss: 0.5718 - val_aux_output_loss: 1.2724\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.6121 - main_output_loss: 0.5400 - aux_output_loss: 1.2616 - val_loss: 0.6234 - val_main_output_loss: 0.5558 - val_aux_output_loss: 1.2324\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5932 - main_output_loss: 0.5234 - aux_output_loss: 1.2212 - val_loss: 0.6061 - val_main_output_loss: 0.5406 - val_aux_output_loss: 1.1957\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5772 - main_output_loss: 0.5098 - aux_output_loss: 1.1841 - val_loss: 0.5917 - val_main_output_loss: 0.5279 - val_aux_output_loss: 1.1660\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5630 - main_output_loss: 0.4975 - aux_output_loss: 1.1526 - val_loss: 0.5806 - val_main_output_loss: 0.5184 - val_aux_output_loss: 1.1402\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5513 - main_output_loss: 0.4875 - aux_output_loss: 1.1253 - val_loss: 0.5705 - val_main_output_loss: 0.5098 - val_aux_output_loss: 1.1170\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5407 - main_output_loss: 0.4784 - aux_output_loss: 1.1013 - val_loss: 0.5619 - val_main_output_loss: 0.5029 - val_aux_output_loss: 1.0936\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5320 - main_output_loss: 0.4713 - aux_output_loss: 1.0788 - val_loss: 0.5533 - val_main_output_loss: 0.4955 - val_aux_output_loss: 1.0731\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5253 - main_output_loss: 0.4663 - aux_output_loss: 1.0564 - val_loss: 0.5464 - val_main_output_loss: 0.4900 - val_aux_output_loss: 1.0538\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5182 - main_output_loss: 0.4605 - aux_output_loss: 1.0378 - val_loss: 0.5402 - val_main_output_loss: 0.4853 - val_aux_output_loss: 1.0351\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5122 - main_output_loss: 0.4559 - aux_output_loss: 1.0184 - val_loss: 0.5351 - val_main_output_loss: 0.4815 - val_aux_output_loss: 1.0172\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5069 - main_output_loss: 0.4521 - aux_output_loss: 1.0005 - val_loss: 0.5299 - val_main_output_loss: 0.4778 - val_aux_output_loss: 0.9993\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5019 - main_output_loss: 0.4485 - aux_output_loss: 0.9828 - val_loss: 0.5255 - val_main_output_loss: 0.4746 - val_aux_output_loss: 0.9830\n"
     ]
    }
   ],
   "source": [
    "history=model.fit((X_train_A, X_train_B), [y_train, y_train], epochs=20, validation_data=((X_valid_A, X_valid_B), (y_valid, y_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "14acfefc-8743-474b-a579-1ff6357440e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 882us/step - loss: 0.5073 - main_output_loss: 0.4526 - aux_output_loss: 0.9992\n"
     ]
    }
   ],
   "source": [
    "total_loss, main_loss, aux_loss=model.evaluate((X_test_A,X_test_B),(y_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "676e6d05-81d0-4dee-a92f-a0ea4f6f848f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa55827a3b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 33ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_main, y_pred_aux=model.predict((X_new_A,X_new_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c2a86864-dad6-4dbc-8eb2-b7ac3b22d4aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.381964  ]\n",
      " [0.89944094]\n",
      " [3.301559  ]]\n",
      "[[1.6999665]\n",
      " [1.5514565]\n",
      " [1.9337424]]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred_main)\n",
    "print(y_pred_aux)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a66fbb6-b7f9-4186-a814-07a585a760a5",
   "metadata": {},
   "source": [
    "## Using the Subclassing API to Build Dynamic Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f209e49c-d6d4-4875-a083-58e0ca1b1996",
   "metadata": {},
   "source": [
    "こういう時にSubclassing APIを用いる。\n",
    "- ダイナミックな振る舞い: loops, varying shapes, conditional branch\n",
    "- imperative（命令型） programming (<==>declarative:宣言型)\n",
    "\n",
    "コンストラクタに必要な層を記述し、`call`メソッドにネットワークを書く。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "18401be7-7e95-4b35-aa55-8e47e7ffc5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeepModel(keras.Model):\n",
    "    def __init__(self, units=30, activation='relu', **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1 = keras.layers.Dense(units, activation=activation)\n",
    "        self.hidden2 = keras.layers.Dense(units, activation=activation)\n",
    "        self.main_output=keras.layers.Dense(1)\n",
    "        self.aux_output=keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        input_A, input_B = inputs\n",
    "        hidden1 = self.hidden1(input_B)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat= keras.layers.concatenate([input_A, hidden2])\n",
    "        main_output=self.main_output(concat)\n",
    "        aux_output=self.aux_output(hidden2)\n",
    "        return main_output, aux_output\n",
    "\n",
    "# model = WideAndDeepModel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "59b8cc69-8a3c-4f2a-aefa-353183999ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.call((input_A, input_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cb4284-8ca3-4747-8287-e31be6d1aaca",
   "metadata": {},
   "source": [
    "## Saving and Restoring a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4568a318-5aff-4113-b066-95a5f844609e",
   "metadata": {},
   "source": [
    "動作確認のため簡単なモデルを作成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "17348f8a-0df5-4e1f-8787-2d7b14533297",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ac44287a-dda8-48f1-9767-2733b1686047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.3774 - val_loss: 0.5655\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 971us/step - loss: 0.4676 - val_loss: 0.4645\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 964us/step - loss: 0.4225 - val_loss: 0.4441\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 964us/step - loss: 0.4090 - val_loss: 0.4291\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 958us/step - loss: 0.3993 - val_loss: 0.4211\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 963us/step - loss: 0.3918 - val_loss: 0.4217\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 966us/step - loss: 0.3891 - val_loss: 0.4119\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 979us/step - loss: 0.3849 - val_loss: 0.4064\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 985us/step - loss: 0.3795 - val_loss: 0.4052\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 964us/step - loss: 0.3786 - val_loss: 0.4016\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 977us/step - loss: 0.3737 - val_loss: 0.3942\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 992us/step - loss: 0.3728 - val_loss: 0.3923\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 986us/step - loss: 0.3683 - val_loss: 0.3939\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 976us/step - loss: 0.3670 - val_loss: 0.3877\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 969us/step - loss: 0.3652 - val_loss: 0.4051\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 984us/step - loss: 0.3640 - val_loss: 0.3898\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 977us/step - loss: 0.3598 - val_loss: 0.3804\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 986us/step - loss: 0.3583 - val_loss: 0.3843\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 995us/step - loss: 0.3554 - val_loss: 0.3794\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 983us/step - loss: 0.3545 - val_loss: 0.3850\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d35f328c-d486-4f9f-975c-56006b9b7206",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a2be0e1f-b1fb-441d-8ead-d7c9f6cf6168",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c7a4ac64-e92b-47dc-bfc9-d9aa60596abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 657us/step - loss: 0.3954\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3953877389431"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3720d410-bbd3-4edf-a3fc-26e98d9408bc",
   "metadata": {},
   "source": [
    "## Using Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e3c4ab25-2158-416b-a750-18e3ee944848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 0s 807us/step - loss: 0.3535\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 0s 802us/step - loss: 0.3554\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 0s 791us/step - loss: 0.3501\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 0s 793us/step - loss: 0.3495\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 0s 792us/step - loss: 0.3476\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 0s 792us/step - loss: 0.3495\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 0s 798us/step - loss: 0.3461\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 0s 788us/step - loss: 0.3470\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 0s 784us/step - loss: 0.3490\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 0s 790us/step - loss: 0.3412\n"
     ]
    }
   ],
   "source": [
    "checkpoint_cb=keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\")\n",
    "history=model.fit(X_train, y_train, epochs=10, callbacks=[checkpoint_cb])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f29f11b-68de-409f-8bd1-6b27f330caa2",
   "metadata": {},
   "source": [
    "検証データを使っている場合は`save_best_only`で最も性能の良かったモデルのみ保存できる。\n",
    "保存したモデルをリストアすると、性能の良かったエポックのモデルを再現できる。\n",
    "\n",
    "これはアーリーストッピングとして使うことができる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ce75af87-eb0f-4b52-a5a0-287f62519170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3435 - val_loss: 0.3990\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 0s 992us/step - loss: 0.3406 - val_loss: 0.3628\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 0s 983us/step - loss: 0.3444 - val_loss: 0.3660\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 0s 992us/step - loss: 0.3363 - val_loss: 0.3657\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3420 - val_loss: 0.3607\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 0s 985us/step - loss: 0.3417 - val_loss: 0.3604\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3340 - val_loss: 0.3550\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 0s 987us/step - loss: 0.3421 - val_loss: 0.3575\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 0s 997us/step - loss: 0.3316 - val_loss: 0.3641\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 0s 987us/step - loss: 0.3344 - val_loss: 0.3606\n"
     ]
    }
   ],
   "source": [
    "checkpoint_cb=keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\", save_best_only=True)\n",
    "history=model.fit(X_train, y_train, epochs=10, \n",
    "                  validation_data=(X_valid, y_valid),\n",
    "                  callbacks=[checkpoint_cb])\n",
    "# roll back to best model\n",
    "model = keras.models.load_model(\"my_keras_model.h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8106519a-71ca-46a0-9bb2-9c96ad3d92ec",
   "metadata": {},
   "source": [
    "EarlyStopping専用のコールバックも準備されている。\n",
    "\n",
    "[EarlyStopping](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping)：検証データの改善がなくなったら訓練を終了する。\n",
    "\n",
    "チェックポイントの保存と組み合わせて使用することもできる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "312d5451-bb10-451a-ad6e-d8f55bcfebe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.callbacks.EarlyStopping object at 0x7fa5dcb989a0>\n"
     ]
    }
   ],
   "source": [
    "print(early_stopping_cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "81788167-5912-400b-9fc0-50695cc3f079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3415 - val_loss: 0.3568\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 0s 992us/step - loss: 0.3336 - val_loss: 0.3592\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 990us/step - loss: 0.3309 - val_loss: 0.3632\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 0s 992us/step - loss: 0.3318 - val_loss: 0.3577\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 977us/step - loss: 0.3340 - val_loss: 0.3599\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3288 - val_loss: 0.3621\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3295 - val_loss: 0.3519\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 0s 985us/step - loss: 0.3269 - val_loss: 0.3525\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 0s 991us/step - loss: 0.3253 - val_loss: 0.3553\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 0s 979us/step - loss: 0.3265 - val_loss: 0.3545\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 0s 984us/step - loss: 0.3256 - val_loss: 0.3843\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 993us/step - loss: 0.3298 - val_loss: 0.3492\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 0s 974us/step - loss: 0.3234 - val_loss: 0.3540\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 0s 988us/step - loss: 0.3225 - val_loss: 0.3496\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3244 - val_loss: 0.3459\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 0s 972us/step - loss: 0.3211 - val_loss: 0.3530\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 0s 983us/step - loss: 0.3296 - val_loss: 0.3476\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 0s 991us/step - loss: 0.3210 - val_loss: 0.3448\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 0s 985us/step - loss: 0.3179 - val_loss: 0.3532\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 0s 985us/step - loss: 0.3240 - val_loss: 0.3452\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 0s 977us/step - loss: 0.3206 - val_loss: 0.3462\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3205 - val_loss: 0.3418\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3169 - val_loss: 0.4336\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3199 - val_loss: 0.3417\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3165 - val_loss: 0.3489\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3204 - val_loss: 0.3427\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 0s 994us/step - loss: 0.3151 - val_loss: 0.3709\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3136 - val_loss: 0.3445\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 0s 995us/step - loss: 0.3219 - val_loss: 0.3395\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 0s 991us/step - loss: 0.3235 - val_loss: 0.3489\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 0s 972us/step - loss: 0.3225 - val_loss: 0.3417\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 0s 988us/step - loss: 0.3118 - val_loss: 0.3462\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 0s 981us/step - loss: 0.3144 - val_loss: 0.3383\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 0s 971us/step - loss: 0.3148 - val_loss: 0.3392\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 0s 990us/step - loss: 0.3112 - val_loss: 0.3399\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 0s 997us/step - loss: 0.3134 - val_loss: 0.3473\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3121 - val_loss: 0.3626\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 0s 972us/step - loss: 0.3136 - val_loss: 0.3411\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 0s 982us/step - loss: 0.3140 - val_loss: 0.3400\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 0s 972us/step - loss: 0.3140 - val_loss: 0.3446\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3101 - val_loss: 0.3402\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3107 - val_loss: 0.3372\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 0s 998us/step - loss: 0.3355 - val_loss: 0.3364\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 0s 987us/step - loss: 0.3113 - val_loss: 0.3457\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 0s 976us/step - loss: 0.3135 - val_loss: 0.3541\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 0s 970us/step - loss: 0.3090 - val_loss: 0.3365\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 0s 967us/step - loss: 0.3120 - val_loss: 0.3422\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 0s 974us/step - loss: 0.3163 - val_loss: 0.3484\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 0s 964us/step - loss: 0.3089 - val_loss: 0.3405\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 0s 984us/step - loss: 0.3110 - val_loss: 0.3375\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 0s 995us/step - loss: 0.3191 - val_loss: 0.4349\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 0s 991us/step - loss: 0.3135 - val_loss: 0.3390\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 0s 979us/step - loss: 0.3089 - val_loss: 0.3404\n"
     ]
    }
   ],
   "source": [
    "early_stopping_cb=keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "history=model.fit(X_train, y_train, epochs=100, \n",
    "                  validation_data=(X_valid, y_valid),\n",
    "                  callbacks=[checkpoint_cb, early_stopping_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a7b425-be41-4138-ad7f-b7950bf2d04d",
   "metadata": {},
   "source": [
    "カスタムコールバック。\n",
    "\n",
    "[Callback](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/Callback)\n",
    "\n",
    "訓練中の検証損失と訓練損失の比を表示する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5c5da3ab-fc72-4be7-bc58-e4c32d4e6841",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintValTrainRatioCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        print(\"\\nval/train: {:.2f}\".format(logs[\"val_loss\"]/logs[\"loss\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c7c3ea25-b325-4d03-9e2a-a9dffe3e80fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "328/363 [==========================>...] - ETA: 0s - loss: 0.3139\n",
      "val/train: 1.09\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3108 - val_loss: 0.3388\n",
      "Epoch 2/100\n",
      "319/363 [=========================>....] - ETA: 0s - loss: 0.3122\n",
      "val/train: 1.59\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3087 - val_loss: 0.4896\n",
      "Epoch 3/100\n",
      "324/363 [=========================>....] - ETA: 0s - loss: 0.3150\n",
      "val/train: 1.07\n",
      "363/363 [==============================] - 0s 995us/step - loss: 0.3154 - val_loss: 0.3389\n",
      "Epoch 4/100\n",
      "330/363 [==========================>...] - ETA: 0s - loss: 0.3100\n",
      "val/train: 1.10\n",
      "363/363 [==============================] - 0s 976us/step - loss: 0.3087 - val_loss: 0.3403\n",
      "Epoch 5/100\n",
      "320/363 [=========================>....] - ETA: 0s - loss: 0.3110\n",
      "val/train: 1.09\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3100 - val_loss: 0.3388\n",
      "Epoch 6/100\n",
      "321/363 [=========================>....] - ETA: 0s - loss: 0.3033\n",
      "val/train: 1.08\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3103 - val_loss: 0.3336\n",
      "Epoch 7/100\n",
      "325/363 [=========================>....] - ETA: 0s - loss: 0.3172\n",
      "val/train: 1.07\n",
      "363/363 [==============================] - 0s 991us/step - loss: 0.3157 - val_loss: 0.3392\n",
      "Epoch 8/100\n",
      "326/363 [=========================>....] - ETA: 0s - loss: 0.3085\n",
      "val/train: 1.10\n",
      "363/363 [==============================] - 0s 983us/step - loss: 0.3071 - val_loss: 0.3369\n",
      "Epoch 9/100\n",
      "330/363 [==========================>...] - ETA: 0s - loss: 0.3220\n",
      "val/train: 1.06\n",
      "363/363 [==============================] - 0s 977us/step - loss: 0.3205 - val_loss: 0.3395\n",
      "Epoch 10/100\n",
      "333/363 [==========================>...] - ETA: 0s - loss: 0.3092\n",
      "val/train: 1.10\n",
      "363/363 [==============================] - 0s 977us/step - loss: 0.3097 - val_loss: 0.3393\n",
      "Epoch 11/100\n",
      "331/363 [==========================>...] - ETA: 0s - loss: 0.3076\n",
      "val/train: 1.08\n",
      "363/363 [==============================] - 0s 978us/step - loss: 0.3099 - val_loss: 0.3357\n",
      "Epoch 12/100\n",
      "332/363 [==========================>...] - ETA: 0s - loss: 0.3081\n",
      "val/train: 1.09\n",
      "363/363 [==============================] - 0s 981us/step - loss: 0.3070 - val_loss: 0.3334\n",
      "Epoch 13/100\n",
      "331/363 [==========================>...] - ETA: 0s - loss: 0.3075\n",
      "val/train: 1.09\n",
      "363/363 [==============================] - 0s 982us/step - loss: 0.3075 - val_loss: 0.3338\n",
      "Epoch 14/100\n",
      "328/363 [==========================>...] - ETA: 0s - loss: 0.3088\n",
      "val/train: 1.11\n",
      "363/363 [==============================] - 0s 990us/step - loss: 0.3073 - val_loss: 0.3417\n",
      "Epoch 15/100\n",
      "319/363 [=========================>....] - ETA: 0s - loss: 0.3065\n",
      "val/train: 1.11\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3068 - val_loss: 0.3413\n",
      "Epoch 16/100\n",
      "332/363 [==========================>...] - ETA: 0s - loss: 0.3048\n",
      "val/train: 1.10\n",
      "363/363 [==============================] - 0s 973us/step - loss: 0.3063 - val_loss: 0.3354\n",
      "Epoch 17/100\n",
      "330/363 [==========================>...] - ETA: 0s - loss: 0.3096\n",
      "val/train: 1.09\n",
      "363/363 [==============================] - 0s 982us/step - loss: 0.3069 - val_loss: 0.3343\n",
      "Epoch 18/100\n",
      "335/363 [==========================>...] - ETA: 0s - loss: 0.3117\n",
      "val/train: 1.10\n",
      "363/363 [==============================] - 0s 968us/step - loss: 0.3066 - val_loss: 0.3363\n",
      "Epoch 19/100\n",
      "337/363 [==========================>...] - ETA: 0s - loss: 0.3102\n",
      "val/train: 1.08\n",
      "363/363 [==============================] - 0s 969us/step - loss: 0.3076 - val_loss: 0.3319\n",
      "Epoch 20/100\n",
      "318/363 [=========================>....] - ETA: 0s - loss: 0.3037\n",
      "val/train: 1.10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3049 - val_loss: 0.3359\n",
      "Epoch 21/100\n",
      "325/363 [=========================>....] - ETA: 0s - loss: 0.3055\n",
      "val/train: 1.09\n",
      "363/363 [==============================] - 0s 993us/step - loss: 0.3049 - val_loss: 0.3333\n",
      "Epoch 22/100\n",
      "327/363 [==========================>...] - ETA: 0s - loss: 0.3052\n",
      "val/train: 1.09\n",
      "363/363 [==============================] - 0s 988us/step - loss: 0.3045 - val_loss: 0.3333\n",
      "Epoch 23/100\n",
      "319/363 [=========================>....] - ETA: 0s - loss: 0.3013\n",
      "val/train: 1.09\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3049 - val_loss: 0.3320\n",
      "Epoch 24/100\n",
      "313/363 [========================>.....] - ETA: 0s - loss: 0.3058\n",
      "val/train: 1.10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3183 - val_loss: 0.3487\n",
      "Epoch 25/100\n",
      "323/363 [=========================>....] - ETA: 0s - loss: 0.3127\n",
      "val/train: 1.07\n",
      "363/363 [==============================] - 0s 999us/step - loss: 0.3123 - val_loss: 0.3349\n",
      "Epoch 26/100\n",
      "325/363 [=========================>....] - ETA: 0s - loss: 0.3065\n",
      "val/train: 1.11\n",
      "363/363 [==============================] - 0s 996us/step - loss: 0.3056 - val_loss: 0.3379\n",
      "Epoch 27/100\n",
      "316/363 [=========================>....] - ETA: 0s - loss: 0.3074\n",
      "val/train: 1.09\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3052 - val_loss: 0.3324\n",
      "Epoch 28/100\n",
      "313/363 [========================>.....] - ETA: 0s - loss: 0.3074\n",
      "val/train: 1.07\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3099 - val_loss: 0.3331\n",
      "Epoch 29/100\n",
      "326/363 [=========================>....] - ETA: 0s - loss: 0.3058\n",
      "val/train: 1.12\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3055 - val_loss: 0.3407\n"
     ]
    }
   ],
   "source": [
    "custom_cb= PrintValTrainRatioCallback()\n",
    "history=model.fit(X_train, y_train, epochs=100, \n",
    "                  validation_data=(X_valid, y_valid),\n",
    "                  callbacks=[custom_cb, early_stopping_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d73e96-6d70-498c-b072-9a2b6a359fa9",
   "metadata": {},
   "source": [
    "## Using TensorBoard for Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fe3dd4fa-788d-4a84-aa53-d6d7f2eedf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id=time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir=get_run_logdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3e7f2f5f-06e6-46d6-ac5a-6bdb2d55a01b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3049 - val_loss: 0.3339\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3048 - val_loss: 0.3370\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3034 - val_loss: 0.3337\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 0s 990us/step - loss: 0.3050 - val_loss: 0.3382\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 0s 992us/step - loss: 0.3055 - val_loss: 0.3362\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 0s 988us/step - loss: 0.3047 - val_loss: 0.3335\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 0s 978us/step - loss: 0.3062 - val_loss: 0.3413\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3074 - val_loss: 0.3318\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 0s 985us/step - loss: 0.3037 - val_loss: 0.3455\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 0s 985us/step - loss: 0.3048 - val_loss: 0.3313\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3240 - val_loss: 0.3360\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 0s 978us/step - loss: 0.3060 - val_loss: 0.3520\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3033 - val_loss: 0.3352\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 0s 984us/step - loss: 0.3040 - val_loss: 0.3376\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 0s 982us/step - loss: 0.3066 - val_loss: 0.3328\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3043 - val_loss: 0.3370\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 0s 989us/step - loss: 0.3038 - val_loss: 0.3342\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 0s 989us/step - loss: 0.3013 - val_loss: 0.3344\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3066 - val_loss: 0.3413\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 0s 998us/step - loss: 0.3112 - val_loss: 0.3344\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3031 - val_loss: 0.3337\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3021 - val_loss: 0.3336\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 0s 987us/step - loss: 0.3012 - val_loss: 0.3295\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 0s 998us/step - loss: 0.3052 - val_loss: 0.3306\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 0s 986us/step - loss: 0.3021 - val_loss: 0.3346\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 0s 990us/step - loss: 0.3009 - val_loss: 0.3566\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3037 - val_loss: 0.3464\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3163 - val_loss: 0.3318\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3024 - val_loss: 0.3292\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 0s 983us/step - loss: 0.3000 - val_loss: 0.3357\n"
     ]
    }
   ],
   "source": [
    "tensorboard_cb=keras.callbacks.TensorBoard(run_logdir)\n",
    "history=model.fit(X_train, y_train, epochs=30,\n",
    "                  validation_data=(X_valid, y_valid),\n",
    "                  callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "10ab4fb4-1c64-4897-a262-069bfa2ca5d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Could not find `tensorboard`. Please ensure that your PATH\n",
       "contains an executable `tensorboard` program, or explicitly specify\n",
       "the path to a TensorBoard binary by setting the `TENSORBOARD_BINARY`\n",
       "environment variable."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./my_logs --port=6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "624d20fa-11be-4f7d-a1f4-61112fdb2133",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorboard` not found.\n"
     ]
    }
   ],
   "source": [
    "%tensorboard --logdir=./my_logs --port=6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8d22dafc-b064-4136-8660-5996544fce70",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_logdir=get_run_logdir()\n",
    "writer=tf.summary.create_file_writer(test_logdir)\n",
    "with writer.as_default():\n",
    "    for step in range(1, 1000 + 1):\n",
    "        tf.summary.scalar('my_scaler', np.sin(step/10), step = step)\n",
    "        data=(np.random.randn(100)+2) * step/100\n",
    "        tf.summary.histogram('my_hist', data, buckets =50, step = step)\n",
    "        images=np.random.rand(2,32,32,3)\n",
    "        tf.summary.image('my_images', images * step / 1000, step = step)\n",
    "        texts=[\"The step is \" + str(step), \"Its square is \" + str(step**2)]\n",
    "        tf.summary.text('my_text', texts, step = step)\n",
    "        sine_wave=tf.math.sin(tf.range(12000)/48000 *2*np.pi*step)\n",
    "        audio=tf.reshape(tf.cast(sine_wave, tf.float32), [1, -1,1])\n",
    "        tf.summary.audio('my_audio', audio, sample_rate=48000, step=step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a95e045-191d-4348-bedd-c66f14e3e801",
   "metadata": {},
   "source": [
    "# Fine-Tuning Neural Network Hyperparameters\n",
    "ハイパーパラメータ探索のためにsklearnのGridSearchやRandomizedSearchを使いたい。そのような場合、Kerasのモデルをラップしてsklearnのモデルとして扱えるようにする。\n",
    "\n",
    "まずKerasのモデルを作りコンパイルする関数を作る。引数にハイパーパラメータを与える。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "428fcec4-7816-46f0-ab37-4648ec4806f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape = [8]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation='relu'))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimizer=keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    model.compile(loss='mse', optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e7ade0-ca7c-4a85-81c4-999ac11ff078",
   "metadata": {},
   "source": [
    "ラッパークラス。\n",
    "\n",
    "[KerasRegressor](https://keras.io/ja/scikit-learn-api/):sklearnのregressorインターフェースを実装。\n",
    "\n",
    "ただこれを使うとDeprecationWarningが出て代わりに[Sci-Keras](https://github.com/adriangb/scikeras)を使うよう促される。[移行のための資料](https://www.adriangb.com/scikeras/stable/migration.html)。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0b33687-103c-4d45-9fd3-b4c3fbb58250",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1674/1371180924.py:1: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  keras_reg=keras.wrappers.scikit_learn.KerasRegressor(build_model)\n"
     ]
    }
   ],
   "source": [
    "keras_reg=keras.wrappers.scikit_learn.KerasRegressor(build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b825e92f-df24-4100-9ca2-cd63a85071ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scikeras.wrappers import KerasRegressor\n",
    "keras_reg=KerasRegressor(build_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7198202f-2cc5-4239-880c-1d28be5b574f",
   "metadata": {},
   "source": [
    "表面的にはsklearnのモデルとして振る舞うが内部はkerasのモデルになっている。kwargs経由で引数が渡されているっぽい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b7b5d41-7b7a-46c0-8201-e31fd99a50bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "  1/363 [..............................] - ETA: 53s - loss: 11.0541"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tuffy/venvs/.tf/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - 1s 1ms/step - loss: 1.3768 - val_loss: 0.7167\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 0s 992us/step - loss: 0.7990 - val_loss: 0.8212\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 985us/step - loss: 0.8758 - val_loss: 0.5496\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5512 - val_loss: 0.4930\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5046 - val_loss: 0.4774\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4886 - val_loss: 0.4684\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4775 - val_loss: 0.4599\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 0s 994us/step - loss: 0.4688 - val_loss: 0.4501\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4614 - val_loss: 0.4451\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 0s 993us/step - loss: 0.4552 - val_loss: 0.4409\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4506 - val_loss: 0.4351\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4466 - val_loss: 0.4330\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4432 - val_loss: 0.4303\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4396 - val_loss: 0.4271\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4366 - val_loss: 0.4235\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4336 - val_loss: 0.4210\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4303 - val_loss: 0.4187\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4277 - val_loss: 0.4145\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4251 - val_loss: 0.4133\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4229 - val_loss: 0.4107\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4203 - val_loss: 0.4077\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 0s 995us/step - loss: 0.4179 - val_loss: 0.4073\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 0s 977us/step - loss: 0.4161 - val_loss: 0.4042\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 0s 976us/step - loss: 0.4139 - val_loss: 0.4024\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 0s 998us/step - loss: 0.4116 - val_loss: 0.4000\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4096 - val_loss: 0.4000\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4076 - val_loss: 0.3999\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4057 - val_loss: 0.3968\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4042 - val_loss: 0.3933\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4017 - val_loss: 0.3930\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4000 - val_loss: 0.3903\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3985 - val_loss: 0.3900\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 0s 988us/step - loss: 0.3963 - val_loss: 0.3876\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 0s 996us/step - loss: 0.3944 - val_loss: 0.3862\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3926 - val_loss: 0.3839\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 0s 993us/step - loss: 0.3911 - val_loss: 0.3830\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 0s 980us/step - loss: 0.3893 - val_loss: 0.3815\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 0s 995us/step - loss: 0.3873 - val_loss: 0.3828\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 0s 1000us/step - loss: 0.3866 - val_loss: 0.3793\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 0s 996us/step - loss: 0.3852 - val_loss: 0.3795\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3831 - val_loss: 0.3786\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 0s 987us/step - loss: 0.3820 - val_loss: 0.3763\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 0s 978us/step - loss: 0.3823 - val_loss: 0.3758\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 0s 995us/step - loss: 0.3790 - val_loss: 0.3752\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 0s 997us/step - loss: 0.3782 - val_loss: 0.3760\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 0s 984us/step - loss: 0.3770 - val_loss: 0.3727\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 0s 993us/step - loss: 0.3761 - val_loss: 0.3724\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 0s 999us/step - loss: 0.3748 - val_loss: 0.3712\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3743 - val_loss: 0.3698\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3742 - val_loss: 0.3691\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 0s 988us/step - loss: 0.3724 - val_loss: 0.3705\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 0s 994us/step - loss: 0.3712 - val_loss: 0.3685\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3697 - val_loss: 0.3686\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 0s 999us/step - loss: 0.3684 - val_loss: 0.3670\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 0s 987us/step - loss: 0.3674 - val_loss: 0.3661\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 0s 996us/step - loss: 0.3665 - val_loss: 0.3656\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3648 - val_loss: 0.3675\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3644 - val_loss: 0.3662\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3638 - val_loss: 0.3642\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 0s 990us/step - loss: 0.3632 - val_loss: 0.3636\n",
      "Epoch 61/100\n",
      "363/363 [==============================] - 0s 989us/step - loss: 0.3622 - val_loss: 0.3628\n",
      "Epoch 62/100\n",
      "363/363 [==============================] - 0s 988us/step - loss: 0.3609 - val_loss: 0.3611\n",
      "Epoch 63/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3607 - val_loss: 0.3606\n",
      "Epoch 64/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3600 - val_loss: 0.3605\n",
      "Epoch 65/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3592 - val_loss: 0.3591\n",
      "Epoch 66/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3579 - val_loss: 0.3641\n",
      "Epoch 67/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3580 - val_loss: 0.3588\n",
      "Epoch 68/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3565 - val_loss: 0.3579\n",
      "Epoch 69/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3560 - val_loss: 0.3576\n",
      "Epoch 70/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3574 - val_loss: 0.3591\n",
      "Epoch 71/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3557 - val_loss: 0.3558\n",
      "Epoch 72/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3556 - val_loss: 0.3552\n",
      "Epoch 73/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3542 - val_loss: 0.3562\n",
      "Epoch 74/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3528 - val_loss: 0.3558\n",
      "Epoch 75/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3520 - val_loss: 0.3550\n",
      "Epoch 76/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3517 - val_loss: 0.3564\n",
      "Epoch 77/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3515 - val_loss: 0.3569\n",
      "Epoch 78/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3514 - val_loss: 0.3547\n",
      "Epoch 79/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3510 - val_loss: 0.3542\n",
      "Epoch 80/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3566 - val_loss: 0.3529\n",
      "Epoch 81/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3488 - val_loss: 0.3550\n",
      "Epoch 82/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3495 - val_loss: 0.3554\n",
      "Epoch 83/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3482 - val_loss: 0.3516\n",
      "Epoch 84/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3487 - val_loss: 0.3516\n",
      "Epoch 85/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3472 - val_loss: 0.3536\n",
      "Epoch 86/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3531 - val_loss: 0.3515\n",
      "Epoch 87/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3467 - val_loss: 0.3548\n",
      "Epoch 88/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3527 - val_loss: 0.3503\n",
      "Epoch 89/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3519 - val_loss: 0.3513\n",
      "Epoch 90/100\n",
      "363/363 [==============================] - 0s 995us/step - loss: 0.3450 - val_loss: 0.3504\n",
      "Epoch 91/100\n",
      "363/363 [==============================] - 0s 984us/step - loss: 0.3454 - val_loss: 0.3492\n",
      "Epoch 92/100\n",
      "363/363 [==============================] - 0s 979us/step - loss: 0.3444 - val_loss: 0.3492\n",
      "Epoch 93/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3440 - val_loss: 0.3621\n",
      "Epoch 94/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3441 - val_loss: 0.3500\n",
      "Epoch 95/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3427 - val_loss: 0.3499\n",
      "Epoch 96/100\n",
      "363/363 [==============================] - 0s 987us/step - loss: 0.3449 - val_loss: 0.3487\n",
      "Epoch 97/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3422 - val_loss: 0.3488\n",
      "Epoch 98/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3413 - val_loss: 0.3492\n",
      "Epoch 99/100\n",
      "363/363 [==============================] - 0s 993us/step - loss: 0.3410 - val_loss: 0.3485\n",
      "Epoch 100/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3406 - val_loss: 0.3480\n",
      "162/162 [==============================] - 0s 533us/step\n",
      "0.7362852918410829\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "[2.8486905 2.4350681 2.4499483]\n"
     ]
    }
   ],
   "source": [
    "keras_reg.fit(X_train, y_train, epochs=100,\n",
    "             validation_data=(X_valid, y_valid),\n",
    "             callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n",
    "mse_test=keras_reg.score(X_test, y_test)\n",
    "print(mse_test)\n",
    "y_pred=keras_reg.predict(X_new)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0fed7f-6139-4412-982d-6ddc98104c0c",
   "metadata": {},
   "source": [
    "ランダムサーチ。ランダムサーチはK-fold交差検証なので検証データはここでは使わずEarlyStoppingのみで使っている。\n",
    "\n",
    "[reciprocal](https://pageperso.lis-lab.fr/~francois.denis/IAAM1/scipy-html-1.0.0/generated/scipy.stats.reciprocal.html): reciprocal=逆数。逆数分布とか対数一様分布とか呼ばれる。[loguniform](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.loguniform.html#scipy.stats.loguniform)が新しいdocだとヒットする。pdfは\n",
    "$$\n",
    "f(x,a,b)=\\frac{1}{x \\log(b/a)}\n",
    "$$\n",
    "\n",
    "$a<x<b$、aとbを与えて乱数を生成している。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17956288-9681-445f-9537-0cb9fa09cc73",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.8513 - val_loss: 2.5415\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.8818 - val_loss: 1.2637\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0535 - val_loss: 0.8349\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7738 - val_loss: 0.6798\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6703 - val_loss: 0.6210\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6291 - val_loss: 0.5963\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6099 - val_loss: 0.5837\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5993 - val_loss: 0.5761\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5921 - val_loss: 0.5705\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5865 - val_loss: 0.5656\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5817 - val_loss: 0.5615\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5775 - val_loss: 0.5574\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5736 - val_loss: 0.5538\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5700 - val_loss: 0.5505\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5668 - val_loss: 0.5474\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5637 - val_loss: 0.5444\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5609 - val_loss: 0.5416\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5584 - val_loss: 0.5391\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5561 - val_loss: 0.5371\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1000us/step - loss: 0.5539 - val_loss: 0.5351\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5519 - val_loss: 0.5333\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5501 - val_loss: 0.5311\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5484 - val_loss: 0.5295\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5468 - val_loss: 0.5278\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5455 - val_loss: 0.5266\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5440 - val_loss: 0.5256\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5428 - val_loss: 0.5238\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5418 - val_loss: 0.5232\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5408 - val_loss: 0.5219\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5398 - val_loss: 0.5206\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5389 - val_loss: 0.5195\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5382 - val_loss: 0.5196\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5375 - val_loss: 0.5191\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5368 - val_loss: 0.5179\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5361 - val_loss: 0.5170\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5354 - val_loss: 0.5159\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5350 - val_loss: 0.5153\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5346 - val_loss: 0.5158\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5340 - val_loss: 0.5157\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5337 - val_loss: 0.5153\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5333 - val_loss: 0.5153\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5329 - val_loss: 0.5136\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5327 - val_loss: 0.5133\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5323 - val_loss: 0.5126\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5321 - val_loss: 0.5128\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5318 - val_loss: 0.5123\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5317 - val_loss: 0.5120\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5314 - val_loss: 0.5126\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5312 - val_loss: 0.5127\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5310 - val_loss: 0.5115\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5309 - val_loss: 0.5111\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5305 - val_loss: 0.5102\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5307 - val_loss: 0.5105\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5305 - val_loss: 0.5109\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5304 - val_loss: 0.5106\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5302 - val_loss: 0.5113\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5301 - val_loss: 0.5103\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5300 - val_loss: 0.5113\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5300 - val_loss: 0.5110\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5299 - val_loss: 0.5101\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5297 - val_loss: 0.5112\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5297 - val_loss: 0.5116\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5298 - val_loss: 0.5103\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5295 - val_loss: 0.5090\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5296 - val_loss: 0.5106\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5293 - val_loss: 0.5089\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5296 - val_loss: 0.5100\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5295 - val_loss: 0.5097\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5294 - val_loss: 0.5087\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5294 - val_loss: 0.5102\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5294 - val_loss: 0.5102\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5290 - val_loss: 0.5081\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5292 - val_loss: 0.5078\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5296 - val_loss: 0.5084\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5290 - val_loss: 0.5075\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5292 - val_loss: 0.5074\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5294 - val_loss: 0.5077\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5294 - val_loss: 0.5095\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5293 - val_loss: 0.5101\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5292 - val_loss: 0.5093\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5290 - val_loss: 0.5082\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5293 - val_loss: 0.5083\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5291 - val_loss: 0.5101\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5292 - val_loss: 0.5096\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5291 - val_loss: 0.5085\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5292 - val_loss: 0.5100\n",
      "121/121 [==============================] - 0s 606us/step - loss: 0.5171\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.8790 - val_loss: 2.5507\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.9675 - val_loss: 1.4554\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2468 - val_loss: 1.0379\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9626 - val_loss: 0.8688\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8421 - val_loss: 0.7939\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7844 - val_loss: 0.7549\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7515 - val_loss: 0.7304\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7291 - val_loss: 0.7122\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7115 - val_loss: 0.6971\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6963 - val_loss: 0.6836\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6828 - val_loss: 0.6716\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6705 - val_loss: 0.6607\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6593 - val_loss: 0.6507\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6488 - val_loss: 0.6417\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6392 - val_loss: 0.6333\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6302 - val_loss: 0.6256\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6219 - val_loss: 0.6184\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6143 - val_loss: 0.6119\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6072 - val_loss: 0.6060\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6005 - val_loss: 0.6007\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5944 - val_loss: 0.5957\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5888 - val_loss: 0.5911\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5835 - val_loss: 0.5869\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5786 - val_loss: 0.5832\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5741 - val_loss: 0.5796\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5699 - val_loss: 0.5767\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5660 - val_loss: 0.5737\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5623 - val_loss: 0.5712\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5589 - val_loss: 0.5686\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5558 - val_loss: 0.5664\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5529 - val_loss: 0.5645\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5502 - val_loss: 0.5627\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5476 - val_loss: 0.5611\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5453 - val_loss: 0.5600\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5431 - val_loss: 0.5588\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5411 - val_loss: 0.5575\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5392 - val_loss: 0.5564\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5375 - val_loss: 0.5554\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5359 - val_loss: 0.5547\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5344 - val_loss: 0.5539\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5330 - val_loss: 0.5535\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5316 - val_loss: 0.5529\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5304 - val_loss: 0.5523\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5293 - val_loss: 0.5518\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5283 - val_loss: 0.5516\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5273 - val_loss: 0.5512\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5263 - val_loss: 0.5510\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5255 - val_loss: 0.5511\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5246 - val_loss: 0.5507\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5239 - val_loss: 0.5504\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5232 - val_loss: 0.5501\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5226 - val_loss: 0.5500\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5220 - val_loss: 0.5502\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5214 - val_loss: 0.5499\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5209 - val_loss: 0.5501\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5204 - val_loss: 0.5500\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5199 - val_loss: 0.5500\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5195 - val_loss: 0.5503\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5191 - val_loss: 0.5500\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5187 - val_loss: 0.5502\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5184 - val_loss: 0.5504\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5180 - val_loss: 0.5504\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5177 - val_loss: 0.5506\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5174 - val_loss: 0.5507\n",
      "121/121 [==============================] - 0s 628us/step - loss: 0.7190\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5.5588 - val_loss: 3.2153\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.3837 - val_loss: 1.5900\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2887 - val_loss: 0.9841\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8859 - val_loss: 0.7581\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7315 - val_loss: 0.6690\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6686 - val_loss: 0.6313\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6403 - val_loss: 0.6130\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6250 - val_loss: 0.6022\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6147 - val_loss: 0.5940\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6070 - val_loss: 0.5874\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6004 - val_loss: 0.5817\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5946 - val_loss: 0.5766\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5892 - val_loss: 0.5716\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5845 - val_loss: 0.5671\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5800 - val_loss: 0.5627\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5758 - val_loss: 0.5595\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5721 - val_loss: 0.5556\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5687 - val_loss: 0.5529\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5656 - val_loss: 0.5498\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5626 - val_loss: 0.5472\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5599 - val_loss: 0.5443\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5574 - val_loss: 0.5424\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5550 - val_loss: 0.5391\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5531 - val_loss: 0.5372\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5511 - val_loss: 0.5351\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5493 - val_loss: 0.5335\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5476 - val_loss: 0.5315\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5462 - val_loss: 0.5305\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5447 - val_loss: 0.5293\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5432 - val_loss: 0.5269\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5423 - val_loss: 0.5264\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5409 - val_loss: 0.5246\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5401 - val_loss: 0.5241\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5392 - val_loss: 0.5230\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5383 - val_loss: 0.5223\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5375 - val_loss: 0.5228\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5366 - val_loss: 0.5212\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5360 - val_loss: 0.5204\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5353 - val_loss: 0.5189\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5348 - val_loss: 0.5193\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5340 - val_loss: 0.5175\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5338 - val_loss: 0.5169\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5330 - val_loss: 0.5156\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5329 - val_loss: 0.5177\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5324 - val_loss: 0.5171\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5318 - val_loss: 0.5149\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5318 - val_loss: 0.5152\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5314 - val_loss: 0.5152\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5311 - val_loss: 0.5146\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5308 - val_loss: 0.5158\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5306 - val_loss: 0.5150\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5300 - val_loss: 0.5128\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5302 - val_loss: 0.5127\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5297 - val_loss: 0.5118\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5296 - val_loss: 0.5143\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5290 - val_loss: 0.5114\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5294 - val_loss: 0.5110\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5295 - val_loss: 0.5123\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5292 - val_loss: 0.5123\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5291 - val_loss: 0.5115\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5289 - val_loss: 0.5120\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5285 - val_loss: 0.5103\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5287 - val_loss: 0.5102\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5287 - val_loss: 0.5106\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5282 - val_loss: 0.5095\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5286 - val_loss: 0.5112\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5283 - val_loss: 0.5127\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5282 - val_loss: 0.5140\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5279 - val_loss: 0.5104\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5275 - val_loss: 0.5084\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5281 - val_loss: 0.5085\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5281 - val_loss: 0.5083\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5280 - val_loss: 0.5108\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 999us/step - loss: 0.5278 - val_loss: 0.5094\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5279 - val_loss: 0.5099\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5277 - val_loss: 0.5126\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5279 - val_loss: 0.5123\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5279 - val_loss: 0.5107\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5277 - val_loss: 0.5112\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5278 - val_loss: 0.5113\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5274 - val_loss: 0.5093\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5273 - val_loss: 0.5081\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5276 - val_loss: 0.5098\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5272 - val_loss: 0.5080\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5276 - val_loss: 0.5081\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5275 - val_loss: 0.5079\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5276 - val_loss: 0.5088\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5275 - val_loss: 0.5091\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5269 - val_loss: 0.5073\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5273 - val_loss: 0.5069\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5275 - val_loss: 0.5100\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5270 - val_loss: 0.5078\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5275 - val_loss: 0.5082\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5272 - val_loss: 0.5077\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5272 - val_loss: 0.5070\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5275 - val_loss: 0.5077\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5270 - val_loss: 0.5066\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5273 - val_loss: 0.5072\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5278 - val_loss: 0.5081\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5274 - val_loss: 0.5083\n",
      "121/121 [==============================] - 0s 614us/step - loss: 0.5204\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2126 - val_loss: 0.9269\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3378 - val_loss: 1.1960\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.7729 - val_loss: 0.5344\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5098 - val_loss: 0.4705\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4691 - val_loss: 0.4416\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4520 - val_loss: 0.4341\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4432 - val_loss: 0.4234\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4360 - val_loss: 0.4160\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4287 - val_loss: 0.4116\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4235 - val_loss: 0.4160\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4201 - val_loss: 0.4041\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4160 - val_loss: 0.3997\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4122 - val_loss: 0.3984\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4085 - val_loss: 0.3948\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4052 - val_loss: 0.3936\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4028 - val_loss: 0.3958\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4009 - val_loss: 0.3921\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3974 - val_loss: 0.3896\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3958 - val_loss: 0.3911\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3944 - val_loss: 0.3873\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3920 - val_loss: 0.3861\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3905 - val_loss: 0.3822\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3887 - val_loss: 0.3816\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3887 - val_loss: 0.3851\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3896 - val_loss: 0.3803\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3855 - val_loss: 0.3777\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3824 - val_loss: 0.3767\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3813 - val_loss: 0.3776\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3790 - val_loss: 0.3757\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3787 - val_loss: 0.3750\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3794 - val_loss: 0.3736\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3755 - val_loss: 0.3711\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3765 - val_loss: 0.3715\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3764 - val_loss: 0.3701\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3725 - val_loss: 0.3703\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3708 - val_loss: 0.3680\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3695 - val_loss: 0.3677\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3693 - val_loss: 0.3753\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3689 - val_loss: 0.3674\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3665 - val_loss: 0.3686\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3656 - val_loss: 0.3654\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3647 - val_loss: 0.3636\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3639 - val_loss: 0.3624\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3650 - val_loss: 0.3674\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3628 - val_loss: 0.3634\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3610 - val_loss: 0.3638\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3613 - val_loss: 0.3614\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3597 - val_loss: 0.3726\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3623 - val_loss: 0.3597\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3630 - val_loss: 0.3606\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3566 - val_loss: 0.3597\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3659 - val_loss: 0.3576\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3587 - val_loss: 0.3576\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3572 - val_loss: 0.3564\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3603 - val_loss: 0.3567\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3531 - val_loss: 0.3591\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3542 - val_loss: 0.3559\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3526 - val_loss: 0.3725\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3562 - val_loss: 0.3540\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3513 - val_loss: 0.3568\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3695 - val_loss: 0.3529\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3522 - val_loss: 0.3525\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3500 - val_loss: 0.3519\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3500 - val_loss: 0.3519\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3484 - val_loss: 0.3526\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3490 - val_loss: 0.3542\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3477 - val_loss: 0.3524\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3504 - val_loss: 0.3524\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3490 - val_loss: 0.3518\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3472 - val_loss: 0.3491\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3456 - val_loss: 0.3495\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3470 - val_loss: 0.3486\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3458 - val_loss: 0.3512\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3437 - val_loss: 0.3470\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3440 - val_loss: 0.3487\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3430 - val_loss: 0.3505\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3421 - val_loss: 0.3485\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3409 - val_loss: 0.3465\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3409 - val_loss: 0.3468\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3431 - val_loss: 0.3474\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3732 - val_loss: 0.3472\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3424 - val_loss: 0.3446\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3396 - val_loss: 0.3443\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3399 - val_loss: 0.3436\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3388 - val_loss: 0.3461\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3397 - val_loss: 0.3422\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3380 - val_loss: 0.3438\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3374 - val_loss: 0.3412\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3364 - val_loss: 0.3428\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3362 - val_loss: 0.3436\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3370 - val_loss: 0.3433\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3354 - val_loss: 0.3412\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3354 - val_loss: 0.3407\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3351 - val_loss: 0.3417\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3344 - val_loss: 0.3406\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3334 - val_loss: 0.3399\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3337 - val_loss: 0.3419\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3323 - val_loss: 0.3413\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3339 - val_loss: 0.3641\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3605 - val_loss: 0.3387\n",
      "121/121 [==============================] - 0s 650us/step - loss: 0.3278\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1059 - val_loss: 0.8051\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6233 - val_loss: 0.6400\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5605 - val_loss: 0.5465\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5228 - val_loss: 0.5006\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4998 - val_loss: 0.4793\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4851 - val_loss: 0.4682\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4740 - val_loss: 0.4612\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4667 - val_loss: 0.4536\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4590 - val_loss: 0.4549\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4538 - val_loss: 0.4475\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4495 - val_loss: 0.4435\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4440 - val_loss: 0.4394\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4400 - val_loss: 0.4365\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4360 - val_loss: 0.4350\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4322 - val_loss: 0.4309\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4290 - val_loss: 0.4294\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4256 - val_loss: 0.4227\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4231 - val_loss: 0.4218\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4191 - val_loss: 0.4190\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4174 - val_loss: 0.4175\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4143 - val_loss: 0.4161\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4121 - val_loss: 0.4157\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4100 - val_loss: 0.4117\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4074 - val_loss: 0.4106\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4049 - val_loss: 0.4081\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4036 - val_loss: 0.4072\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4013 - val_loss: 0.4039\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3993 - val_loss: 0.4046\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3972 - val_loss: 0.4004\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3955 - val_loss: 0.4006\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3936 - val_loss: 0.3978\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3921 - val_loss: 0.3969\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3905 - val_loss: 0.3947\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3878 - val_loss: 0.3968\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3868 - val_loss: 0.3942\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3853 - val_loss: 0.3920\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3835 - val_loss: 0.3912\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3824 - val_loss: 0.3877\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3808 - val_loss: 0.3860\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3794 - val_loss: 0.3846\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3773 - val_loss: 0.3844\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3761 - val_loss: 0.3837\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3749 - val_loss: 0.3826\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3734 - val_loss: 0.3818\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3716 - val_loss: 0.3804\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3710 - val_loss: 0.3788\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3687 - val_loss: 0.3780\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3684 - val_loss: 0.3749\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3665 - val_loss: 0.3784\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3654 - val_loss: 0.3751\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3643 - val_loss: 0.3723\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3630 - val_loss: 0.3756\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3616 - val_loss: 0.3701\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3600 - val_loss: 0.3685\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3588 - val_loss: 0.3705\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3582 - val_loss: 0.3697\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3564 - val_loss: 0.3668\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3550 - val_loss: 0.3661\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3536 - val_loss: 0.3664\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3528 - val_loss: 0.3641\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3522 - val_loss: 0.3630\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3510 - val_loss: 0.3651\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3497 - val_loss: 0.3617\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3489 - val_loss: 0.3610\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3465 - val_loss: 0.3607\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3459 - val_loss: 0.3599\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3454 - val_loss: 0.3610\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3445 - val_loss: 0.3634\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3439 - val_loss: 0.3577\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3423 - val_loss: 0.3615\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3418 - val_loss: 0.3562\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3404 - val_loss: 0.3619\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3394 - val_loss: 0.3561\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3387 - val_loss: 0.3561\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3378 - val_loss: 0.3559\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3374 - val_loss: 0.3540\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3359 - val_loss: 0.3552\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3352 - val_loss: 0.3549\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3344 - val_loss: 0.3532\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3336 - val_loss: 0.3518\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3317 - val_loss: 0.3519\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3315 - val_loss: 0.3509\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3299 - val_loss: 0.3531\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3307 - val_loss: 0.3517\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3293 - val_loss: 0.3513\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3284 - val_loss: 0.3516\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3271 - val_loss: 0.3496\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3267 - val_loss: 0.3488\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3256 - val_loss: 0.3585\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3255 - val_loss: 0.3484\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3249 - val_loss: 0.3497\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3242 - val_loss: 0.3483\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3236 - val_loss: 0.3513\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3230 - val_loss: 0.3455\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3220 - val_loss: 0.3448\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3222 - val_loss: 0.3444\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3210 - val_loss: 0.3461\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3204 - val_loss: 0.3437\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3199 - val_loss: 0.3491\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3202 - val_loss: 0.3442\n",
      "121/121 [==============================] - 0s 641us/step - loss: 0.3664\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 1.3501 - val_loss: 1.0085\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3500 - val_loss: 0.6842\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6912 - val_loss: 0.5720\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5652 - val_loss: 0.5140\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5175 - val_loss: 0.4836\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4924 - val_loss: 0.4632\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4742 - val_loss: 0.4546\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4630 - val_loss: 0.4415\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4535 - val_loss: 0.4352\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4464 - val_loss: 0.4306\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4408 - val_loss: 0.4254\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4356 - val_loss: 0.4241\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4313 - val_loss: 0.4181\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4279 - val_loss: 0.4141\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4246 - val_loss: 0.4140\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4212 - val_loss: 0.4098\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4179 - val_loss: 0.4064\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4157 - val_loss: 0.4063\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4129 - val_loss: 0.4028\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4109 - val_loss: 0.4022\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4085 - val_loss: 0.3982\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4068 - val_loss: 0.3969\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4042 - val_loss: 0.3954\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4026 - val_loss: 0.3937\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4018 - val_loss: 0.3921\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3999 - val_loss: 0.3902\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3968 - val_loss: 0.3898\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3955 - val_loss: 0.3896\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3940 - val_loss: 0.3890\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3937 - val_loss: 0.3925\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3936 - val_loss: 0.3850\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3904 - val_loss: 0.3851\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3887 - val_loss: 0.3837\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3872 - val_loss: 0.3829\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3863 - val_loss: 0.3807\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3852 - val_loss: 0.3786\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3835 - val_loss: 0.3804\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3859 - val_loss: 0.3826\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3822 - val_loss: 0.3773\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3808 - val_loss: 0.3754\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3797 - val_loss: 0.3759\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3791 - val_loss: 0.3742\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3774 - val_loss: 0.3733\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3765 - val_loss: 0.3723\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3761 - val_loss: 0.3728\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3746 - val_loss: 0.3724\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3750 - val_loss: 0.3726\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3735 - val_loss: 0.3706\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3720 - val_loss: 0.3696\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3710 - val_loss: 0.3702\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3709 - val_loss: 0.3687\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3696 - val_loss: 0.3679\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3685 - val_loss: 0.3685\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3681 - val_loss: 0.3669\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3671 - val_loss: 0.3683\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3661 - val_loss: 0.3671\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3655 - val_loss: 0.3662\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3658 - val_loss: 0.3653\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3646 - val_loss: 0.3644\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3632 - val_loss: 0.3646\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3629 - val_loss: 0.3669\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3622 - val_loss: 0.3633\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3623 - val_loss: 0.3664\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3608 - val_loss: 0.3631\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3611 - val_loss: 0.3633\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3590 - val_loss: 0.3650\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3592 - val_loss: 0.3624\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3585 - val_loss: 0.3615\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3580 - val_loss: 0.3608\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3564 - val_loss: 0.3620\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3570 - val_loss: 0.3646\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3564 - val_loss: 0.3604\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3584 - val_loss: 0.3616\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3552 - val_loss: 0.3594\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3584 - val_loss: 0.3601\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3547 - val_loss: 0.3617\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3535 - val_loss: 0.3622\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3536 - val_loss: 0.3583\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3554 - val_loss: 0.3589\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3516 - val_loss: 0.3606\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3517 - val_loss: 0.3585\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3548 - val_loss: 0.3592\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3502 - val_loss: 0.3568\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3508 - val_loss: 0.3668\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3823 - val_loss: 0.3611\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3509 - val_loss: 0.3555\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3499 - val_loss: 0.3550\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3493 - val_loss: 0.3559\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3508 - val_loss: 0.3550\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3479 - val_loss: 0.3547\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3475 - val_loss: 0.3549\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3457 - val_loss: 0.3539\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3474 - val_loss: 0.3538\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3470 - val_loss: 0.3555\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3454 - val_loss: 0.3529\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3445 - val_loss: 0.3516\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3475 - val_loss: 0.3529\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3449 - val_loss: 0.3528\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3434 - val_loss: 0.3515\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3467 - val_loss: 0.3512\n",
      "121/121 [==============================] - 0s 640us/step - loss: 0.3459\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.7602 - val_loss: 1.7896\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.1910 - val_loss: 0.6125\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5865 - val_loss: 0.5242\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5182 - val_loss: 0.4745\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4805 - val_loss: 0.4477\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4577 - val_loss: 0.4341\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4444 - val_loss: 0.4137\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4302 - val_loss: 0.4036\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4291 - val_loss: 0.4020\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4189 - val_loss: 0.4012\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4145 - val_loss: 0.3918\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4069 - val_loss: 0.3909\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4044 - val_loss: 0.3862\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4015 - val_loss: 0.3892\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4008 - val_loss: 0.3928\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3996 - val_loss: 0.3818\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3993 - val_loss: 0.3804\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4017 - val_loss: 0.3807\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3987 - val_loss: 0.3794\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3927 - val_loss: 0.3782\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3884 - val_loss: 0.3738\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3873 - val_loss: 0.3718\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3839 - val_loss: 0.3721\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3869 - val_loss: 0.3726\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3846 - val_loss: 0.3708\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3839 - val_loss: 0.3725\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3845 - val_loss: 0.3693\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3793 - val_loss: 0.3698\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3762 - val_loss: 0.3702\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3905 - val_loss: 0.3719\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3974 - val_loss: 0.3704\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3869 - val_loss: 0.3713\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3750 - val_loss: 0.3644\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3714 - val_loss: 0.3631\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3736 - val_loss: 0.3690\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3902 - val_loss: 0.3657\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3770 - val_loss: 0.3624\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3686 - val_loss: 0.3613\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3676 - val_loss: 0.3804\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4237 - val_loss: 0.3659\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3725 - val_loss: 0.3651\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3785 - val_loss: 0.3691\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3682 - val_loss: 0.3621\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3651 - val_loss: 0.3593\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3632 - val_loss: 0.3616\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3615 - val_loss: 0.3600\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3607 - val_loss: 0.3600\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3599 - val_loss: 0.3567\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3595 - val_loss: 0.3578\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3580 - val_loss: 0.3567\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3572 - val_loss: 0.3590\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3561 - val_loss: 0.3546\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3552 - val_loss: 0.3580\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3632 - val_loss: 0.3566\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3545 - val_loss: 0.3552\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3552 - val_loss: 0.3531\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3552 - val_loss: 0.3546\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3528 - val_loss: 0.3561\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3522 - val_loss: 0.3533\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3515 - val_loss: 0.3533\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3498 - val_loss: 0.3552\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3507 - val_loss: 0.3511\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3500 - val_loss: 0.3528\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3484 - val_loss: 0.3533\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3486 - val_loss: 0.3504\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3481 - val_loss: 0.3543\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3479 - val_loss: 0.3508\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3474 - val_loss: 0.3502\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3469 - val_loss: 0.3510\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3459 - val_loss: 0.3484\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3453 - val_loss: 0.3502\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3451 - val_loss: 0.3472\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3441 - val_loss: 0.3488\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3442 - val_loss: 0.3485\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3428 - val_loss: 0.3539\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3432 - val_loss: 0.3461\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3424 - val_loss: 0.3506\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3425 - val_loss: 0.3491\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3423 - val_loss: 0.3501\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3423 - val_loss: 0.3567\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3765 - val_loss: 0.3458\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3461 - val_loss: 0.3445\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3413 - val_loss: 0.3433\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3467 - val_loss: 0.3490\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3476 - val_loss: 0.3441\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3396 - val_loss: 0.3438\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3394 - val_loss: 0.3426\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3386 - val_loss: 0.3420\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3376 - val_loss: 0.3422\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3367 - val_loss: 0.3432\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3379 - val_loss: 0.3407\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3389 - val_loss: 0.3415\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3370 - val_loss: 0.3446\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3367 - val_loss: 0.3470\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3353 - val_loss: 0.3395\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3353 - val_loss: 0.3415\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3358 - val_loss: 0.3386\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3344 - val_loss: 0.3399\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3341 - val_loss: 0.3421\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3351 - val_loss: 0.3421\n",
      "121/121 [==============================] - 0s 635us/step - loss: 0.3317\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0601 - val_loss: 0.6639\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6280 - val_loss: 0.5771\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5628 - val_loss: 0.5274\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5228 - val_loss: 0.4976\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4966 - val_loss: 0.4796\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4796 - val_loss: 0.4654\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4680 - val_loss: 0.4583\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4583 - val_loss: 0.4524\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4514 - val_loss: 0.4457\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4456 - val_loss: 0.4400\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4401 - val_loss: 0.4367\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4361 - val_loss: 0.4339\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4323 - val_loss: 0.4292\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4283 - val_loss: 0.4288\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4253 - val_loss: 0.4244\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4212 - val_loss: 0.4223\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4197 - val_loss: 0.4186\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4159 - val_loss: 0.4167\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4142 - val_loss: 0.4136\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4107 - val_loss: 0.4132\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4085 - val_loss: 0.4093\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4064 - val_loss: 0.4061\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4043 - val_loss: 0.4059\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4017 - val_loss: 0.4054\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4001 - val_loss: 0.4017\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3980 - val_loss: 0.4004\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3956 - val_loss: 0.3977\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3937 - val_loss: 0.3964\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3920 - val_loss: 0.3964\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3897 - val_loss: 0.3934\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3880 - val_loss: 0.3935\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3866 - val_loss: 0.3904\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3839 - val_loss: 0.3936\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3842 - val_loss: 0.3888\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3817 - val_loss: 0.3872\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3810 - val_loss: 0.3853\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3784 - val_loss: 0.3844\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3773 - val_loss: 0.3835\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3765 - val_loss: 0.3823\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3746 - val_loss: 0.3858\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3738 - val_loss: 0.3831\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3715 - val_loss: 0.3808\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3708 - val_loss: 0.3782\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3698 - val_loss: 0.3775\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3687 - val_loss: 0.3757\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3669 - val_loss: 0.3789\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3662 - val_loss: 0.3744\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3649 - val_loss: 0.3732\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3639 - val_loss: 0.3737\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3624 - val_loss: 0.3717\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3612 - val_loss: 0.3721\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3601 - val_loss: 0.3705\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3586 - val_loss: 0.3699\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3580 - val_loss: 0.3709\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3570 - val_loss: 0.3689\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3560 - val_loss: 0.3676\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3549 - val_loss: 0.3697\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3544 - val_loss: 0.3666\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3531 - val_loss: 0.3665\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3516 - val_loss: 0.3675\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3510 - val_loss: 0.3663\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3505 - val_loss: 0.3679\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3492 - val_loss: 0.3679\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3488 - val_loss: 0.3648\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3488 - val_loss: 0.3635\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3471 - val_loss: 0.3656\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3472 - val_loss: 0.3625\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3457 - val_loss: 0.3619\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3445 - val_loss: 0.3616\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3445 - val_loss: 0.3587\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3432 - val_loss: 0.3590\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3426 - val_loss: 0.3578\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3421 - val_loss: 0.3591\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3411 - val_loss: 0.3588\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3405 - val_loss: 0.3578\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3399 - val_loss: 0.3550\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3396 - val_loss: 0.3566\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3386 - val_loss: 0.3604\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3378 - val_loss: 0.3566\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3368 - val_loss: 0.3547\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3361 - val_loss: 0.3572\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3353 - val_loss: 0.3562\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3354 - val_loss: 0.3521\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3346 - val_loss: 0.3544\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3346 - val_loss: 0.3553\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3339 - val_loss: 0.3534\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3329 - val_loss: 0.3519\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3335 - val_loss: 0.3509\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3323 - val_loss: 0.3504\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3309 - val_loss: 0.3500\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3298 - val_loss: 0.3517\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3306 - val_loss: 0.3500\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3302 - val_loss: 0.3518\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3311 - val_loss: 0.3492\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3289 - val_loss: 0.3549\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3286 - val_loss: 0.3493\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3277 - val_loss: 0.3465\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3281 - val_loss: 0.3457\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3275 - val_loss: 0.3457\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3265 - val_loss: 0.3466\n",
      "121/121 [==============================] - 0s 640us/step - loss: 0.3846\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4099 - val_loss: 0.9773\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3719 - val_loss: 0.6696\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6545 - val_loss: 0.5577\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5623 - val_loss: 0.5210\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5306 - val_loss: 0.4986\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5105 - val_loss: 0.4811\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4952 - val_loss: 0.4700\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4843 - val_loss: 0.4595\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4749 - val_loss: 0.4537\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4675 - val_loss: 0.4472\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4621 - val_loss: 0.4448\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4566 - val_loss: 0.4395\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4520 - val_loss: 0.4332\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4485 - val_loss: 0.4302\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4447 - val_loss: 0.4291\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4418 - val_loss: 0.4246\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4389 - val_loss: 0.4241\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4361 - val_loss: 0.4212\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4339 - val_loss: 0.4204\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4317 - val_loss: 0.4186\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4297 - val_loss: 0.4151\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4267 - val_loss: 0.4141\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4255 - val_loss: 0.4117\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4227 - val_loss: 0.4102\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4200 - val_loss: 0.4072\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4178 - val_loss: 0.4080\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4157 - val_loss: 0.4043\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4138 - val_loss: 0.4067\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4118 - val_loss: 0.4023\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4094 - val_loss: 0.4015\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4078 - val_loss: 0.3984\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4068 - val_loss: 0.3967\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4039 - val_loss: 0.3947\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4032 - val_loss: 0.3936\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4007 - val_loss: 0.3927\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3995 - val_loss: 0.3925\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3983 - val_loss: 0.3929\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3966 - val_loss: 0.3903\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3979 - val_loss: 0.3921\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3950 - val_loss: 0.3904\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3944 - val_loss: 0.3882\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3918 - val_loss: 0.3864\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3902 - val_loss: 0.3906\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3895 - val_loss: 0.3842\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3893 - val_loss: 0.3832\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3872 - val_loss: 0.3948\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3864 - val_loss: 0.3813\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3852 - val_loss: 0.3808\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3831 - val_loss: 0.3794\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3822 - val_loss: 0.3787\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3813 - val_loss: 0.3776\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3801 - val_loss: 0.3791\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3790 - val_loss: 0.3753\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3784 - val_loss: 0.3748\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3765 - val_loss: 0.3749\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3764 - val_loss: 0.3835\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3771 - val_loss: 0.3739\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3743 - val_loss: 0.3745\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3732 - val_loss: 0.3725\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3730 - val_loss: 0.3719\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3712 - val_loss: 0.3709\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3704 - val_loss: 0.3705\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3692 - val_loss: 0.3694\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3688 - val_loss: 0.3690\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3680 - val_loss: 0.3732\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3749 - val_loss: 0.3681\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3671 - val_loss: 0.3672\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3683 - val_loss: 0.3675\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3654 - val_loss: 0.3663\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3644 - val_loss: 0.3689\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3633 - val_loss: 0.3678\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3631 - val_loss: 0.3645\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3623 - val_loss: 0.3656\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3630 - val_loss: 0.3647\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3614 - val_loss: 0.3637\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3611 - val_loss: 0.3626\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3602 - val_loss: 0.3644\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3598 - val_loss: 0.3633\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3594 - val_loss: 0.3625\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3585 - val_loss: 0.3632\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3610 - val_loss: 0.3622\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3608 - val_loss: 0.3653\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3571 - val_loss: 0.3616\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3568 - val_loss: 0.3617\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3560 - val_loss: 0.3626\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3559 - val_loss: 0.3598\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3553 - val_loss: 0.3587\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3549 - val_loss: 0.3640\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3588 - val_loss: 0.3577\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3534 - val_loss: 0.3583\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3529 - val_loss: 0.3587\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3515 - val_loss: 0.3580\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3541 - val_loss: 0.3582\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3520 - val_loss: 0.3574\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3514 - val_loss: 0.3565\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3513 - val_loss: 0.3596\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3503 - val_loss: 0.3564\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3565 - val_loss: 0.3599\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3606 - val_loss: 0.3564\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3502 - val_loss: 0.3569\n",
      "121/121 [==============================] - 0s 663us/step - loss: 0.3559\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.1457 - val_loss: 0.5400\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6686 - val_loss: 0.9109\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1292 - val_loss: 3.0907\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "121/121 [==============================] - 0s 707us/step - loss: nan\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8090 - val_loss: 0.5543\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5083 - val_loss: 0.4582\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4546 - val_loss: 0.4243\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4295 - val_loss: 0.4100\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4096 - val_loss: 0.3949\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3925 - val_loss: 0.3837\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3785 - val_loss: 0.3903\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3677 - val_loss: 0.3679\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3593 - val_loss: 0.3968\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3502 - val_loss: 0.3751\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3427 - val_loss: 0.3525\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3372 - val_loss: 0.3637\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3304 - val_loss: 0.3775\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3219 - val_loss: 0.3659\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3179 - val_loss: 0.3512\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3136 - val_loss: 0.3443\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3085 - val_loss: 0.3357\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3061 - val_loss: 0.3252\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2989 - val_loss: 0.3386\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2990 - val_loss: 0.3246\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2975 - val_loss: 0.3222\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2954 - val_loss: 0.3243\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2907 - val_loss: 0.3293\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2892 - val_loss: 0.3493\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2848 - val_loss: 0.3228\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2818 - val_loss: 0.3211\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2838 - val_loss: 0.3133\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2786 - val_loss: 0.3138\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2764 - val_loss: 0.3683\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2756 - val_loss: 0.3861\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2742 - val_loss: 0.3146\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2730 - val_loss: 0.3161\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2727 - val_loss: 0.3065\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2686 - val_loss: 0.3342\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2673 - val_loss: 0.3185\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2687 - val_loss: 0.3040\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2667 - val_loss: 0.3168\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2622 - val_loss: 0.3099\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2619 - val_loss: 0.3313\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2638 - val_loss: 0.3077\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2634 - val_loss: 0.3036\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2624 - val_loss: 0.3084\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2602 - val_loss: 0.3022\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2587 - val_loss: 0.3160\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2585 - val_loss: 0.3087\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2571 - val_loss: 0.3018\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2555 - val_loss: 0.3015\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2531 - val_loss: 0.3089\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2554 - val_loss: 0.3075\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2536 - val_loss: 0.2956\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2497 - val_loss: 0.3139\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2512 - val_loss: 0.3097\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2521 - val_loss: 0.3029\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2492 - val_loss: 0.3010\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2499 - val_loss: 0.3006\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2496 - val_loss: 0.2970\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2487 - val_loss: 0.3229\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2471 - val_loss: 0.2984\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2481 - val_loss: 0.3689\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2468 - val_loss: 0.3003\n",
      "121/121 [==============================] - 0s 698us/step - loss: 0.3466\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 1.3701 - val_loss: 0.5516\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8826 - val_loss: 0.4480\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4406 - val_loss: 0.4563\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4400 - val_loss: 0.4026\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4101 - val_loss: 0.3839\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3876 - val_loss: 0.3817\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3740 - val_loss: 0.3673\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3630 - val_loss: 0.3782\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3592 - val_loss: 0.3639\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3550 - val_loss: 0.3552\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3473 - val_loss: 0.3449\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3434 - val_loss: 0.3412\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3385 - val_loss: 0.3421\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3369 - val_loss: 0.3454\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3314 - val_loss: 0.3579\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3281 - val_loss: 0.3342\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3223 - val_loss: 0.3341\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3197 - val_loss: 0.3211\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3167 - val_loss: 0.3220\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3138 - val_loss: 0.3396\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3090 - val_loss: 0.3328\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3107 - val_loss: 0.3195\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3048 - val_loss: 0.3435\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3087 - val_loss: 0.3079\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3031 - val_loss: 0.3410\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3031 - val_loss: 0.3168\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3011 - val_loss: 0.3114\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2972 - val_loss: 0.3424\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2978 - val_loss: 0.3083\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2991 - val_loss: 0.3042\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2939 - val_loss: 0.3114\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2934 - val_loss: 0.3171\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2895 - val_loss: 0.3247\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2913 - val_loss: 0.3367\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2911 - val_loss: 0.3088\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2912 - val_loss: 0.3015\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2875 - val_loss: 0.3056\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2841 - val_loss: 0.3041\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2863 - val_loss: 0.3122\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2857 - val_loss: 0.3206\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2849 - val_loss: 0.3019\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2827 - val_loss: 0.3055\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2804 - val_loss: 0.3119\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2808 - val_loss: 0.3100\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2826 - val_loss: 0.2969\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2801 - val_loss: 0.3147\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2773 - val_loss: 0.3037\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2761 - val_loss: 0.3040\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2766 - val_loss: 0.3013\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2747 - val_loss: 0.2955\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2774 - val_loss: 0.2970\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2709 - val_loss: 0.2993\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2725 - val_loss: 0.3082\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2713 - val_loss: 0.3089\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2722 - val_loss: 0.3206\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2728 - val_loss: 0.3063\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2721 - val_loss: 0.3042\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2693 - val_loss: 0.3114\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2668 - val_loss: 0.2939\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2680 - val_loss: 0.3092\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2658 - val_loss: 0.3057\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2668 - val_loss: 0.3000\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2627 - val_loss: 0.3095\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2666 - val_loss: 0.3021\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2626 - val_loss: 0.3277\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2635 - val_loss: 0.2996\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2631 - val_loss: 0.3189\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2589 - val_loss: 0.3035\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2631 - val_loss: 0.3075\n",
      "121/121 [==============================] - 0s 696us/step - loss: 0.2910\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 3.8666 - val_loss: 2.2290\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.7365 - val_loss: 1.2048\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1709 - val_loss: 0.9196\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8948 - val_loss: 0.7895\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7807 - val_loss: 0.7294\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7310 - val_loss: 0.6980\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7050 - val_loss: 0.6776\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6877 - val_loss: 0.6630\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6744 - val_loss: 0.6503\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6628 - val_loss: 0.6391\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6522 - val_loss: 0.6287\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6425 - val_loss: 0.6193\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6334 - val_loss: 0.6108\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6249 - val_loss: 0.6024\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6166 - val_loss: 0.5948\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6091 - val_loss: 0.5871\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6017 - val_loss: 0.5800\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5947 - val_loss: 0.5732\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5881 - val_loss: 0.5671\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5818 - val_loss: 0.5609\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5758 - val_loss: 0.5549\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5702 - val_loss: 0.5496\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5646 - val_loss: 0.5440\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5595 - val_loss: 0.5389\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5544 - val_loss: 0.5343\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5495 - val_loss: 0.5292\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5448 - val_loss: 0.5254\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5405 - val_loss: 0.5204\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5362 - val_loss: 0.5164\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5320 - val_loss: 0.5122\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5282 - val_loss: 0.5083\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5245 - val_loss: 0.5046\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5207 - val_loss: 0.5008\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5174 - val_loss: 0.4975\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5140 - val_loss: 0.4940\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5107 - val_loss: 0.4907\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5076 - val_loss: 0.4877\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5046 - val_loss: 0.4846\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5016 - val_loss: 0.4818\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4989 - val_loss: 0.4788\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4962 - val_loss: 0.4762\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4936 - val_loss: 0.4737\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4912 - val_loss: 0.4710\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4887 - val_loss: 0.4688\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4865 - val_loss: 0.4662\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4842 - val_loss: 0.4641\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4821 - val_loss: 0.4621\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4800 - val_loss: 0.4600\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4781 - val_loss: 0.4578\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4761 - val_loss: 0.4558\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4743 - val_loss: 0.4538\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4725 - val_loss: 0.4519\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4707 - val_loss: 0.4501\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4690 - val_loss: 0.4485\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4673 - val_loss: 0.4468\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4657 - val_loss: 0.4454\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4641 - val_loss: 0.4440\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4626 - val_loss: 0.4423\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4612 - val_loss: 0.4409\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4598 - val_loss: 0.4392\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4585 - val_loss: 0.4380\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4570 - val_loss: 0.4368\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4557 - val_loss: 0.4353\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4544 - val_loss: 0.4341\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4531 - val_loss: 0.4329\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4519 - val_loss: 0.4317\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4508 - val_loss: 0.4307\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4494 - val_loss: 0.4296\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4485 - val_loss: 0.4283\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4472 - val_loss: 0.4272\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4462 - val_loss: 0.4261\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4450 - val_loss: 0.4249\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4440 - val_loss: 0.4238\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4427 - val_loss: 0.4236\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4418 - val_loss: 0.4222\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4411 - val_loss: 0.4212\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4398 - val_loss: 0.4202\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4389 - val_loss: 0.4195\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4380 - val_loss: 0.4184\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4370 - val_loss: 0.4177\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4361 - val_loss: 0.4168\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4352 - val_loss: 0.4159\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4343 - val_loss: 0.4153\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4335 - val_loss: 0.4144\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4325 - val_loss: 0.4137\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4318 - val_loss: 0.4129\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4310 - val_loss: 0.4122\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4300 - val_loss: 0.4115\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4293 - val_loss: 0.4107\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4287 - val_loss: 0.4102\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4278 - val_loss: 0.4094\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4271 - val_loss: 0.4086\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4263 - val_loss: 0.4082\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4257 - val_loss: 0.4075\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4249 - val_loss: 0.4068\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4243 - val_loss: 0.4065\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4237 - val_loss: 0.4059\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4228 - val_loss: 0.4053\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4223 - val_loss: 0.4043\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4216 - val_loss: 0.4039\n",
      "121/121 [==============================] - 0s 701us/step - loss: 0.4177\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 3.7888 - val_loss: 2.2485\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5137 - val_loss: 1.0860\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9379 - val_loss: 0.9057\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8167 - val_loss: 0.8292\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7552 - val_loss: 0.7766\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7153 - val_loss: 0.7397\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6881 - val_loss: 0.7099\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6681 - val_loss: 0.6882\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6519 - val_loss: 0.6699\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6386 - val_loss: 0.6526\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6269 - val_loss: 0.6379\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6164 - val_loss: 0.6242\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6069 - val_loss: 0.6118\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5982 - val_loss: 0.6019\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5902 - val_loss: 0.5911\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5826 - val_loss: 0.5819\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5755 - val_loss: 0.5732\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5688 - val_loss: 0.5651\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5625 - val_loss: 0.5583\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5566 - val_loss: 0.5510\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5510 - val_loss: 0.5449\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5458 - val_loss: 0.5390\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5407 - val_loss: 0.5335\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5359 - val_loss: 0.5282\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5313 - val_loss: 0.5233\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5270 - val_loss: 0.5186\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5228 - val_loss: 0.5143\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5187 - val_loss: 0.5100\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5151 - val_loss: 0.5060\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5113 - val_loss: 0.5023\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5079 - val_loss: 0.4986\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5045 - val_loss: 0.4952\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5013 - val_loss: 0.4918\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4981 - val_loss: 0.4887\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4951 - val_loss: 0.4858\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4923 - val_loss: 0.4829\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4896 - val_loss: 0.4801\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4866 - val_loss: 0.4780\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4844 - val_loss: 0.4750\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4818 - val_loss: 0.4726\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4795 - val_loss: 0.4703\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4772 - val_loss: 0.4681\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4749 - val_loss: 0.4659\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4728 - val_loss: 0.4640\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4706 - val_loss: 0.4620\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4688 - val_loss: 0.4600\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4668 - val_loss: 0.4582\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4649 - val_loss: 0.4564\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4631 - val_loss: 0.4547\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4613 - val_loss: 0.4530\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4596 - val_loss: 0.4514\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4579 - val_loss: 0.4498\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4563 - val_loss: 0.4484\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4547 - val_loss: 0.4469\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4531 - val_loss: 0.4455\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4515 - val_loss: 0.4441\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4501 - val_loss: 0.4429\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4486 - val_loss: 0.4415\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4472 - val_loss: 0.4403\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4457 - val_loss: 0.4392\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4445 - val_loss: 0.4380\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4431 - val_loss: 0.4370\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4418 - val_loss: 0.4358\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4406 - val_loss: 0.4347\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4393 - val_loss: 0.4338\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4380 - val_loss: 0.4327\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4369 - val_loss: 0.4318\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4358 - val_loss: 0.4309\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4346 - val_loss: 0.4301\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4335 - val_loss: 0.4292\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4325 - val_loss: 0.4283\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4315 - val_loss: 0.4275\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4304 - val_loss: 0.4266\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4294 - val_loss: 0.4259\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4284 - val_loss: 0.4252\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4275 - val_loss: 0.4243\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4265 - val_loss: 0.4235\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4256 - val_loss: 0.4231\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4248 - val_loss: 0.4221\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4238 - val_loss: 0.4212\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4229 - val_loss: 0.4206\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4221 - val_loss: 0.4199\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4212 - val_loss: 0.4192\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4204 - val_loss: 0.4187\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4196 - val_loss: 0.4180\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4187 - val_loss: 0.4176\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4180 - val_loss: 0.4166\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4171 - val_loss: 0.4160\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4164 - val_loss: 0.4155\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4156 - val_loss: 0.4148\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4148 - val_loss: 0.4142\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4141 - val_loss: 0.4141\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4133 - val_loss: 0.4135\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4126 - val_loss: 0.4125\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4118 - val_loss: 0.4120\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4111 - val_loss: 0.4113\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4103 - val_loss: 0.4110\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4097 - val_loss: 0.4102\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4090 - val_loss: 0.4097\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4082 - val_loss: 0.4097\n",
      "121/121 [==============================] - 0s 695us/step - loss: 0.4466\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 3.5386 - val_loss: 2.1261\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.6740 - val_loss: 1.1355\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0827 - val_loss: 0.8831\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8621 - val_loss: 0.7759\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7755 - val_loss: 0.7258\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7341 - val_loss: 0.6978\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7087 - val_loss: 0.6770\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6901 - val_loss: 0.6609\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6753 - val_loss: 0.6477\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6624 - val_loss: 0.6360\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6508 - val_loss: 0.6257\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6405 - val_loss: 0.6160\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6309 - val_loss: 0.6069\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6219 - val_loss: 0.5984\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6132 - val_loss: 0.5904\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6051 - val_loss: 0.5835\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5980 - val_loss: 0.5757\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5904 - val_loss: 0.5697\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5839 - val_loss: 0.5626\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5774 - val_loss: 0.5568\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5715 - val_loss: 0.5507\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5656 - val_loss: 0.5447\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5600 - val_loss: 0.5393\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5548 - val_loss: 0.5344\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5499 - val_loss: 0.5299\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5452 - val_loss: 0.5250\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5408 - val_loss: 0.5208\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5363 - val_loss: 0.5169\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5325 - val_loss: 0.5127\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5285 - val_loss: 0.5090\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5248 - val_loss: 0.5052\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5212 - val_loss: 0.5017\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5177 - val_loss: 0.4985\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5145 - val_loss: 0.4954\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5114 - val_loss: 0.4919\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5085 - val_loss: 0.4893\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5055 - val_loss: 0.4864\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5028 - val_loss: 0.4837\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5002 - val_loss: 0.4811\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4976 - val_loss: 0.4789\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4950 - val_loss: 0.4761\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4928 - val_loss: 0.4740\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4904 - val_loss: 0.4717\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4883 - val_loss: 0.4699\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4861 - val_loss: 0.4674\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4841 - val_loss: 0.4655\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4821 - val_loss: 0.4636\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4801 - val_loss: 0.4619\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4783 - val_loss: 0.4600\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4765 - val_loss: 0.4582\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4747 - val_loss: 0.4565\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4730 - val_loss: 0.4551\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4712 - val_loss: 0.4533\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4696 - val_loss: 0.4516\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4678 - val_loss: 0.4504\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4662 - val_loss: 0.4491\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4646 - val_loss: 0.4475\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4632 - val_loss: 0.4458\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4616 - val_loss: 0.4445\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4600 - val_loss: 0.4430\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4587 - val_loss: 0.4417\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4572 - val_loss: 0.4403\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4557 - val_loss: 0.4390\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4545 - val_loss: 0.4375\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4530 - val_loss: 0.4369\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4516 - val_loss: 0.4356\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4504 - val_loss: 0.4345\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4491 - val_loss: 0.4331\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4478 - val_loss: 0.4317\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4464 - val_loss: 0.4304\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4453 - val_loss: 0.4294\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4439 - val_loss: 0.4287\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4427 - val_loss: 0.4273\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4412 - val_loss: 0.4267\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4403 - val_loss: 0.4254\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4391 - val_loss: 0.4241\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4380 - val_loss: 0.4229\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4368 - val_loss: 0.4224\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4356 - val_loss: 0.4212\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4345 - val_loss: 0.4199\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4334 - val_loss: 0.4198\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4323 - val_loss: 0.4183\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4313 - val_loss: 0.4175\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4303 - val_loss: 0.4167\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4292 - val_loss: 0.4160\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4282 - val_loss: 0.4149\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4272 - val_loss: 0.4141\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4263 - val_loss: 0.4135\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4252 - val_loss: 0.4126\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4244 - val_loss: 0.4115\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4233 - val_loss: 0.4105\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4226 - val_loss: 0.4101\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4216 - val_loss: 0.4099\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4208 - val_loss: 0.4087\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4199 - val_loss: 0.4079\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4191 - val_loss: 0.4075\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4183 - val_loss: 0.4068\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4174 - val_loss: 0.4060\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4167 - val_loss: 0.4053\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4157 - val_loss: 0.4051\n",
      "121/121 [==============================] - 0s 706us/step - loss: 0.4191\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 0.9576 - val_loss: 0.8349\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3628 - val_loss: 0.4833\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.5780 - val_loss: 0.4905\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5945 - val_loss: 0.4205\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "121/121 [==============================] - 0s 705us/step - loss: nan\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 0.7437 - val_loss: 0.4636\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4490 - val_loss: 0.4250\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4188 - val_loss: 0.4098\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4026 - val_loss: 0.4096\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3887 - val_loss: 0.4647\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3776 - val_loss: 0.3832\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3695 - val_loss: 0.3783\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3621 - val_loss: 0.3896\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3576 - val_loss: 0.3679\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3487 - val_loss: 0.3565\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3461 - val_loss: 0.3520\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3387 - val_loss: 0.3549\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3363 - val_loss: 0.3621\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3344 - val_loss: 0.3563\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3307 - val_loss: 0.3537\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3243 - val_loss: 0.3409\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3212 - val_loss: 0.3576\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3215 - val_loss: 0.3513\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3176 - val_loss: 0.3363\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3134 - val_loss: 0.3389\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3107 - val_loss: 0.3488\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3127 - val_loss: 0.3418\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3066 - val_loss: 0.3432\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3057 - val_loss: 0.3302\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3025 - val_loss: 0.3348\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3006 - val_loss: 0.3313\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2995 - val_loss: 0.3232\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2974 - val_loss: 0.3397\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2991 - val_loss: 0.3496\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2964 - val_loss: 0.3348\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2934 - val_loss: 0.3313\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2928 - val_loss: 0.3180\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2919 - val_loss: 0.3246\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2898 - val_loss: 0.3202\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2877 - val_loss: 0.3171\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2879 - val_loss: 0.3239\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2830 - val_loss: 0.3278\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2851 - val_loss: 0.3125\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2863 - val_loss: 0.3434\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2817 - val_loss: 0.3147\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2808 - val_loss: 0.3288\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2813 - val_loss: 0.3439\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2813 - val_loss: 0.3149\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2793 - val_loss: 0.3127\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2759 - val_loss: 0.3070\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2780 - val_loss: 0.3081\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2767 - val_loss: 0.3171\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2772 - val_loss: 0.3250\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2744 - val_loss: 0.3299\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2760 - val_loss: 0.3072\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2735 - val_loss: 0.3056\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2726 - val_loss: 0.3202\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2707 - val_loss: 0.3182\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2705 - val_loss: 0.3137\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2693 - val_loss: 0.3024\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2701 - val_loss: 0.3143\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2669 - val_loss: 0.3253\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2667 - val_loss: 0.3021\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2703 - val_loss: 0.3054\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2667 - val_loss: 0.3204\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2661 - val_loss: 0.3117\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2690 - val_loss: 0.3002\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2652 - val_loss: 0.3109\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2652 - val_loss: 0.3128\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2644 - val_loss: 0.3002\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2637 - val_loss: 0.3086\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2629 - val_loss: 0.3177\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2651 - val_loss: 0.3037\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2627 - val_loss: 0.3091\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2618 - val_loss: 0.3004\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2598 - val_loss: 0.3110\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2615 - val_loss: 0.3200\n",
      "121/121 [==============================] - 0s 667us/step - loss: 0.3398\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 1.6117 - val_loss: 1.4093\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6347 - val_loss: 0.6314\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5498 - val_loss: 0.4338\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4300 - val_loss: 0.4123\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4177 - val_loss: 0.4075\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4076 - val_loss: 0.4067\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4069 - val_loss: 0.3874\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3960 - val_loss: 0.3868\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3866 - val_loss: 0.3752\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3785 - val_loss: 0.3840\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3707 - val_loss: 0.3683\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3666 - val_loss: 0.3623\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3597 - val_loss: 0.3824\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3558 - val_loss: 0.3605\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3528 - val_loss: 0.3548\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3477 - val_loss: 0.3716\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3441 - val_loss: 0.3514\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3410 - val_loss: 0.3532\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3362 - val_loss: 0.3425\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3341 - val_loss: 0.3482\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3305 - val_loss: 0.3400\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3294 - val_loss: 0.3471\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3258 - val_loss: 0.3295\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3231 - val_loss: 0.3400\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3220 - val_loss: 0.3273\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3193 - val_loss: 0.3401\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3186 - val_loss: 0.3437\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3141 - val_loss: 0.3311\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3143 - val_loss: 0.3216\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3113 - val_loss: 0.3233\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3094 - val_loss: 0.3219\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3063 - val_loss: 0.3205\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3063 - val_loss: 0.3301\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3060 - val_loss: 0.3263\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3035 - val_loss: 0.3429\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3034 - val_loss: 0.3222\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3027 - val_loss: 0.3198\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3016 - val_loss: 0.3157\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2993 - val_loss: 0.3107\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2975 - val_loss: 0.3198\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2969 - val_loss: 0.3396\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2964 - val_loss: 0.3191\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2964 - val_loss: 0.3168\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2938 - val_loss: 0.3137\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2941 - val_loss: 0.3278\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2932 - val_loss: 0.3085\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2917 - val_loss: 0.3170\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2894 - val_loss: 0.3236\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2905 - val_loss: 0.3147\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2891 - val_loss: 0.3114\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2885 - val_loss: 0.3143\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2866 - val_loss: 0.3119\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2846 - val_loss: 0.3235\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2876 - val_loss: 0.3138\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2840 - val_loss: 0.3158\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2813 - val_loss: 0.3054\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2823 - val_loss: 0.3070\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2819 - val_loss: 0.3027\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2821 - val_loss: 0.3090\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2794 - val_loss: 0.3085\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2819 - val_loss: 0.3076\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2796 - val_loss: 0.3144\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2791 - val_loss: 0.3170\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2965 - val_loss: 0.3837\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4449 - val_loss: 0.3170\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2947 - val_loss: 0.3120\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2873 - val_loss: 0.3078\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2863 - val_loss: 0.3023\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2839 - val_loss: 0.3081\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2830 - val_loss: 0.3086\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2820 - val_loss: 0.3123\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2796 - val_loss: 0.3163\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2787 - val_loss: 0.3161\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2798 - val_loss: 0.3070\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2768 - val_loss: 0.3046\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2794 - val_loss: 0.3057\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2770 - val_loss: 0.3048\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2767 - val_loss: 0.3106\n",
      "121/121 [==============================] - 0s 689us/step - loss: 0.2897\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 3.0697 - val_loss: 1.3632\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2252 - val_loss: 1.0385\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9788 - val_loss: 0.8552\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8173 - val_loss: 0.7248\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7138 - val_loss: 0.6564\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6541 - val_loss: 0.6136\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6216 - val_loss: 0.5855\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5952 - val_loss: 0.5626\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5734 - val_loss: 0.5432\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5558 - val_loss: 0.5277\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5407 - val_loss: 0.5133\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5283 - val_loss: 0.5011\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5174 - val_loss: 0.4918\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5091 - val_loss: 0.4834\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5021 - val_loss: 0.4770\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4958 - val_loss: 0.4702\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4903 - val_loss: 0.4647\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4851 - val_loss: 0.4605\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4804 - val_loss: 0.4552\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4756 - val_loss: 0.4525\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4724 - val_loss: 0.4484\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4682 - val_loss: 0.4446\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4651 - val_loss: 0.4418\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4620 - val_loss: 0.4388\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4587 - val_loss: 0.4366\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4561 - val_loss: 0.4332\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4535 - val_loss: 0.4314\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4508 - val_loss: 0.4289\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4487 - val_loss: 0.4273\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4460 - val_loss: 0.4255\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4441 - val_loss: 0.4248\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4418 - val_loss: 0.4221\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4393 - val_loss: 0.4211\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4376 - val_loss: 0.4199\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4355 - val_loss: 0.4180\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4340 - val_loss: 0.4154\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4324 - val_loss: 0.4142\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4305 - val_loss: 0.4131\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4286 - val_loss: 0.4118\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4274 - val_loss: 0.4119\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4260 - val_loss: 0.4103\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4244 - val_loss: 0.4083\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4231 - val_loss: 0.4068\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4216 - val_loss: 0.4070\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4205 - val_loss: 0.4055\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4189 - val_loss: 0.4041\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4178 - val_loss: 0.4038\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4167 - val_loss: 0.4017\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4157 - val_loss: 0.4012\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4146 - val_loss: 0.4004\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4135 - val_loss: 0.4013\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4123 - val_loss: 0.3987\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4111 - val_loss: 0.3974\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4103 - val_loss: 0.3978\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4094 - val_loss: 0.3970\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4083 - val_loss: 0.3963\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4070 - val_loss: 0.3956\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4065 - val_loss: 0.3964\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4054 - val_loss: 0.3947\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4048 - val_loss: 0.3933\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4033 - val_loss: 0.3938\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4029 - val_loss: 0.3915\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4019 - val_loss: 0.3913\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4008 - val_loss: 0.3893\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4002 - val_loss: 0.3888\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3994 - val_loss: 0.3894\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3986 - val_loss: 0.3890\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3981 - val_loss: 0.3876\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3966 - val_loss: 0.3872\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3965 - val_loss: 0.3868\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3956 - val_loss: 0.3857\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3949 - val_loss: 0.3850\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3943 - val_loss: 0.3842\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3932 - val_loss: 0.3852\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3926 - val_loss: 0.3837\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3920 - val_loss: 0.3828\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3911 - val_loss: 0.3827\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3904 - val_loss: 0.3825\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3896 - val_loss: 0.3813\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3889 - val_loss: 0.3820\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3883 - val_loss: 0.3816\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3877 - val_loss: 0.3789\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3868 - val_loss: 0.3820\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3862 - val_loss: 0.3812\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3856 - val_loss: 0.3787\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3850 - val_loss: 0.3777\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3843 - val_loss: 0.3782\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3837 - val_loss: 0.3769\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3830 - val_loss: 0.3783\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3822 - val_loss: 0.3789\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3821 - val_loss: 0.3757\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3813 - val_loss: 0.3758\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3805 - val_loss: 0.3754\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3798 - val_loss: 0.3754\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3793 - val_loss: 0.3747\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3789 - val_loss: 0.3740\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3783 - val_loss: 0.3740\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3776 - val_loss: 0.3737\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3766 - val_loss: 0.3758\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3767 - val_loss: 0.3720\n",
      "121/121 [==============================] - 0s 687us/step - loss: 0.3664\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.3803 - val_loss: 0.8238\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7164 - val_loss: 0.6907\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6399 - val_loss: 0.6283\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5947 - val_loss: 0.5858\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5627 - val_loss: 0.5564\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5391 - val_loss: 0.5370\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5212 - val_loss: 0.5173\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5071 - val_loss: 0.5036\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4963 - val_loss: 0.4924\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4877 - val_loss: 0.4845\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4807 - val_loss: 0.4775\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4747 - val_loss: 0.4709\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4691 - val_loss: 0.4660\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4642 - val_loss: 0.4616\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4600 - val_loss: 0.4566\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4558 - val_loss: 0.4538\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4522 - val_loss: 0.4516\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4490 - val_loss: 0.4466\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4458 - val_loss: 0.4438\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4433 - val_loss: 0.4414\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4403 - val_loss: 0.4386\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4372 - val_loss: 0.4373\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4351 - val_loss: 0.4355\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4328 - val_loss: 0.4324\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4306 - val_loss: 0.4303\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4278 - val_loss: 0.4297\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4268 - val_loss: 0.4272\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4247 - val_loss: 0.4249\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4225 - val_loss: 0.4232\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4211 - val_loss: 0.4214\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4192 - val_loss: 0.4203\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4171 - val_loss: 0.4194\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4155 - val_loss: 0.4187\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4144 - val_loss: 0.4171\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4125 - val_loss: 0.4158\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4109 - val_loss: 0.4142\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4094 - val_loss: 0.4140\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4079 - val_loss: 0.4119\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4066 - val_loss: 0.4109\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4052 - val_loss: 0.4099\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4035 - val_loss: 0.4082\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4015 - val_loss: 0.4085\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4001 - val_loss: 0.4074\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3988 - val_loss: 0.4050\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3973 - val_loss: 0.4038\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3954 - val_loss: 0.4047\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3938 - val_loss: 0.4021\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3929 - val_loss: 0.3991\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3914 - val_loss: 0.3987\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3900 - val_loss: 0.3961\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3883 - val_loss: 0.3967\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3872 - val_loss: 0.3937\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3861 - val_loss: 0.3931\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3848 - val_loss: 0.3920\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3837 - val_loss: 0.3907\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3825 - val_loss: 0.3901\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3815 - val_loss: 0.3889\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3801 - val_loss: 0.3877\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3795 - val_loss: 0.3869\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3785 - val_loss: 0.3852\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3775 - val_loss: 0.3849\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3766 - val_loss: 0.3843\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3754 - val_loss: 0.3830\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3743 - val_loss: 0.3830\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3731 - val_loss: 0.3822\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3721 - val_loss: 0.3806\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3715 - val_loss: 0.3798\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3702 - val_loss: 0.3794\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3692 - val_loss: 0.3794\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3687 - val_loss: 0.3774\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3678 - val_loss: 0.3773\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3667 - val_loss: 0.3768\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3658 - val_loss: 0.3764\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3652 - val_loss: 0.3749\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3641 - val_loss: 0.3747\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3632 - val_loss: 0.3736\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3630 - val_loss: 0.3731\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3623 - val_loss: 0.3732\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3612 - val_loss: 0.3724\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3604 - val_loss: 0.3716\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3595 - val_loss: 0.3710\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3595 - val_loss: 0.3697\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3584 - val_loss: 0.3708\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3575 - val_loss: 0.3714\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3574 - val_loss: 0.3677\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3563 - val_loss: 0.3683\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3553 - val_loss: 0.3672\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3543 - val_loss: 0.3676\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3533 - val_loss: 0.3683\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3532 - val_loss: 0.3649\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3526 - val_loss: 0.3642\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3515 - val_loss: 0.3654\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3508 - val_loss: 0.3639\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3501 - val_loss: 0.3631\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3491 - val_loss: 0.3650\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3489 - val_loss: 0.3620\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3475 - val_loss: 0.3668\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3470 - val_loss: 0.3615\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3463 - val_loss: 0.3607\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3453 - val_loss: 0.3602\n",
      "121/121 [==============================] - 0s 693us/step - loss: 0.3779\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.1998 - val_loss: 0.8957\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6930 - val_loss: 0.6133\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6210 - val_loss: 0.5836\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5938 - val_loss: 0.5634\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5727 - val_loss: 0.5457\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5548 - val_loss: 0.5323\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5399 - val_loss: 0.5187\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5271 - val_loss: 0.5073\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5157 - val_loss: 0.4977\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5062 - val_loss: 0.4889\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4975 - val_loss: 0.4825\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4892 - val_loss: 0.4735\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4829 - val_loss: 0.4695\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4773 - val_loss: 0.4646\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4723 - val_loss: 0.4620\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4673 - val_loss: 0.4577\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4635 - val_loss: 0.4536\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4600 - val_loss: 0.4510\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4563 - val_loss: 0.4474\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4540 - val_loss: 0.4457\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4520 - val_loss: 0.4475\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4483 - val_loss: 0.4437\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4459 - val_loss: 0.4447\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4443 - val_loss: 0.4379\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4422 - val_loss: 0.4382\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4402 - val_loss: 0.4342\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4381 - val_loss: 0.4313\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4368 - val_loss: 0.4352\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4353 - val_loss: 0.4306\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4338 - val_loss: 0.4308\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4308 - val_loss: 0.4259\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4300 - val_loss: 0.4288\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4282 - val_loss: 0.4237\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4267 - val_loss: 0.4263\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4255 - val_loss: 0.4205\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4239 - val_loss: 0.4213\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4227 - val_loss: 0.4181\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4207 - val_loss: 0.4173\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4203 - val_loss: 0.4159\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4188 - val_loss: 0.4235\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4175 - val_loss: 0.4137\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4165 - val_loss: 0.4137\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4150 - val_loss: 0.4107\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4139 - val_loss: 0.4114\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4134 - val_loss: 0.4102\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4119 - val_loss: 0.4088\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4108 - val_loss: 0.4078\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4092 - val_loss: 0.4056\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4090 - val_loss: 0.4077\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4077 - val_loss: 0.4051\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4069 - val_loss: 0.4048\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4055 - val_loss: 0.4031\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4046 - val_loss: 0.4060\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4036 - val_loss: 0.4012\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4025 - val_loss: 0.4013\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4021 - val_loss: 0.3991\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4009 - val_loss: 0.4005\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3998 - val_loss: 0.4006\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3989 - val_loss: 0.3983\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3980 - val_loss: 0.3985\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3963 - val_loss: 0.3978\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3960 - val_loss: 0.3954\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3951 - val_loss: 0.3967\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3938 - val_loss: 0.3957\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3935 - val_loss: 0.3941\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3930 - val_loss: 0.3950\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3921 - val_loss: 0.3933\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3913 - val_loss: 0.3942\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3904 - val_loss: 0.3933\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3901 - val_loss: 0.3907\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3886 - val_loss: 0.3911\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3882 - val_loss: 0.3909\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3878 - val_loss: 0.3913\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3867 - val_loss: 0.3905\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3857 - val_loss: 0.3889\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3849 - val_loss: 0.3899\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3843 - val_loss: 0.3899\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3836 - val_loss: 0.3884\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3825 - val_loss: 0.3888\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3823 - val_loss: 0.3877\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3811 - val_loss: 0.3874\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3807 - val_loss: 0.3875\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3806 - val_loss: 0.3863\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3795 - val_loss: 0.3841\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3782 - val_loss: 0.3863\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3782 - val_loss: 0.3821\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3777 - val_loss: 0.3820\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3768 - val_loss: 0.3841\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3763 - val_loss: 0.3822\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3755 - val_loss: 0.3816\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3748 - val_loss: 0.3846\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3739 - val_loss: 0.3840\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3736 - val_loss: 0.3807\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3732 - val_loss: 0.3803\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3722 - val_loss: 0.3817\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3719 - val_loss: 0.3818\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3709 - val_loss: 0.3791\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3707 - val_loss: 0.3792\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3699 - val_loss: 0.3793\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3695 - val_loss: 0.3777\n",
      "121/121 [==============================] - 0s 720us/step - loss: 0.3750\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3592 - val_loss: 6.7264\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 10.5581 - val_loss: 774.6107\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2929.3389 - val_loss: 106570.3672\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 607413.5625 - val_loss: 14682928.0000\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 83301248.0000 - val_loss: 2018430208.0000\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 999us/step - loss: 4722416640.0000 - val_loss: 278060826624.0000\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1330290753536.0000 - val_loss: 38333354868736.0000\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 61065865986048.0000 - val_loss: 5328553860136960.0000\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 18372551537328128.0000 - val_loss: 717644985977012224.0000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1444229276365750272.0000 - val_loss: 99022923195087847424.0000\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 204436542222344650752.0000 - val_loss: 13614852299702069624832.0000\n",
      "121/121 [==============================] - 0s 604us/step - loss: 2094273891081501278208.0000\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9104 - val_loss: 0.5381\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5324 - val_loss: 0.5270\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5228 - val_loss: 0.5475\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5208 - val_loss: 0.5408\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5194 - val_loss: 0.5306\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5190 - val_loss: 0.5476\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5185 - val_loss: 0.5204\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5210 - val_loss: 0.5250\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5217 - val_loss: 0.5270\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5189 - val_loss: 0.5428\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5213 - val_loss: 0.5463\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 996us/step - loss: 0.5205 - val_loss: 0.5441\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5170 - val_loss: 0.5468\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5210 - val_loss: 0.5317\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5195 - val_loss: 0.5486\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5190 - val_loss: 0.5396\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5191 - val_loss: 0.5308\n",
      "121/121 [==============================] - 0s 615us/step - loss: 0.6431\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2256 - val_loss: 1.4319\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 13.8693 - val_loss: 32.2599\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 47.2084 - val_loss: 1089.6923\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 893.7189 - val_loss: 37247.9727\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 40396.6836 - val_loss: 1288422.7500\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 20090528.0000 - val_loss: 44155348.0000\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 763803904.0000 - val_loss: 1509348096.0000\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 22493220864.0000 - val_loss: 52027850752.0000\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 59614126080.0000 - val_loss: 1787219279872.0000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 24943412641792.0000 - val_loss: 61697490419712.0000\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 29905716772864.0000 - val_loss: 2180459467374592.0000\n",
      "121/121 [==============================] - 0s 617us/step - loss: 23381961342976.0000\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 3.2238 - val_loss: 1.7337\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5243 - val_loss: 1.0470\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9566 - val_loss: 0.8240\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8045 - val_loss: 0.7527\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7480 - val_loss: 0.7179\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7184 - val_loss: 0.6952\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6981 - val_loss: 0.6773\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6818 - val_loss: 0.6626\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6678 - val_loss: 0.6506\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6563 - val_loss: 0.6387\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6459 - val_loss: 0.6297\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6363 - val_loss: 0.6207\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6279 - val_loss: 0.6122\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6206 - val_loss: 0.6055\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6135 - val_loss: 0.5990\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6072 - val_loss: 0.5929\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6012 - val_loss: 0.5874\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5958 - val_loss: 0.5820\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5907 - val_loss: 0.5778\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5857 - val_loss: 0.5726\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5810 - val_loss: 0.5677\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5767 - val_loss: 0.5636\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5725 - val_loss: 0.5602\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5684 - val_loss: 0.5559\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5644 - val_loss: 0.5518\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5607 - val_loss: 0.5481\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5571 - val_loss: 0.5450\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5537 - val_loss: 0.5421\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5503 - val_loss: 0.5398\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5468 - val_loss: 0.5365\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5433 - val_loss: 0.5319\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5405 - val_loss: 0.5301\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5373 - val_loss: 0.5264\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5344 - val_loss: 0.5238\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5316 - val_loss: 0.5219\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5288 - val_loss: 0.5188\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5259 - val_loss: 0.5156\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5232 - val_loss: 0.5153\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5207 - val_loss: 0.5119\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5177 - val_loss: 0.5073\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5158 - val_loss: 0.5074\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5133 - val_loss: 0.5037\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5104 - val_loss: 0.5007\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5082 - val_loss: 0.4995\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5061 - val_loss: 0.5003\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5036 - val_loss: 0.4942\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5012 - val_loss: 0.4915\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5000 - val_loss: 0.4909\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4971 - val_loss: 0.4898\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4949 - val_loss: 0.4855\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4934 - val_loss: 0.4844\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4908 - val_loss: 0.4816\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4898 - val_loss: 0.4842\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4875 - val_loss: 0.4790\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4860 - val_loss: 0.4787\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4841 - val_loss: 0.4777\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4823 - val_loss: 0.4745\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4805 - val_loss: 0.4726\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4788 - val_loss: 0.4698\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4777 - val_loss: 0.4681\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4762 - val_loss: 0.4724\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4750 - val_loss: 0.4682\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4731 - val_loss: 0.4646\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4719 - val_loss: 0.4686\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4708 - val_loss: 0.4647\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4694 - val_loss: 0.4646\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4676 - val_loss: 0.4593\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4667 - val_loss: 0.4586\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4663 - val_loss: 0.4588\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4647 - val_loss: 0.4576\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4641 - val_loss: 0.4595\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4616 - val_loss: 0.4535\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4615 - val_loss: 0.4532\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4607 - val_loss: 0.4533\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4598 - val_loss: 0.4542\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4585 - val_loss: 0.4525\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4577 - val_loss: 0.4559\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4566 - val_loss: 0.4504\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4550 - val_loss: 0.4472\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4550 - val_loss: 0.4507\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4539 - val_loss: 0.4523\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4533 - val_loss: 0.4467\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4528 - val_loss: 0.4482\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4513 - val_loss: 0.4447\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4512 - val_loss: 0.4450\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4498 - val_loss: 0.4426\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4497 - val_loss: 0.4426\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4490 - val_loss: 0.4446\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4480 - val_loss: 0.4412\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4471 - val_loss: 0.4434\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4465 - val_loss: 0.4397\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4463 - val_loss: 0.4407\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4457 - val_loss: 0.4423\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4440 - val_loss: 0.4369\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4448 - val_loss: 0.4383\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4432 - val_loss: 0.4381\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4427 - val_loss: 0.4362\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4420 - val_loss: 0.4352\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4420 - val_loss: 0.4350\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4408 - val_loss: 0.4352\n",
      "121/121 [==============================] - 0s 669us/step - loss: 0.4302\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 4.6737 - val_loss: 3.1465\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.3055 - val_loss: 1.5969\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3156 - val_loss: 1.0475\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9827 - val_loss: 0.8659\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8412 - val_loss: 0.7693\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7520 - val_loss: 0.7036\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6917 - val_loss: 0.6605\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6525 - val_loss: 0.6327\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6274 - val_loss: 0.6146\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6110 - val_loss: 0.6020\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5997 - val_loss: 0.5925\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5912 - val_loss: 0.5847\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5842 - val_loss: 0.5779\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5782 - val_loss: 0.5714\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5726 - val_loss: 0.5654\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5673 - val_loss: 0.5596\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5623 - val_loss: 0.5544\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5578 - val_loss: 0.5493\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5535 - val_loss: 0.5443\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5494 - val_loss: 0.5397\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5455 - val_loss: 0.5354\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5417 - val_loss: 0.5312\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5382 - val_loss: 0.5273\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5347 - val_loss: 0.5234\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5314 - val_loss: 0.5200\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5282 - val_loss: 0.5165\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5251 - val_loss: 0.5133\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5223 - val_loss: 0.5101\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5195 - val_loss: 0.5072\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5168 - val_loss: 0.5045\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5142 - val_loss: 0.5018\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5118 - val_loss: 0.4993\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5093 - val_loss: 0.4970\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5072 - val_loss: 0.4947\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5051 - val_loss: 0.4927\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5030 - val_loss: 0.4907\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5010 - val_loss: 0.4891\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4991 - val_loss: 0.4872\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4973 - val_loss: 0.4856\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4956 - val_loss: 0.4840\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4939 - val_loss: 0.4827\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4923 - val_loss: 0.4812\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4908 - val_loss: 0.4802\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4892 - val_loss: 0.4788\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4877 - val_loss: 0.4781\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4862 - val_loss: 0.4767\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4849 - val_loss: 0.4758\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4836 - val_loss: 0.4746\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4823 - val_loss: 0.4734\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4810 - val_loss: 0.4723\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4797 - val_loss: 0.4711\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4785 - val_loss: 0.4700\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4773 - val_loss: 0.4690\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4761 - val_loss: 0.4679\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4749 - val_loss: 0.4669\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4738 - val_loss: 0.4661\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4727 - val_loss: 0.4652\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4716 - val_loss: 0.4645\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4705 - val_loss: 0.4638\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4695 - val_loss: 0.4624\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4685 - val_loss: 0.4616\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4675 - val_loss: 0.4611\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4665 - val_loss: 0.4600\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4655 - val_loss: 0.4596\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4648 - val_loss: 0.4585\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4639 - val_loss: 0.4577\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4631 - val_loss: 0.4569\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4621 - val_loss: 0.4559\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4613 - val_loss: 0.4553\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4605 - val_loss: 0.4548\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4595 - val_loss: 0.4540\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4590 - val_loss: 0.4535\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4582 - val_loss: 0.4530\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4574 - val_loss: 0.4523\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4567 - val_loss: 0.4518\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4559 - val_loss: 0.4509\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4552 - val_loss: 0.4507\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4546 - val_loss: 0.4500\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4537 - val_loss: 0.4490\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4530 - val_loss: 0.4483\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4522 - val_loss: 0.4480\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4515 - val_loss: 0.4474\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4508 - val_loss: 0.4465\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4501 - val_loss: 0.4461\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4493 - val_loss: 0.4456\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4487 - val_loss: 0.4450\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4478 - val_loss: 0.4449\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4474 - val_loss: 0.4439\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4466 - val_loss: 0.4431\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4459 - val_loss: 0.4424\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4453 - val_loss: 0.4419\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4447 - val_loss: 0.4416\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4441 - val_loss: 0.4409\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4435 - val_loss: 0.4406\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4429 - val_loss: 0.4399\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4423 - val_loss: 0.4395\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4416 - val_loss: 0.4392\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4411 - val_loss: 0.4387\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4405 - val_loss: 0.4381\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4399 - val_loss: 0.4380\n",
      "121/121 [==============================] - 0s 678us/step - loss: 0.5085\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 3.1668 - val_loss: 1.9741\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.7870 - val_loss: 1.2933\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2615 - val_loss: 1.0398\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0280 - val_loss: 0.9014\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8876 - val_loss: 0.8173\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8086 - val_loss: 0.7622\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7614 - val_loss: 0.7257\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7309 - val_loss: 0.7001\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7097 - val_loss: 0.6810\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6934 - val_loss: 0.6659\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6804 - val_loss: 0.6534\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6691 - val_loss: 0.6423\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6590 - val_loss: 0.6324\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6500 - val_loss: 0.6234\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6415 - val_loss: 0.6151\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6336 - val_loss: 0.6074\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6260 - val_loss: 0.5999\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6186 - val_loss: 0.5933\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6122 - val_loss: 0.5864\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6056 - val_loss: 0.5802\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5995 - val_loss: 0.5743\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5935 - val_loss: 0.5686\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5878 - val_loss: 0.5632\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5824 - val_loss: 0.5580\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5769 - val_loss: 0.5532\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5722 - val_loss: 0.5485\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5673 - val_loss: 0.5439\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5628 - val_loss: 0.5395\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5585 - val_loss: 0.5351\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5541 - val_loss: 0.5312\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5501 - val_loss: 0.5274\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5462 - val_loss: 0.5234\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5425 - val_loss: 0.5199\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5389 - val_loss: 0.5167\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5354 - val_loss: 0.5134\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5322 - val_loss: 0.5103\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5288 - val_loss: 0.5073\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5259 - val_loss: 0.5043\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5229 - val_loss: 0.5013\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5201 - val_loss: 0.4988\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5175 - val_loss: 0.4964\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5149 - val_loss: 0.4938\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5124 - val_loss: 0.4916\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5099 - val_loss: 0.4892\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5076 - val_loss: 0.4868\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5054 - val_loss: 0.4848\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5032 - val_loss: 0.4829\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5012 - val_loss: 0.4812\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4991 - val_loss: 0.4794\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4972 - val_loss: 0.4775\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4955 - val_loss: 0.4757\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4934 - val_loss: 0.4740\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4918 - val_loss: 0.4724\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4901 - val_loss: 0.4709\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4886 - val_loss: 0.4695\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4869 - val_loss: 0.4680\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4853 - val_loss: 0.4667\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4840 - val_loss: 0.4653\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4826 - val_loss: 0.4639\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4811 - val_loss: 0.4628\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4798 - val_loss: 0.4611\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4784 - val_loss: 0.4603\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4772 - val_loss: 0.4589\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4759 - val_loss: 0.4577\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4747 - val_loss: 0.4564\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4735 - val_loss: 0.4555\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4724 - val_loss: 0.4548\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4712 - val_loss: 0.4535\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4700 - val_loss: 0.4528\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4691 - val_loss: 0.4517\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4680 - val_loss: 0.4507\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4670 - val_loss: 0.4495\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4659 - val_loss: 0.4488\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4649 - val_loss: 0.4479\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4638 - val_loss: 0.4475\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4631 - val_loss: 0.4461\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4622 - val_loss: 0.4455\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4613 - val_loss: 0.4447\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4603 - val_loss: 0.4441\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4595 - val_loss: 0.4433\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4586 - val_loss: 0.4423\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4578 - val_loss: 0.4418\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4569 - val_loss: 0.4414\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4560 - val_loss: 0.4406\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4552 - val_loss: 0.4398\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4544 - val_loss: 0.4390\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4534 - val_loss: 0.4382\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4528 - val_loss: 0.4377\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4520 - val_loss: 0.4367\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4513 - val_loss: 0.4358\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4506 - val_loss: 0.4356\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4497 - val_loss: 0.4349\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4492 - val_loss: 0.4342\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4484 - val_loss: 0.4338\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4477 - val_loss: 0.4333\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4470 - val_loss: 0.4327\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4462 - val_loss: 0.4320\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4455 - val_loss: 0.4314\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4448 - val_loss: 0.4308\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4443 - val_loss: 0.4300\n",
      "121/121 [==============================] - 0s 682us/step - loss: 0.4421\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.0528 - val_loss: 0.8141\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8013 - val_loss: 0.6714\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6943 - val_loss: 0.5547\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5833 - val_loss: 0.5186\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5344 - val_loss: 0.4898\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5113 - val_loss: 0.4744\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5027 - val_loss: 0.4945\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4992 - val_loss: 0.4609\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4878 - val_loss: 0.4553\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4839 - val_loss: 0.4520\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4795 - val_loss: 0.4485\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4751 - val_loss: 0.4440\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4749 - val_loss: 0.4437\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4698 - val_loss: 0.4400\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4670 - val_loss: 0.4376\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4644 - val_loss: 0.4357\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4633 - val_loss: 0.4376\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4602 - val_loss: 0.4350\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4579 - val_loss: 0.4310\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4600 - val_loss: 0.4326\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4548 - val_loss: 0.4296\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4539 - val_loss: 0.4367\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4534 - val_loss: 0.4266\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4491 - val_loss: 0.4254\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4526 - val_loss: 0.4287\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4477 - val_loss: 0.4237\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4449 - val_loss: 0.4244\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4440 - val_loss: 0.4236\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4424 - val_loss: 0.4220\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4411 - val_loss: 0.4194\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4457 - val_loss: 0.4230\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4409 - val_loss: 0.4192\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4374 - val_loss: 0.4174\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4367 - val_loss: 0.4170\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4363 - val_loss: 0.4140\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4346 - val_loss: 0.4132\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4326 - val_loss: 0.4144\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4322 - val_loss: 0.4111\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4309 - val_loss: 0.4115\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4311 - val_loss: 0.4109\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4281 - val_loss: 0.4099\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4330 - val_loss: 0.4124\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4298 - val_loss: 0.4094\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4256 - val_loss: 0.4067\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4242 - val_loss: 0.4145\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4266 - val_loss: 0.4041\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4218 - val_loss: 0.4044\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4243 - val_loss: 0.4051\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4211 - val_loss: 0.4028\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4201 - val_loss: 0.4066\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4182 - val_loss: 0.4015\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4199 - val_loss: 0.4022\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4173 - val_loss: 0.4020\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4162 - val_loss: 0.3995\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4143 - val_loss: 0.3981\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4163 - val_loss: 0.3990\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4144 - val_loss: 0.3986\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4138 - val_loss: 0.4004\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4147 - val_loss: 0.3978\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4116 - val_loss: 0.3966\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4109 - val_loss: 0.3946\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4111 - val_loss: 0.3953\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4088 - val_loss: 0.3954\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4085 - val_loss: 0.3943\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4076 - val_loss: 0.3931\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4070 - val_loss: 0.3938\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4059 - val_loss: 0.3910\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4071 - val_loss: 0.4092\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4241 - val_loss: 0.3941\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4063 - val_loss: 0.3903\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4058 - val_loss: 0.3913\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4042 - val_loss: 0.3893\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4030 - val_loss: 0.3911\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4049 - val_loss: 0.3895\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4037 - val_loss: 0.3900\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4020 - val_loss: 0.3903\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4009 - val_loss: 0.3900\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4000 - val_loss: 0.3887\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3997 - val_loss: 0.3856\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3999 - val_loss: 0.3875\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4004 - val_loss: 0.3890\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3997 - val_loss: 0.3866\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3978 - val_loss: 0.3854\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4021 - val_loss: 0.3859\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3990 - val_loss: 0.3850\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3972 - val_loss: 0.3834\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4009 - val_loss: 0.3841\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3961 - val_loss: 0.3832\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3968 - val_loss: 0.3829\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3958 - val_loss: 0.3851\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4041 - val_loss: 0.3847\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3959 - val_loss: 0.3824\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3956 - val_loss: 0.3815\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3926 - val_loss: 0.3823\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3981 - val_loss: 0.3841\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3938 - val_loss: 0.3823\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3918 - val_loss: 0.3805\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3933 - val_loss: 0.3811\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3912 - val_loss: 0.3816\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3923 - val_loss: 0.4293\n",
      "121/121 [==============================] - 0s 634us/step - loss: 0.4320\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5491 - val_loss: 0.9522\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7248 - val_loss: 0.7507\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6244 - val_loss: 0.6411\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5736 - val_loss: 0.5771\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5444 - val_loss: 0.5327\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5225 - val_loss: 0.5052\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5071 - val_loss: 0.4884\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4954 - val_loss: 0.4783\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4873 - val_loss: 0.4710\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4810 - val_loss: 0.4673\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4756 - val_loss: 0.4663\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4718 - val_loss: 0.4645\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4679 - val_loss: 0.4641\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4643 - val_loss: 0.4635\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4617 - val_loss: 0.4650\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4593 - val_loss: 0.4628\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4568 - val_loss: 0.4660\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4552 - val_loss: 0.4618\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4535 - val_loss: 0.4613\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4514 - val_loss: 0.4603\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4498 - val_loss: 0.4600\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4481 - val_loss: 0.4622\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4465 - val_loss: 0.4607\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4451 - val_loss: 0.4580\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4433 - val_loss: 0.4607\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4425 - val_loss: 0.4574\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4410 - val_loss: 0.4572\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4397 - val_loss: 0.4559\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4381 - val_loss: 0.4552\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4372 - val_loss: 0.4529\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4358 - val_loss: 0.4536\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4337 - val_loss: 0.4526\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4330 - val_loss: 0.4497\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4318 - val_loss: 0.4483\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4308 - val_loss: 0.4479\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4293 - val_loss: 0.4458\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4281 - val_loss: 0.4437\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4268 - val_loss: 0.4424\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4263 - val_loss: 0.4381\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4248 - val_loss: 0.4382\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4240 - val_loss: 0.4353\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4228 - val_loss: 0.4356\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4213 - val_loss: 0.4350\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4207 - val_loss: 0.4318\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4197 - val_loss: 0.4292\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4179 - val_loss: 0.4285\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4172 - val_loss: 0.4252\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4164 - val_loss: 0.4254\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4152 - val_loss: 0.4234\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4145 - val_loss: 0.4220\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4126 - val_loss: 0.4208\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4117 - val_loss: 0.4209\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4111 - val_loss: 0.4189\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4097 - val_loss: 0.4171\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4087 - val_loss: 0.4161\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4073 - val_loss: 0.4179\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4067 - val_loss: 0.4129\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4056 - val_loss: 0.4122\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4046 - val_loss: 0.4116\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4035 - val_loss: 0.4119\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4024 - val_loss: 0.4111\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4014 - val_loss: 0.4097\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4012 - val_loss: 0.4077\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4002 - val_loss: 0.4073\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3997 - val_loss: 0.4056\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3984 - val_loss: 0.4049\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3977 - val_loss: 0.4038\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3964 - val_loss: 0.4038\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3957 - val_loss: 0.4031\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3954 - val_loss: 0.4012\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3947 - val_loss: 0.4020\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3941 - val_loss: 0.3994\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3934 - val_loss: 0.3991\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3920 - val_loss: 0.4004\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3924 - val_loss: 0.3974\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3911 - val_loss: 0.3972\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3896 - val_loss: 0.3969\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3896 - val_loss: 0.3955\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3889 - val_loss: 0.3955\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3884 - val_loss: 0.3956\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3876 - val_loss: 0.3949\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3873 - val_loss: 0.3942\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3856 - val_loss: 0.3936\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3857 - val_loss: 0.3936\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3853 - val_loss: 0.3947\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3850 - val_loss: 0.3942\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3841 - val_loss: 0.3923\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3832 - val_loss: 0.3914\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3831 - val_loss: 0.3905\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3827 - val_loss: 0.3910\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3817 - val_loss: 0.3914\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3813 - val_loss: 0.3892\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3807 - val_loss: 0.3906\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3805 - val_loss: 0.3884\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3801 - val_loss: 0.3887\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3799 - val_loss: 0.3878\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3794 - val_loss: 0.3886\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3779 - val_loss: 0.3887\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3783 - val_loss: 0.3865\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3775 - val_loss: 0.3895\n",
      "121/121 [==============================] - 0s 643us/step - loss: 0.4262\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.7310 - val_loss: 0.7894\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9798 - val_loss: 0.7516\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8193 - val_loss: 0.5689\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5592 - val_loss: 0.5198\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5303 - val_loss: 0.5010\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5142 - val_loss: 0.4887\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5019 - val_loss: 0.4801\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4913 - val_loss: 0.4715\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4818 - val_loss: 0.4630\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4777 - val_loss: 0.4593\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4739 - val_loss: 0.4619\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4666 - val_loss: 0.4482\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4652 - val_loss: 0.4455\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4593 - val_loss: 0.4427\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4534 - val_loss: 0.4401\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4526 - val_loss: 0.4367\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4481 - val_loss: 0.4345\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4430 - val_loss: 0.4359\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4405 - val_loss: 0.4317\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4379 - val_loss: 0.4274\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4373 - val_loss: 0.4410\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4349 - val_loss: 0.4231\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4311 - val_loss: 0.4267\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4299 - val_loss: 0.4217\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4271 - val_loss: 0.4228\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4277 - val_loss: 0.4200\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4257 - val_loss: 0.4161\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4225 - val_loss: 0.4156\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4216 - val_loss: 0.4138\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4205 - val_loss: 0.4140\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4206 - val_loss: 0.4145\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4179 - val_loss: 0.4115\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4163 - val_loss: 0.4116\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4150 - val_loss: 0.4081\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4146 - val_loss: 0.4141\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4147 - val_loss: 0.4078\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4118 - val_loss: 0.4052\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4107 - val_loss: 0.4064\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4096 - val_loss: 0.4054\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4089 - val_loss: 0.4032\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4070 - val_loss: 0.4017\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4062 - val_loss: 0.4014\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4055 - val_loss: 0.3999\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4050 - val_loss: 0.3999\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4031 - val_loss: 0.4000\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4043 - val_loss: 0.3997\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4013 - val_loss: 0.3989\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4016 - val_loss: 0.3949\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4009 - val_loss: 0.3953\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3993 - val_loss: 0.3943\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3995 - val_loss: 0.3935\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3979 - val_loss: 0.3926\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3966 - val_loss: 0.3981\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4071 - val_loss: 0.3929\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4032 - val_loss: 0.3935\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3978 - val_loss: 0.3903\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3995 - val_loss: 0.3923\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3942 - val_loss: 0.3886\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3928 - val_loss: 0.3909\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3932 - val_loss: 0.3899\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3918 - val_loss: 0.3993\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3938 - val_loss: 0.3906\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3927 - val_loss: 0.3872\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3941 - val_loss: 0.3880\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3895 - val_loss: 0.3847\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3882 - val_loss: 0.3864\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3900 - val_loss: 0.3916\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3867 - val_loss: 0.3906\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3923 - val_loss: 0.3845\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3917 - val_loss: 0.3840\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3874 - val_loss: 0.3816\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3855 - val_loss: 0.3849\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3885 - val_loss: 0.3821\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3847 - val_loss: 0.3819\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3847 - val_loss: 0.3846\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3837 - val_loss: 0.3808\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3831 - val_loss: 0.3808\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3816 - val_loss: 0.3822\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3821 - val_loss: 0.3798\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3813 - val_loss: 0.3793\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3852 - val_loss: 0.3806\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3841 - val_loss: 0.3785\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3804 - val_loss: 0.3797\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3798 - val_loss: 0.3774\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3805 - val_loss: 0.3765\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3899 - val_loss: 0.3793\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4038 - val_loss: 0.3782\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3792 - val_loss: 0.3764\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3787 - val_loss: 0.3764\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3824 - val_loss: 0.3806\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3890 - val_loss: 0.3750\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3782 - val_loss: 0.3767\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3772 - val_loss: 0.3749\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3780 - val_loss: 0.3752\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3760 - val_loss: 0.3762\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3775 - val_loss: 0.3744\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3832 - val_loss: 0.3773\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3995 - val_loss: 0.3746\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3836 - val_loss: 0.3753\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3799 - val_loss: 0.3728\n",
      "121/121 [==============================] - 0s 653us/step - loss: 0.3757\n",
      "Epoch 1/100\n",
      "  1/363 [..............................] - ETA: 54s - loss: 5.5193"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tuffy/venvs/.tf/lib/python3.10/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [-5.85485895e-01 -3.46677909e-01 -3.57387841e-01             nan\n",
      " -4.27793692e-01             nan -3.73092771e-01 -6.98091305e+20\n",
      " -4.60249235e-01 -4.11295513e-01]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - 1s 1ms/step - loss: 1.2644 - val_loss: 4.6440\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 0s 992us/step - loss: 9.0837 - val_loss: 0.5868\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 988us/step - loss: 0.8366 - val_loss: 0.5429\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 0s 994us/step - loss: 0.6175 - val_loss: 0.4787\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5165 - val_loss: 0.4552\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 0s 996us/step - loss: 0.4780 - val_loss: 0.4353\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 0s 990us/step - loss: 0.4553 - val_loss: 0.4337\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 0s 987us/step - loss: 0.4407 - val_loss: 0.4198\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 0s 986us/step - loss: 0.4304 - val_loss: 0.4139\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4238 - val_loss: 0.4115\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 0s 997us/step - loss: 0.4181 - val_loss: 0.4039\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 997us/step - loss: 0.4140 - val_loss: 0.4012\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 0s 982us/step - loss: 0.4096 - val_loss: 0.3982\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4064 - val_loss: 0.3963\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4030 - val_loss: 0.3947\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4003 - val_loss: 0.3900\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3976 - val_loss: 0.3875\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3946 - val_loss: 0.3864\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3920 - val_loss: 0.3863\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3897 - val_loss: 0.3818\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3874 - val_loss: 0.3790\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3854 - val_loss: 0.3776\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3833 - val_loss: 0.3758\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3812 - val_loss: 0.3759\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3788 - val_loss: 0.3741\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3770 - val_loss: 0.3713\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3755 - val_loss: 0.3690\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3730 - val_loss: 0.3680\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3714 - val_loss: 0.3685\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3693 - val_loss: 0.3665\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3681 - val_loss: 0.3682\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3666 - val_loss: 0.3655\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3655 - val_loss: 0.3631\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 0s 990us/step - loss: 0.3635 - val_loss: 0.3656\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 0s 990us/step - loss: 0.3627 - val_loss: 0.3614\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 0s 990us/step - loss: 0.3611 - val_loss: 0.3594\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3598 - val_loss: 0.3609\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 0s 988us/step - loss: 0.3588 - val_loss: 0.3609\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3579 - val_loss: 0.3592\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3567 - val_loss: 0.3579\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3565 - val_loss: 0.3553\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3545 - val_loss: 0.3579\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3535 - val_loss: 0.3536\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3522 - val_loss: 0.3532\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3519 - val_loss: 0.3538\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3508 - val_loss: 0.3539\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3524 - val_loss: 0.3514\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3502 - val_loss: 0.3523\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3488 - val_loss: 0.3515\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3471 - val_loss: 0.3514\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 0s 984us/step - loss: 0.3456 - val_loss: 0.3502\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3451 - val_loss: 0.3511\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 0s 996us/step - loss: 0.3442 - val_loss: 0.3479\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3428 - val_loss: 0.3487\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3458 - val_loss: 0.3471\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3421 - val_loss: 0.3466\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3410 - val_loss: 0.3459\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3405 - val_loss: 0.3450\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 0s 982us/step - loss: 0.3395 - val_loss: 0.3433\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 0s 994us/step - loss: 0.3381 - val_loss: 0.3461\n",
      "Epoch 61/100\n",
      "363/363 [==============================] - 0s 985us/step - loss: 0.3378 - val_loss: 0.3476\n",
      "Epoch 62/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3373 - val_loss: 0.3414\n",
      "Epoch 63/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3361 - val_loss: 0.3469\n",
      "Epoch 64/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3358 - val_loss: 0.3427\n",
      "Epoch 65/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3351 - val_loss: 0.3420\n",
      "Epoch 66/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3359 - val_loss: 0.3410\n",
      "Epoch 67/100\n",
      "363/363 [==============================] - 0s 993us/step - loss: 0.3334 - val_loss: 0.3450\n",
      "Epoch 68/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3325 - val_loss: 0.3435\n",
      "Epoch 69/100\n",
      "363/363 [==============================] - 0s 999us/step - loss: 0.3353 - val_loss: 0.3404\n",
      "Epoch 70/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3335 - val_loss: 0.3384\n",
      "Epoch 71/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3311 - val_loss: 0.3411\n",
      "Epoch 72/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3311 - val_loss: 0.3385\n",
      "Epoch 73/100\n",
      "363/363 [==============================] - 0s 999us/step - loss: 0.3334 - val_loss: 0.3355\n",
      "Epoch 74/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3335 - val_loss: 0.3389\n",
      "Epoch 75/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3352 - val_loss: 0.3397\n",
      "Epoch 76/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3297 - val_loss: 0.3460\n",
      "Epoch 77/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3415 - val_loss: 0.3352\n",
      "Epoch 78/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3280 - val_loss: 0.3376\n",
      "Epoch 79/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3268 - val_loss: 0.3397\n",
      "Epoch 80/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3267 - val_loss: 0.3340\n",
      "Epoch 81/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3258 - val_loss: 0.3357\n",
      "Epoch 82/100\n",
      "363/363 [==============================] - 0s 999us/step - loss: 0.3255 - val_loss: 0.3334\n",
      "Epoch 83/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3248 - val_loss: 0.3336\n",
      "Epoch 84/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3254 - val_loss: 0.3327\n",
      "Epoch 85/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3248 - val_loss: 0.3314\n",
      "Epoch 86/100\n",
      "363/363 [==============================] - 0s 998us/step - loss: 0.3235 - val_loss: 0.3315\n",
      "Epoch 87/100\n",
      "363/363 [==============================] - 0s 991us/step - loss: 0.3226 - val_loss: 0.3324\n",
      "Epoch 88/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3221 - val_loss: 0.3348\n",
      "Epoch 89/100\n",
      "363/363 [==============================] - 0s 985us/step - loss: 0.3237 - val_loss: 0.3351\n",
      "Epoch 90/100\n",
      "363/363 [==============================] - 0s 987us/step - loss: 0.3217 - val_loss: 0.3307\n",
      "Epoch 91/100\n",
      "363/363 [==============================] - 0s 998us/step - loss: 0.3215 - val_loss: 0.3337\n",
      "Epoch 92/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3218 - val_loss: 0.3302\n",
      "Epoch 93/100\n",
      "363/363 [==============================] - 0s 995us/step - loss: 0.3214 - val_loss: 0.3290\n",
      "Epoch 94/100\n",
      "363/363 [==============================] - 0s 989us/step - loss: 0.3195 - val_loss: 0.3297\n",
      "Epoch 95/100\n",
      "363/363 [==============================] - 0s 994us/step - loss: 0.3195 - val_loss: 0.3283\n",
      "Epoch 96/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3192 - val_loss: 0.3288\n",
      "Epoch 97/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3209 - val_loss: 0.3312\n",
      "Epoch 98/100\n",
      "363/363 [==============================] - 0s 997us/step - loss: 0.3187 - val_loss: 0.3273\n",
      "Epoch 99/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3201 - val_loss: 0.3276\n",
      "Epoch 100/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3176 - val_loss: 0.3269\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=&lt;keras.wrappers.scikit_learn.KerasRegressor object at 0x7fe705054700&gt;,\n",
       "                   param_distributions={&#x27;learning_rate&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7fe6dc319300&gt;,\n",
       "                                        &#x27;n_hidden&#x27;: [0, 1, 2, 3],\n",
       "                                        &#x27;n_neurons&#x27;: array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
       "       52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,\n",
       "       69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85,\n",
       "       86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=&lt;keras.wrappers.scikit_learn.KerasRegressor object at 0x7fe705054700&gt;,\n",
       "                   param_distributions={&#x27;learning_rate&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7fe6dc319300&gt;,\n",
       "                                        &#x27;n_hidden&#x27;: [0, 1, 2, 3],\n",
       "                                        &#x27;n_neurons&#x27;: array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
       "       52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,\n",
       "       69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85,\n",
       "       86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KerasRegressor</label><div class=\"sk-toggleable__content\"><pre>&lt;keras.wrappers.scikit_learn.KerasRegressor object at 0x7fe705054700&gt;</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KerasRegressor</label><div class=\"sk-toggleable__content\"><pre>&lt;keras.wrappers.scikit_learn.KerasRegressor object at 0x7fe705054700&gt;</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=<keras.wrappers.scikit_learn.KerasRegressor object at 0x7fe705054700>,\n",
       "                   param_distributions={'learning_rate': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7fe6dc319300>,\n",
       "                                        'n_hidden': [0, 1, 2, 3],\n",
       "                                        'n_neurons': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
       "       52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,\n",
       "       69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85,\n",
       "       86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distribs={\n",
    "    'n_hidden': [0,1,2,3],\n",
    "    'n_neurons': np.arange(1,100),\n",
    "    'learning_rate': reciprocal(3e-4, 3e-2),\n",
    "}\n",
    "\n",
    "rnd_search_cv=RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3)\n",
    "rnd_search_cv.fit(X_train, y_train, epochs=100,\n",
    "                 validation_data=(X_valid, y_valid),\n",
    "                 callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48144b61-6a49-4547-9bd1-55f4248bd5c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.004451635554021628, 'n_hidden': 1, 'n_neurons': 47}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8252831-9079-4fef-a073-8e1722b76f21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.3466779092947642"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3c559f7-37bb-422e-9966-69d2c768f1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=rnd_search_cv.best_estimator_.model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75dbd802-c429-49f6-b8e0-03dd9bcc3517",
   "metadata": {},
   "source": [
    "本で紹介されているハイパーパラメータチューニング用ライブラリ\n",
    "\n",
    "[Hyperopt](https://github.com/hyperopt/hyperopt): popular。\n",
    "\n",
    "[Hyperas](https://github.com/maxpumperla/hyperas), [kopt](https://github.com/Avsecz/kopt), [Talos](https://github.com/autonomio/talos):　dKerasモデルの最適化。有用。\n",
    "\n",
    "[Keras Tuner](https://keras.io/keras_tuner/): GoogleのKeras専用ライブラリ、使い勝手良。\n",
    "\n",
    "[Scikit-Optimize](https://scikit-optimize.github.io/stable/): 汎用。ベイズ最適化。\n",
    "\n",
    "[Spearmint](https://github.com/JasperSnoek/spearmint): ベイズ最適化。\n",
    "\n",
    "[Hyperband](https://github.com/zygmuntz/hyperband): 高速。Lisha Li et al.\n",
    "\n",
    "[Sklearn-Deap](https://github.com/rsteca/sklearn-deap): 進化計算。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3629b28-9ad0-4a34-b018-3422e65b74f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_tf",
   "language": "python",
   "name": "ml_tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
